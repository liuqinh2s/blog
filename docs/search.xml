<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2Fblog%2F2019%2F02%2F19%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序算法是一个原理非常简单易懂的算法，但如果现场手写的话又有多少人能写得出来呢？我今天又试了一下，发现还是存在一些认知上的问题。首先我明白快排的核心操作是：选取一个中枢，然后把小于中枢的放到左边，大于中枢的放到右边。但我发现时隔仅仅一年多，我居然已经忘了这个操作的英文名字了。直到我在写这篇文章的时候才突然想起来：partition操作。 在使用partition操作的前提下，递归解决问题就OK了。 partition具体操作如下： 我选取的中枢是第一个元素，且从前往后遍历数组。遇到小于中枢的，我要交换当前结点和中枢。遇到大于中枢的，直接略过。 第一个分支也就是遇到小于中枢的结点，这里才是操作比较复杂的部分，仔细想想其实这里要交换两次。将小于中枢的结点与中枢交换之后，中枢跑到了最后面，此时的结构相当于：小小小..大大大..中枢。我们还要将中枢塞到中间去。 1234567891011121314151617181920212223242526public void qsort(int[] array, int begin, int end)&#123; if(begin&gt;=end-1)&#123; return; &#125; int pivotIndex = partition(array, begin, end); qsort(array, begin, pivotIndex); qsort(array, pivotIndex+1, end);&#125;private int partition(int[] array, int begin, int end)&#123; int pivot = array[begin]; int pivotIndex = begin; int index = begin+1; while(index&lt;end)&#123; if(array[index]&lt;pivot)&#123; int temp = array[index]; array[index] = array[pivotIndex]; array[pivotIndex++] = temp; temp = array[index]; array[index] = array[pivotIndex]; array[pivotIndex] = temp; &#125; index++; &#125; return pivotIndex;&#125; 还可以思考一下： 选第一个元素做中枢，从后往前遍历 选最后一个元素做中枢，从前往后遍历 选最后一个元素做中枢，从后往前遍历 所以最后我发现快速排序确实是一个简单易懂的算法，难点在于partition操作的具体问题具体分析。四类partition全部写一遍。应该差不多了。 上面的方法归根结底都是使用 一个中枢 来划分，实际上也可以用两个指针来划分：一个记录小部的末尾，一个记录大部的首部。这两个指针一个从前往后，一个从后往前，直到相遇，本轮划分操作就结束。 于是我又抽空写了一下这个两个指针往中间靠的，结果并没有一遍写对，原因是边界检查，居然要不停的检查： 123456789101112131415161718192021private int partition1(int[] array, int begin, int end)&#123; int pivot = array[begin]; int smallEnd = begin; int bigBegin = end-1; while(smallEnd&lt;bigBegin)&#123; while (smallEnd&lt;bigBegin &amp;&amp; array[bigBegin]&gt;pivot)&#123; bigBegin--; &#125; if(smallEnd&lt;bigBegin)&#123; array[smallEnd++] = array[bigBegin]; &#125; while(smallEnd&lt;bigBegin &amp;&amp; array[smallEnd]&lt;pivot)&#123; smallEnd++; &#125; if(smallEnd&lt;bigBegin)&#123; array[bigBegin--] = array[smallEnd]; &#125; &#125; array[smallEnd] = pivot; return smallEnd;&#125; 这样感觉就太不美了。]]></content>
      <categories>
        <category>算法</category>
        <category>排序</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[并查集]]></title>
    <url>%2Fblog%2F2019%2F01%2F19%2F%E5%B9%B6%E6%9F%A5%E9%9B%86%2F</url>
    <content type="text"><![CDATA[并查集什么是并查集并查集的核心是parent指针，一个结点可以找到自己所属的结点。从而把结点归类。有两个核心操作： Union（用来合并两个并查集） Find（用于查找一个结点的parent） 所以并查集可以叫做：union-find data structure。 什么是路径压缩我们看两个结点是否属于同一个并查集，实际上只看最顶层的那个parent，如果这两个结点属于同一个最顶层parent，那么它们就在同一个并查集中。 所以我们实际上只需要两层的树结构，让所有其他结点的parent指针指向最顶层parent，这样就能达到扁平化并查集的目的，从而使Find操作从O(logN)的时间复杂度变成O(1)。这就叫：路径压缩 代码如下： 123456public void findParent(UnionFindSetNode node)&#123; if(node.parent!=node)&#123; node.parent = findParent(node.parent); &#125; return node.parent;&#125; 这段代码很巧妙，可以在查找本结点父亲的时候，将路径上的所有祖先扁平化。 合并操作核心目标是：尽可能减少深度。所以需要注意的点是：把深度小的并查集归并到深度大的并查集。我们给并查集多添加一个深度属性：rank，比如两层的并查集，parent的rank就是1，叶子节点们的rank就是0。 代码如下： 1234567891011121314public void union(UnionFindSetNode node1, UnionFindSetNode node2)&#123; UnionFindSetNode parent1 = findParent(node1); UnionFindSetNode parent2 = findParent(node2); if(parent1!=parent2)&#123; if(parent1.rank&gt;parent2.rank)&#123; parent2.parent = parent1; &#125;else if(parent1.rank&lt;parent2.rank)&#123; parent1.parent = parent2; &#125;else&#123; parent1.parent = parent2; parent2.rank++; &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[KMP算法]]></title>
    <url>%2Fblog%2F2019%2F01%2F17%2FKMP%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[KMP算法KMP算法用来在一个文本中查找模式串，如下图所示： 文本匹配例子： 我们把上面那个长字符串的称为文本，下面这个短的称为模式串。我们的目的是查看ABADABAD是否出现在文本中。 不必要的比较： 跳过不必要的比较： KMP算法的核心作用在于帮助模式串顺利的跳过很多不必要的比较（模式串没有任何前缀与文本匹配），直接后移到一部分前缀已经匹配的位置，开始下一次的比较。更准确的讲是移动到：最长真前后缀匹配的位置，如上图所示的ABA。 什么是真前后缀前缀和后缀我们都不陌生，比如单词ABA，它有三个前缀：A、AB、ABA，和三个后缀：A、BA、ABA。 真前后缀的意思是，前后缀必须是单词的真子集，也就是说不能是单词本身。所以上面那个单词ABA的真前缀是：A、AB，真后缀是：A、BA。 那么单词ABA真前后缀的最长匹配是：A。 那么真前后缀是否匹配有什么用？我们仔细观察文章最开头的文本匹配例子。在不必要的比较中，我们拿BADABA和ABADAB比较。而这两个，前者是模式串ABADABA部分的后缀，后者则是前缀。如果我们算得了ABADABA的真前后缀的最长匹配，就已经知道了BADABA和ABADAB不相等。而且还知道ADABA和ABADA也不相等，等等。 只要我们知道了真前后缀的最长匹配是什么，我们可以直接跳过所有这些没必要的比较。 KMP的核心就是：在每一次失配的时候，利用最长真前后缀匹配长度，直接跳过不必要的比较。 next数组next数组也就是：部分匹配表（Partial Match Table）。就是一个最长真前后缀匹配长度表。 首先next数组只需要用模式串得出，它是对模式串的解析，跟要匹配的文本没有半毛钱关系。其次next数组记录的其实就是最长真前后缀匹配长度，但错开了一位。 真前后缀的意思是，前后缀不能是字符串本身，只能是字符串的真子集 i 0 1 2 3 4 5 6 7 8 模式串 A B A D A B A D \0 next[i] -1 0 0 1 0 1 2 3 4 i = 0，next[0]，我们填-1； i = 1，前面的字符串为A，其最长相同真前后缀长度为0，即next[1] = 0； i = 2，前面的字符串为AB，其最长相同真前后缀长度为0，即next[2] = 0； i = 3，前面的字符串为ABA，其最长相同真前后缀为A，即next[3] = 1； i = 4，前面的字符串为ABAD，其最长相同真前后缀长度为0，即next[4] = 0； i = 5，前面的字符串为ABADA，其最长相同真前后缀长度为A，即next[5] = 1； i = 6，前面的字符串为ABADAB，其最长相同真前后缀长度为AB，即next[6] = 2； i = 7，前面的字符串为ABADABA，其最长相同真前后缀为ABA，即next[7] = 3； i = 8，前面的字符串为ABADABAD，其最长相同真前后缀为ABAD，即next[8]=4； 这张next表及其有用，前面说了，在字符串匹配的每一次失配的时候，我们都可以用已经匹配上的这段字符串的最长真前后缀匹配长度来定位将要跳转的位置。还是拿最开始的文本匹配例子： 当图一失配的时候，我们查ABADABAD的失配位置的next数组，也就是next[7]，得到ABADABA的最长真前后缀匹配长度3，然后拿&quot;ABADABAD&quot;.charAt(3)也就是D跟文本中失配处的字符&#39; &#39;继续匹配。如果又失配，那么递归处理。递归的边界是什么？答案是next[0]。 代码这个代码并不难写，我简单讲一下。 首先我们需要构造next数组，需要的参数只有一个：模式串。 然后我们使用一个指针遍历模式串，另一个指针负责记录匹配深度。 分支只有两个，一个是递归的边界或者匹配的时候：i++，j++，next[i]=j。一个是非递归边界且不匹配的时候，递归查找下一个必要的匹配：j=next[j]。 12345678910111213141516171819202122232425262728293031323334private int[] getNextArray(String pattern)&#123; int[] nextArray = new int[pattern.length()+1]; nextArray[0]=-1; int i=0; int j=-1; while(i&lt;pattern.length())&#123; if(j==-1 || pattern.charAt(i)==pattern.charAt(j))&#123; i++; j++; nextArray[i]=j; &#125;else&#123; j = nextArray[j]; &#125; &#125; return nextArray;&#125;public int KMP(String text, String pattern)&#123; int[] nextArray = getNextArray(pattern); int i=0; int j=-1; while(i&lt;text.length() &amp;&amp; j&lt;pattern.length())&#123; if(j==-1 || text.charAt(i)==pattern.charAt(j))&#123; i++; j++; &#125;else&#123; j = nextArray[j]; &#125; &#125; if(j==pattern.length())&#123; return i-j; &#125; return -1;&#125; 当然这种错开，和next[0]=-1的设定，不那么自然。其实可以有更自然的设计： i 0 1 2 3 4 5 6 7 8 模式串 A B A D A B A D \0 next[i] 0 0 1 0 1 2 3 4 这样一一对应就行了，next数组也与模式串等长。 这种next表的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839private int[] getNextArray(String pattern)&#123; int[] nextArray = new int[pattern.length()]; int i=1; int j=0; while(i&lt;pattern.length())&#123; while(j&gt;0 &amp;&amp; pattern.charAt(i)!=pattern.charAt(j))&#123; j = nextArray[j-1]; &#125; while(i&lt;pattern.length() &amp;&amp; pattern.charAt(i)==pattern.charAt(j))&#123; nextArray[i++] = ++j; &#125; if(j==0)&#123; nextArray[i++] = j; &#125; &#125; return nextArray;&#125;public int KMP(String text, String pattern)&#123; int[] nextArray = getNextArray(pattern); int i=0; int j=0; while(i&lt;text.length() &amp;&amp; j&lt;pattern.length())&#123; while(j&gt;0 &amp;&amp; text.charAt(i)!=pattern.charAt(j))&#123; j = nextArray[j-1]; &#125; while(i&lt;text.length() &amp;&amp; j&lt;pattern.length() &amp;&amp; text.charAt(i)==pattern.charAt(j))&#123; i++; j++; &#125; if(j==0)&#123; i++; &#125; &#125; if(j==pattern.length())&#123; return i-j; &#125; return -1;&#125; 这段代码看起来远不如上面第一种next表的代码简洁清晰。下面做一个简化，去掉内部的循环： 1234567891011121314151617181920212223242526272829303132333435private int[] getNextArray(String pattern)&#123; int[] nextArray = new int[pattern.length()]; int i=1; int j=0; while(i&lt;pattern.length())&#123; if(j&gt;0 &amp;&amp; pattern.charAt(i)!=pattern.charAt(j))&#123; j = nextArray[j-1]; &#125; else if(pattern.charAt(i)==pattern.charAt(j))&#123; nextArray[i++] = ++j; &#125; else if(j==0)&#123; nextArray[i++] = j; &#125; &#125; return nextArray;&#125;public int KMP(String text, String pattern)&#123; int[] nextArray = getNextArray(pattern); int i=0; int j=0; while(i&lt;text.length() &amp;&amp; j&lt;pattern.length())&#123; if(j&gt;0 &amp;&amp; text.charAt(i)!=pattern.charAt(j))&#123; j = nextArray[j-1]; &#125; else if(text.charAt(i)==pattern.charAt(j))&#123; i++; j++; &#125; else if(j==0)&#123; i++; &#125; &#125; if(j==pattern.length())&#123; return i-j; &#125; return -1;&#125; 看代码很容易知道，文本的指针是只增不减的，而且只在失配且匹配深度大于0的时候递归处理失配情况。但如何精确分析算法复杂度呢？ 算法复杂度分析这个算法的分析属于平摊分析。引入一个变量k，k=2*i-j。观察下面的代码： 1234567while(j&lt;m &amp;&amp; i&lt;n)&#123; if(0&gt;j || T[i]==P[j])&#123; i++;j++; // k加1 &#125;else&#123; j = next[j]; // j至少减一，i不变，那么k至少加1 &#125;&#125; 由上述注释分析得出：k单调递增。k的最大值是2*n+1，而k是迭代次数的上界，所以算法最坏时间是：2*n+1，所以这是一个O(n)的算法。同理可得算出next表的时间复杂度是O(m)。所以总的算法复杂度是O(m+n)。]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[蓄水池算法]]></title>
    <url>%2Fblog%2F2019%2F01%2F15%2F%E8%93%84%E6%B0%B4%E6%B1%A0%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[蓄水池算法(Reservoir Sampling)这个算法真的很奇妙，它的核心是一个数学证明。外延，或者说应用场景是： $C_n^k$，也就是从大小为n的样本集中随机取k个不同的样本 流式数据，或者说无法直接根据索引拿到数据（更加不可能一遍加载到内存） 算法描述算法的描述其实很简单：维基百科：水塘抽样 1234567问题描述：从包含n个不同的项目的集合S中随机选取k个不同的样本。算法：从S中取首k个放入[水塘]中对每个S[j]项（j&gt;=k，数组从0开始）：true随机产生一个范围从0到j的整数rtrue若r&lt;k则把水塘中的第r项换成S[j]项最后得到的水塘就是抽样结果 这个算法保证了每一项最后可能存在于水塘中的概率都是一样的。 单看算法，你肯定不知道为什么是等概率，其实数学证明并不难，请看下面的证明： 数学证明我们把样本分为两类： 一类是首k个，它们一开始就在水塘中 一类是其他，它们一开始并不在水塘中 我们发现两个简单的逻辑： 对于水塘中的样本，只要随机数不选到该样本，该样本就不会被替换 水塘的某个项一旦被替换，就不可能再回到水塘，不会出现被替换掉，然后再回到水塘的局面，这样就保证了问题不会进一步变得复杂。所以：某个项被保留的概率 = 被选中到水塘的概率 * 后续不被替换的概率 分类讨论，首k个样本最终存在于水塘中的概率，和其余样本最终存在于水塘中的概率： 首k个样本，随便选一个做研究对象。被选中到水塘的概率为：1。（数组从1开始）从j=k+1开始考虑替换，第一次不被替换的概率是$\frac{k}{k+1}$，第二次不被替换的概率是$\frac{k+1}{k+2}$，第三次…，一直到最后一次不被替换的概率是$\frac{n-1}{n}$。所以该项被保留的概率 = $1\times\frac{k}{k+1}\times\frac{k+1}{k+2}\times\frac{k+2}{k+3}\times\cdots\times\frac{n-1}{n}=\frac{k}{n}$ 一开始不在水塘中的那一部分，随便选一个做研究对象。被选中到水塘的概率为：$\frac{k}{j}$，后续不被替换的概率$\frac{j}{j+1}$，一直到$\frac{n-1}{n}$。所以该项被保留的概率 = $\frac{k}{j}\times\frac{j}{j+1}\times\cdots\frac{n-1}{n}=\frac{k}{n}$ 到此我们就证明了所以样本最终存在于水塘中的概率都是$\frac{k}{n}$，这也完全符合了我们的数学期望。 代码弄个流式数据我们这里没有条件，只能用伪代码模拟一下： 1234567891011121314151617181920public Data[] reservoirSampling(int k, DataStream dataStream)&#123; Data[] reservoir = new int[k]; // init pool for(int i=0;i&lt;reservoir.length;i++)&#123; reservoir[i] = dataStream.getCurrentData(); dataStream.toNext(); &#125; Random random = new Random(); for(int i=k;!dataStream.isFinish();i++)&#123; int d = random.nextInt(i+1); if(d&lt;k)&#123; reservoir[d] = dataStream.getCurrentData(); &#125; dataStream.toNext(); &#125; return reservoir;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[自己写json解释器]]></title>
    <url>%2Fblog%2F2019%2F01%2F10%2F%E8%87%AA%E5%B7%B1%E5%86%99Json%E8%A7%A3%E9%87%8A%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言最近发现自己似乎除了公司的项目外，基本没什么别的项目。有一个gitbook正在制作（严格来说并不是项目）：leetcode刷题笔记。最近一直在语雀上看阮一峰的每周分享，在第四期中看到这个：Douglas Crockford 的名片。想来想去，觉得可以做几个解析器，比如json解析器，markdown解析器，正则表达式解析器等等，然后可以回过头再去看看编译原理，夯实基础。 说干就干，先深入了解一下json，并看看别人如何实现json的解析。 https://www.json.org/ https://zhuanlan.zhihu.com/p/28049617 json知识json（JavaScript Object Notation，JavaScript对象记法），是一种数据交换语言（data-interchange format，也就是在传输数据的时候用的标记语言）。相比XML更加简洁易读。尽管json脱胎于JavaScript，但json已经是独立于语言的文本格式了。常见的应用场景有：WEB开发，NoSql数据库。 json的结构有两种： 键值对。在其他语言中，又叫做：object（对象），record（记录），struct（结构体），dictionary（字典），hash table（哈希表），keyed list（键列），associative array（关联数组）。 数组。 对于具体的值而言，有七种： 其中true、false、null这三种都是极其容易解析的，这里就不展示铁路图。下面展示一下string和number的铁路图。 string： string只有两种特殊情况，且都比较简单： 遇到\且后面是u，那么说明接下来的4个字节是一组的，组成一个unicode编码。 遇到\且后面不是u，那么只对后面紧跟的一个字节转义。 number： 这个图其实也很简单，首先是有负号或者没负号（如果是正数，不用写正号）；然后是数字部分，要么是0，要么是非0开头的一串数字。然后是小数点，然后是小数部分，然后是指数部分。 开始写代码代码地址：json解析器（java版）在json中解析一个值只需要看第一个字符就知道了，json的解析不需要先做tokenize。我们先对json字符串进行trim()操作，去除掉首位多余的空白符。我们使用一个全局变量index，来记录读到哪个位置了。使用ignoreWhiteSpace()方法来略过空白符。 123456789101112private void ignoreWhiteSpace() throws Exception &#123; while (index &lt; json.length()) &#123; if (json.charAt(index) &lt;= ' ') &#123; index++; &#125; else &#123; break; &#125; &#125; if (index &gt;= json.length()) &#123; throw new Exception("illegal json string, while parsing value ArrayIndexOutOfBounds"); &#125;&#125; 先针对模式进行匹配： 1234567891011121314151617181920212223private Object parseValue() throws Exception &#123; ignoreWhiteSpace(); switch (json.charAt(index)) &#123; case '&#123;': return parseObject(); case '[': return parseArray(); case 'n': case 'N': return parseNull(); case 't': case 'T': return parseTrue(); case 'f': case 'F': return parseFalse(); case '"': case '\'': return parseString(); default: return parseNumber(); &#125;&#125; 当遇到一个{就代表接下来是一个键值对结构；当遇到一个[就知道接下来是一个数组结构。代码很清晰这里就不做解释了。我们看每种模式下的处理方法：先挑最简单的，null、true、false的解析： 1234567891011121314151617181920212223242526private Object parseNull() throws Exception &#123; if (json.substring(index, index + 4).equals("null")) &#123; index += 4; return null; &#125; else &#123; throw new Exception("illegal json string, while parsing null"); &#125;&#125;private Boolean parseTrue() throws Exception &#123; if (json.substring(index, index + 4).equals("true") || json.substring(index, index + 4).equals("True")) &#123; index += 4; return true; &#125; else &#123; throw new Exception("illegal json string, while parsing true"); &#125;&#125;private Boolean parseFalse() throws Exception &#123; if (json.substring(index, index + 5).equals("false") || json.substring(index, index + 5).equals("False")) &#123; index += 5; return false; &#125; else &#123; throw new Exception("illegal json string, while parsing false"); &#125;&#125; 是不是很简单呢？我这里对首字母的大小写做了兼容，实际上官方的json规定是必须小写。然后我们看看string的解析： 123456789101112131415161718private String parseString() throws Exception &#123; char firstChar = json.charAt(index); index++; int recordIndex = index; for (; index &lt; json.length() &amp;&amp; json.charAt(index) != firstChar; index++) &#123; if (json.charAt(index) == '\\') &#123; if (json.charAt(index + 1) == 'u') &#123; index += 5; &#125; else &#123; index++; &#125; &#125; &#125; if (json.charAt(index) != firstChar) &#123; throw new Exception("illegal json string, while parsing string"); &#125; return json.substring(recordIndex, index++);&#125; 这里同样对单引号的字符串做了兼容，官方标准是必须用双引号。可以看到其实代码非常简单，遇到反斜杠就转义，并跳过转义的部分就行了。然后我们看看number的解析，虽然我们把parseNumber()放在了default分支中，但其实合法的number的开头必须是在字符集：-、0~9里面。 12345678910111213141516171819202122232425262728private Object parseNumber() throws Exception &#123; ignoreWhiteSpace(); int recordIndex = index; boolean hasDot = false; while (index &lt; json.length() &amp;&amp; isNumberChar(json.charAt(index))) &#123; if(json.charAt(index)=='.')&#123; hasDot = true; &#125; index++; &#125; ignoreWhiteSpace(); return hasDot?Double.parseDouble(json.substring(recordIndex, index)):Integer.parseInt(json.substring(recordIndex, index));&#125;private Boolean isNumberChar(char c) &#123; return numChars.get(c) != null || c &lt;= '9' &amp;&amp; c &gt;= '0';&#125;private Map&lt;Character, Boolean&gt; numChars = new HashMap&lt;&gt;();public Object parse(String json) throws Exception &#123; char[] chars = &#123;'-', '+', 'e', 'E', '.'&#125;; for (char c : chars) &#123; numChars.put(c, true); &#125; this.json = json.trim(); return parseValue();&#125; 在这段代码中，我只对number的字符集进行了校验，字符集包括：-、+、e、E、.以及0~9。所以它可以兼容+05这样的数字。最后我们解析两种基本结构，这两种结构都可以包含子json对象，可想而知里面肯定要递归调用parseValue。 12345678910111213141516171819202122232425262728293031323334353637383940private Map parseObject() throws Exception &#123; index++; ignoreWhiteSpace(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); while (index &lt; json.length() &amp;&amp; json.charAt(index) != '&#125;') &#123; String key = parseString(); ignoreWhiteSpace(); if (json.charAt(index++) != ':') &#123; throw new Exception("illegal json string, while parsing :"); &#125; Object value = parseValue(); map.put(key, value); ignoreWhiteSpace(); if (json.charAt(index) == ',') &#123; index++; &#125; ignoreWhiteSpace(); &#125; if (json.charAt(index++) != '&#125;') &#123; throw new Exception("illegal json string, while parsing object"); &#125; return map;&#125;private List parseArray() throws Exception &#123; index++; ignoreWhiteSpace(); List&lt;Object&gt; arrayList = new ArrayList&lt;&gt;(); while (index &lt; json.length() &amp;&amp; json.charAt(index) != ']') &#123; arrayList.add(parseValue()); if (json.charAt(index) == ',') &#123; index++; &#125; ignoreWhiteSpace(); &#125; if (json.charAt(index++) != ']') &#123; throw new Exception("illegal json string, while parsing array"); &#125; return arrayList;&#125; 写到这儿，一个简单且完整的json解析器就完成了。代码中需要注意的是index的增加，解析完了一个部分，就要加一。 如果有任何问题或者建议欢迎联系我，：1479001484]]></content>
      <categories>
        <category>动手实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[$\lim\limits_{x\rightarrow 0} \frac{\sin x}{x} = 1$的证明]]></title>
    <url>%2Fblog%2F2019%2F01%2F07%2F%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9E%81%E9%99%90%E7%9A%84%E8%AF%81%E6%98%8E%2F</url>
    <content type="text"><![CDATA[高数中的第一个证明，可能就是这个$\lim\limits_{x\rightarrow 0} \frac{\sin x}{x} = 1$的证明了。下面给出这个极限的证明，用到了解析几何（作图法）。 作图工具 Geometry 如图我们可以看到，有一个单位圆，圆心为 $A$ ，线段 $CE$ 的长度等于 $\sin x$，线段 $CB$ 是 弦（我们令他等于 $a$），弧 $\overset{\frown} {CB}$ 的长度就是 $x$，线段DB的长度等于 $\tan x$。 它们的长度的大小关系我们很容易得出： $\sin x &lt; a$，因为三角形的直角边小于斜边 $a &lt; x$，因为两点之间线段最短 $x &lt; \tan x$，这个略微不那么直接，可以用面积法（通过比较面积继而得到表达式中两个未知数的大小关系），扇形 $CAB$ 的面积：$\frac{1}{2} \cdot 1 \cdot x$ ，三角形 $\triangle DAB$ 的面积：$\frac{1}{2} \cdot 1 \cdot \tan x$ 。而 $CAB$ 的面积小于 $DAB$ 的面积。所以得到 $x &lt; \tan x$ 由此我们得到不等式：$\sin x &lt; x &lt; \tan x$ (当 $x&gt;0$ )，同时除以 $\sin x$，得到：$1 &lt; \frac{x}{\sin x} &lt; \frac{1}{\cos x}$。 当 $x x &gt; \tan x$，同时除以 $\sin x$（除以负数要变号），得到：$1 &lt; \frac{x}{\sin x} &lt; \frac{1}{\cos x}$。 令 $x\rightarrow 0^{-}$，由夹逼定理得到左极限 $\lim\limits_{x\rightarrow 0^{-}} \frac{\sin x}{x} = 1$ 令 $x\rightarrow 0^{+}$，由夹逼定理得到右极限 $\lim\limits_{x\rightarrow 0^{+}} \frac{\sin x}{x} = 1$ 最终可以得到：$\lim\limits_{x\rightarrow 0} \frac{\sin x}{x} = 1$ （左右极限都等于1）]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[js实现sleep方法的最佳实践]]></title>
    <url>%2Fblog%2F2018%2F11%2F22%2Fjs%E5%AE%9E%E7%8E%B0sleep%E6%96%B9%E6%B3%95%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[setTimeout是异步的，跟其他语言里的sleep和delay并不一样，不能阻塞住程序。上网查了之后发现js没有自带的sleep方法，那么如何自己实现sleep方法呢？ What is the JavaScript version of sleep()? 1234567891011function sleep(ms) &#123; return new Promise(resolve =&gt; setTimeout(resolve, ms));&#125;async function demo() &#123; console.log('Taking a break...'); await sleep(2000); console.log('Two seconds later');&#125;demo(); async await 表达式会暂停当前 async function 的执行，等待 Promise 处理完成。若 Promise 正常处理(fulfilled)，其回调的resolve函数参数作为 await 表达式的值，继续执行 async function。 若 Promise 处理异常(rejected)，await 表达式会把 Promise 的异常原因抛出。 另外，如果 await 操作符后的表达式的值不是一个 Promise，则返回该值本身。 如果你对箭头函数不了解，可以先去了解一下箭头函数。 这里利用了Promise对象。有了Promise对象，就可以将异步操作以同步操作的流程表达出来，避免了层层嵌套的回调函数。 123456789const promise = new Promise(function(resolve, reject) &#123; // ... some code if (/* 异步操作成功 */)&#123; resolve(value); &#125; else &#123; reject(error); &#125;&#125;) Promise本身是一个容器，这个对象里面有两个回调方法和三种状态： 回调方法：resolve（此函数的作用是：将Promise对象的状态从“未完成”变为“成功”，即从pending变为fulfilled，并将value作为操作的结果返回出去）和reject（此函数的作用是：将将Promise对象的状态从“未完成”变为”失败“，即从pending变为rejected，并将value作为操作的结果返回出去）三种状态：pending（进行中）、fulfilled（已成功）和rejected（已失败）。 12345promise.then(function(value) &#123; // success&#125;, function(error) &#123; // failure&#125;); then方法可以接受两个回调函数作为参数。第一个回调函数是Promise对象的状态变为resolved（也就是fulfilled）时调用，第二个回调函数是Promise对象的状态变为rejected时调用。其中，第二个函数是可选的，不一定要提供。这两个函数都接受Promise对象传出的值作为参数。 JavaScript是单线程的JavaScript Promise：简介 JavaScript生成一个对象var a = new Object; JavaScript继承机制Javascript继承机制的设计思想 阮一峰这篇文章并没有将彻底，他少了一个例子： 123456789101112131415161718192021222324252627function DOG(name)&#123; this.name = name; &#125; DOG.prototype = &#123; species : '犬科' &#125;; var dogA = new DOG('大毛'); var dogB = new DOG('二毛'); DOG.prototype.species = '猫科';// console.log(dogA.species); // 猫科// console.log(dogB.species); // 猫科 dogA.species = "犬科" dogA.__proto__.species = "hhhhh" console.log(dogA.species); // 猫科 console.log(dogB.species); // 猫科 如果真的想理解，应该从对象的内存模型入手。 JavaScript作用域let是局部声明的，var是全局声明 JavaScript 单线程与异步]]></content>
      <categories>
        <category>编程语言</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程珠玑系列笔记 -- 第二章 啊哈！算法]]></title>
    <url>%2Fblog%2F2018%2F11%2F06%2F%E7%BC%96%E7%A8%8B%E7%8F%A0%E7%8E%91%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B02%2F</url>
    <content type="text"><![CDATA[本书的另一个中心思想显而易见：良好的算法是程序性能提升的关键。 下面还是通过探讨几个实例，来领会一下算法的重要性。 三个问题A. 给定一个最多包含40亿个随机排列的32位整数的顺序文件，找出一个不在文件中的32位整数(在文件中至少缺失一个这样的数 - - 为什么? )。在具有足够内存的情况下，如何解决该问题?如果有几个外部的“临时”文件可用，但是仅有几百字节的内存，又该如何解决该问题? 至少缺失一个这样的数是因为：32位无符号整数的表示范围是0 到 4,294,967,295，比40亿大：。如果有足够的内存，可以采用第一章的位图表示法，需要的内存是：4 000 000 000/8 = 500 000 000，500MB的内存。而且我们需要使用二分查找来加速查找过程，顺序遍历500MB的空间是很慢的。使用二分查找对这种量大的数据集是非常重要的手段，但 二分查找的基础是数据集有序。所以初看这里是没法直接使用二分法的，但是如果我们这样想：32位整数的每一位不是0就是1，我们按照第1位划分的话，就可以划分出两个集合（需要遍历全部数据一遍），如果某个集合小于 $2^{31}$ 个数就选中成为我们下一次划分的对象（如果两个集合都小于 $2^{31}$ 就随便选一个），直到我们得到一个空集，而这个空集中本来应该存在的那些数，就是缺失的数了。在划分集合的时候，我们实际上要把数据存到硬盘中，可以使用buffer来减少IO次数。最坏时间复杂度是一个等比数列： n+\frac{1}{2}n+\cdots+1 = 2n可见这里的二分法并没有起到logN的效果。需要遍历的二分法还算什么二分法呢？但庆幸的是，我们至少可以解决这一题。 B. 将一个n元一维向量左旋转i个位置。例如，当n=8且i=3时，向量abcdefgh旋转为defghabc。简单的代码使用一个n元的中间向量在n步内完成该工作。你能否仅使用数十个额外字节的存储空间，在正比于n的时间内完成向量的旋转？ 方法1：将前i个元素复制到一个临时空间，余下的n-i个元素向左移i个位置，最后将最初的i个元素从临时空间复制到x中余下的位置。时间复杂度：2i+(n-i)=n+i，也就是O(n)；空间复杂度：i，也就是O(n)。 方法2：使用类似方法1的办法，但只使用一个元素大小的临时空间，每次只移动一位，总共需要移动i次。时间复杂度：(n+1)*i，也就是O(n^2)；空间复杂度：O(1)。 方法3：杂技算法。第一步：移动x[0]到临时变量t，然后移动x[i]到x[0]，x[2i]到x[i]，依此类推（将x中的所有下标对n取模），直至返回到取x[0]中的元素，此时改为从t取值然后终止过程。第二步：如果该过程没有移动全部元素，就从x[1]开始再次进行移动（执行第一步的算法操作），直到所有的元素都已经移动为止。 这个算法的核心思想应该是这样的：将该数组序列看成是一个环状队列，每次执行第一步的算法都可以使一组元素落到它们最终的位置上，而又不影响到其它元素。 第二步执行的次数是GCD(n,i)（n和i的最大公约数）。这样一来我们就不用记录元素是否移动过这个状态了，直接就可以知道循环多少次。 该算法的时间复杂度：n+GCD(n,i)，也就是O(n)。空间复杂度：O(1)。 这个算法虽然表现不错，但是不便于理解。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;using namespace std;int gcd(int a, int b)&#123; return a%b?gcd(b, a%b): b;&#125;int a[20];void acrobat()&#123; int n=20, i=6; int temp; for(int j=0;j&lt;gcd(n,i);j++)&#123; temp = a[j]; int count=0; while(1)&#123; if(i*(count+1)%n == 0)&#123; a[j+i*count%n] = temp; break; &#125;else&#123; a[j+i*count%n] = a[j+i*(count+1)%n]; count++; &#125; &#125; &#125;&#125;int main()&#123; for(int i=0;i&lt;20;i++)&#123; a[i] = i; &#125; acrobat(); cout &lt;&lt; "out" &lt;&lt; endl; for(int i=0;i&lt;20;i++)&#123; cout &lt;&lt; a[i] &lt;&lt; endl; &#125; return 0;&#125; 方法4：递归算法。旋转向量x其实就是交换向量ab的两段，得到向量ba。这里a代表x中的前i个元素。假设a比b短，将b分为$b_l$和$b_r$，使得$b_r$具有与a相同的长度。交换a和$b_r$，也就将$ab_l b_r$转换为$b_r b_l a$。序列a此时已处于其最终的位置，因此现在的问题就集中到交换b的部分。由于新的问题与原来的问题具有相同的形式，我们可以递归解决。 1234567891011121314151617181920212223//分别从i和j位置开始，交换k个元素inline void swap(int a[], int i, int j, int k)&#123; for(int p=0;p&lt;k;p++)&#123; int temp = a[i+p]; a[i+p] = a[j+p]; a[j+p] = temp; &#125;&#125;//从i位置开始，处理左leni，右lenj的旋转void first(int a[], int i, int leni, int lenj)&#123; if(leni == lenj)&#123; swap(a, i, i+leni, leni); return; &#125; if(leni&lt;lenj)&#123; swap(a, i, i+lenj, leni); first(a, i, leni, lenj-leni); &#125;else&#123; swap(a, i, i+leni, lenj); first(a, i+lenj, leni-lenj, lenj); &#125;&#125; 方法5：三次翻转: $(a^r b^r)^r = ba$。从ab开始，首先对a求逆，得到$a^r b$，然后对b求逆，得到$a^r b^r$。最后对整体求逆，得到$(a^r b^r)^r$，此时恰好就是ab。 123reverse(0, i-1) /* cbadefgh */reverse(i, n-1) /* cbahgfed */reverse(0, n-1) /* defghabc */ 123456789101112131415//从i位置开始，到j位置结束(包含j)，翻转这一段的a中的元素inline void reverse(int a[], int i, int j)&#123; for(int k=0;k&lt;(j+1-i)/2;k++)&#123; int temp = a[k+i]; a[k+i] = a[j-k]; a[j-k] = temp; &#125;&#125;//i位置是b段的开始，总长度nvoid res(int a[], int i, int n)&#123; reverse(a, 0, i-1); reverse(a, i, n-1); reverse(a, 0, n-1);&#125; C. 给定一个英语字典，找出其中的所有变位词集合。例如，“pots”、“stop”、“tops”互为变位词，因此每一个单词都可以通过改变其他单词中字母的顺序来得到。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《编程珠玑》</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编程珠玑系列笔记 -- 第一章 开篇]]></title>
    <url>%2Fblog%2F2018%2F11%2F05%2F%E7%BC%96%E7%A8%8B%E7%8F%A0%E7%8E%91%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B01%2F</url>
    <content type="text"><![CDATA[本书的中心思想：对实例研究的深入思考不仅有趣，而且可以获得实际的益处。 规律和智慧都隐藏在实例之中，而我们通过实例来窥探它们。实例是道的载体。 开篇明确问题，一旦问题明确，这场战役就成功了90%。 确定用户的真实需求是程序设计的根本。 简单的程序通常比具有相同功能的复杂程序更可靠、更安全、更健壮、更高效，而且易于实现和维护。因为简单的程序往往更具有概括性、更抽象、更能洞悉问题的本质。 具体问题具体分析A：怎样给一个磁盘文件排序？B：为什么非要自己写排序程序呢？为什么不用系统提供的排序程序呢？A：我需要在一个大系统中排序。由于不明的技术原因，我不能使用系统中的文件排序程序。B：需要排序的内容是什么？文件中有多少条记录？每条记录的格式是什么？A：文件最多包含1千万条记录，每条记录都是7位的整数。B：等一下，既然文件这么小，何必非要在非要在磁盘上进行排序呢？为什么不在内存里进行排序呢？A：尽管机器有许多兆字节的内存，但排序功能只是大系统中的一部分，所以估计到时候只有1MB的内存可用。B：你还能告诉我其他一些与记录相关的信息吗？A：每条记录都是7位的正整数，再无其他相关数据。每个整数最多出现一次。 实际上问了这么多，提问者都没有主动将自己的问题无保留的告诉被求助对象，反而是被求助对象耐心的一点一点询问。问题的真实背景是这样的： 在美国，电话号码由3位区号后再跟7位数字组成，拨打含免费区号800（当时只有这一个号码）的电话是不收费的。这位程序员正在开发这类数据库处理系统的一小部分，需要排序的整数就是免费电话号码。输入文件是电话号码列表，号码重复出现算出错。期望的输出文件是以升序排列的电话号码列表。应用背景同时定义了相应的性能需求。当与系统的会话时间较长时，用户大约每小时请求一次有序文件，并且在排序未完成之前什么都做不了。因此，排序最多只允许执行几分钟，10秒钟是比较理想的运行时间。 准确的问题描述输入： 一个最多包含n个正整数的文件，每个数都小于n，其中n=$10^7$。如果在输入文件中有任何整数重复出现就是致命错误。没有其他数据与该整数相关联。 输出： 按升序排列的输入整数的列表。 约束： 最多有（大约）1MB的内存可用，有充足的磁盘存储空间。运行时间最多几分钟，运行时间为10秒钟就不需要再优化了。 程序设计传统的排序有归并排序、快速排序，一般人想到的都是使用一个4字节的int型来表示数据，但1000万的数据就需要40MB的内存，所以需要至少40趟排序，需要读取输入文件至少40次，这将会是非常大的开销。 很显然，我们真正要做的应该是压缩数据表示，如果能让所有数据一次读入内存（仅1MB）就好了。考虑到这一题的特殊性，我们使用长度为1000万位的位图来表示所有数据，每个整数都只占1bit，可以说是极限的数据表示法了。这样一来我们只需要125万个字节，也就是1.25MB内存。满足了一次读入内存的要求。 这种数据表示，利用了该问题的三个在排序问题中不常见的属性： 输入数据限制在相对较小的范围内 数据没有重复 对每条记录而言，除了单一整数外，没有任何其他关联数据 排序伪代码： 12345678910/* phase 1: initialize set to empty */for i = [0, n) bit[i]=0/* phase 2: insert present elements into the set */for each i in the input file bit[i]=1/* phase 3: write sorted output */for i = [0, n) if b[i]==1 write i on the output file 时间-空间折中与双赢： 随着现在存储器的空间越来越大，我们往往倾向于用空间换时间的算法，这种折中非常常见。但减少程序的运行空间需求也会减少其运行时间。空间需求的减少之所以会导致运行时间的减少，有两个原因：需要处理的数据变少了，意味着处理这些数据所需的时间也变少了。同时可以将这些数据保存在内存中而不是磁盘上，进一步避免了磁盘访问的时间（IO是巨大的开销，网络传递数据是更大的开销）。当然了，只有在设计远非最优的时候，才有可能时空双赢。 折中在所有工程领域都存在。例如，汽车设计者可能会通过增加沉重的部件，用行驶里程的减少来换取更快的加速。但双赢是更好的结果。我对自己驾驶过的一辆小轿车做过一番研究，我观察到：“轿车基本结构重量的减少会使各底盘部件的重量进一步减少—甚至消除了对某些底盘部件的需求，例如转向助力系统。” 真实代码1234567891011121314151617181920212223242526272829303132#define BITSPERWORD 32#define SHIFT 5#define MASK 0x1F#define N 10000000int a[N/BITSPERWORD];void set(int i)&#123; a[i&gt;&gt;SHIFT] |= (1&lt;&lt;(i&amp;MASK));&#125;void clear(int i)&#123; a[i&gt;&gt;SHIFT] &amp;= ~(1&lt;&lt;(i&amp;MASK));&#125;void test(int i)&#123; return a[i&gt;&gt;SHIFT] &amp; (1&lt;&lt;(i&amp;MASK));&#125;int main()&#123; int i; for(i=0;i&lt;N;i++)&#123; clear(i); &#125; while(scanf("%d", &amp;i)!=EOF)&#123; set(i); &#125; for(i=0;i&lt;N;i++)&#123; if(test(i))&#123; printf("%d\n", i); &#125; &#125; return 0;&#125; 对移位操作熟悉的话就会知道，i&gt;&gt;SHIFT的意思就是i/32。a[i&gt;&gt;SHIFT]也就是定位到i所属的数组单元（每个数组单元4个字节）。而i&amp;MASK的意思是i%32，然后(1&lt;&lt;(i&amp;MASK))就定位了i在所属的数组单元中的具体位置。 但我们手上没有数据来测试我们的代码是否正确，测试数据可以用随机生成的办法产生，具体会在《编程珠玑第12章 取样问题》中讲解。 接下来我们来看看习题： 习题 如果不缺内存，如何使用一个具有库的语言来实现一种排序算法以表示和排序集合？ 使用C语言的标准库函数qsort: 1234567891011121314151617int intcompare(int *x, int *y)&#123; return *x - *y;&#125;int a[10000000];int main()&#123; int n=0; while(scanf("%d",&amp;a[n])!=EOF)&#123; n++; &#125; qsort(a, n, sizeof(int), intcompare); for(int i=0;i&lt;n;i++)&#123; printf("%d", a[i]); &#125; return 0;&#125; 使用C++的标准模板库中的容器set来完成相同任务： 123456789101112int main()&#123; set&lt;int&gt; S; int i; set&lt;int&gt;::iterator j; while(cin &gt;&gt; i)&#123; S.insert(i); &#125; for(j=S.begin();j&lt;S.end();j++)&#123; cout &lt;&lt; *j &lt;&lt; endl; &#125; return 0;&#125; 如何使用位逻辑运算（例如与、或、移位）来实现位向量？ 代码上面已经给出：真实代码 运行时效率是设计目标的一个重要组成部分，所得到的程序需要足够高效。在你自己的系统上实现位图排序并度量其运行时间。该时间与系统排序的运行时间以及习题1中排序的运行时间相比如何？假设n为10000000，且输入文件包含10000000个整数。 如果认真考虑了习题3，你将会生成小于n且没有重复的k个整数的问题。最简单的方法就是使用前k个正整数。这个极端的数据集合将不会明显地改变位图方法的运行时间，但是可能会歪曲系统排序的运行时间。如何生成位于0至n-1之间的k个不同的随机顺序的随机整数？尽量使你的程序简短且高效。 那个程序员说他有1MB的内存空间可用，但是我们概要描述的代码需要1.25MB内存。他可以不费力的索取到额外的空间。如果1MB空间是严格的边界，你会推荐如何处理呢？你的算法的运行时间又是多少？ 使用位图表示1 000万个数需要1000万个位，或者说125万字节。考虑到没有以数字0或1打头的电话号码，我们可以将内存需求降低为100万字节。另一种做法是采用两趟算法，首先使用5 000 000/8=625 000个字的存储空间来排序0~4 999 999之间的整数，然后在第二趟排序5 000 000~9 999 999的整数。k趟算法可以在kn的时间开销和n/k的空间开销内完成对最多n个小于n的无重复正整数的排序。 如果那个程序员说的不是每个整数最多出现一次，而是每个整数最多出现10次，你又如何建议他呢？你的解决方案如何随着可用存储空间总量的变化而变化？ 如果每个整数最多出现10次，那么我们就可以使用4位的半字节来统计它出现的次数。利用习题5的答案，我们可以使用10 000 000/2个字节在1趟内完成对整个文件的排序，或使用10 000 000/2k个字节在k趟内完成对整个文件的排序。 使用更多的空间来换取更少的运行时间存在一个问题：初始化空间本身需要消耗大量的时间。说明如何设计一种技术，在第一次访问向量的项时将其初始化为0。你的方案应该使用常量时间进行初始化和向量访问，使用的额外空间应正比于向量的大小。因为该方法通过进一步增加空间来减少减少初始化的时间，所以仅在空间很廉价、时间很宝贵且向量很稀疏的情况下才考虑使用。 借助于两个额外的n元向量from、to和一个整数top，from和to也都没有初始化过，top初始化为0。当我们访问索引为i的data元素，想要知道data[i]有没有初始化过。如果from[i]&lt;top且to[from[i]]=i，那么说明已经初始化过。to数组就是用来记录已经访问过哪些data元素的，实际上to数组可以是一个动态数组)。 下面代码实现对data[i]的首次访问： 1234from[i] = top;to[top] = i;data[i] = 0;top++; 在成本低廉的隔日送达时代之前，商店允许顾客通过电话订购商品，并在几天后上门自取。商店的数据库使用客户的电话号码作为其检索的主关键字（客户知道他们自己的电话号码，而且这些关键字几乎都是唯一的）。你如何组织商店的数据库，以允许高效的插入和检索操作？ 商店将纸质订单表格放在10x10的箱数组中，使用客户电话号码的最后两位作为散列索引。当客户打电话下订单时，将订单放到适当的箱中。当客户来取商品时，销售人员顺序搜索对应箱中的订单—这就是经典的“用顺序搜索来解决冲突的开放散列”。电话号码的最后两位数字非常接近于随机，因此是非常理想的散列函数，而最前面的两位数字则很不理想 - - 为什么?一些市政机关使用类似的方案在记事本中记录信息。 在20世纪80年代早期，洛克希德公司加利福尼亚州桑尼维尔市工厂的工程师每天都要将许多由计算机辅助设计（CAD）系统生成的图纸从工厂送到位于圣克鲁斯市的测试站。虽然仅有40公里远，但使用汽车快递服务每天都需要一个多小时的时间（由于交通阻塞和山路崎岖），花费100美元。请给出新的数据传输方案并估计每一种方案的费用。 两地的计算机原先是通过微波连接的，但是当时测试站打印图纸所需的打印机却非常昂贵。因此，该团队在主厂绘制图纸，然后拍摄下来并通过信鸽把35毫米的底片送到测试站，在测试站进行放大并打印成图片。鸽子来回一.次需要45分钟，是汽车所需时间的一半，并且每天只需要花费几美元。在项目开发的16个月中，信鸽传送了几百卷底片，仅丢失了两卷(当地有鹰，因此没有让信鸽传送机密数据)。由于现在打印机比较便宜，因此可以使用微波链路解决该问题。 载人航天的先驱们很快就意识到需要在外太空的极端环境下实现顺利书写。民间盛传美国国家宇航局(NASA)花费100万美元研发出了一种特殊的钢笔来解决这个问题。那么，前苏联又会如何解决相同的问题呢? 看过三傻大闹宝莱坞的都知道，前苏联用的是铅笔，但铅笔的碎屑由于失重漂浮在空中会是很麻烦的问题。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《编程珠玑》</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[熟练使用JetBrains家的IDE]]></title>
    <url>%2Fblog%2F2018%2F11%2F04%2F%E7%86%9F%E7%BB%83%E4%BD%BF%E7%94%A8JetBrains%E5%AE%B6%E7%9A%84IDE%2F</url>
    <content type="text"><![CDATA[通用快捷键 格式化代码（reformat code）:win: ctrl+alt+Lmac: command+option+L 在一行的任意位置使用： shift + enter，新建下一行并跳到下一行。 善用代码自动补全功能，变量名和方法名等可以用 enter 补全。导入包可以用 alt + enter。 上下移动代码，ctrl+shift+上下键 Android Studio 生成函数注释：你在方法前输入/**然后一回车，自动帮你生成方法和参数的注释。 Intellj Idea快速打出常用语句： sout：System.out.println(); psvm： 123public static void main(String[] args) &#123; &#125; 使用IDE的右键中的生成Getter Setter选项自动生成Getter Setter，使用toString自动生成toString。 跳转到接口：ctrl+b； 跳转到实现类：ctrl + alt +B 上面这个按钮可以快速的在目录树中定位到当前类所在的路径 ctrl+alt+t]]></content>
      <categories>
        <category>工具</category>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是回调]]></title>
    <url>%2Fblog%2F2018%2F11%2F04%2F%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%9E%E8%B0%83%2F</url>
    <content type="text"><![CDATA[打个比方，有一家旅馆提供叫醒服务，但是要求旅客自己决定叫醒的方法。可以是打客房电话，也可以是派服务员去敲门，睡得死怕耽误事的，还可以要求往自己头上浇盆水。这里，“叫醒”这个行为是旅馆提供的，相当于库函数，但是叫醒的方式是由旅客决定并告诉旅馆的，也就是回调函数。而旅客告诉旅馆怎么叫醒自己的动作，也就是把回调函数传入库函数的动作，称为登记回调函数（to register a callback function）。 在回调中，我们利用某种方式，把回调函数像参数一样传入中间函数。可以这么理解，在传入一个回调函数之前，中间函数是不完整的。换句话说，程序可以在运行时，通过登记不同的回调函数，来决定、改变中间函数的行为。这就比简单的函数调用要灵活太多了。 什么是回调函数？我们绕点远路来回答这个问题。编程分为两类：系统编程（system programming）和应用编程（application programming）。所谓系统编程，简单来说，就是编写库；而应用编程就是利用写好的各种库来编写具某种功用的程序，也就是应用。系统程序员会给自己写的库留下一些接口，即API（application programming interface，应用编程接口），以供应用程序员使用。所以在抽象层的图示里，库位于应用的底下。当程序跑起来时，一般情况下，应用程序（application program）会时常通过API调用库里所预先备好的函数。但是有些库函数（library function）却要求应用先传给它一个函数，好在合适的时候调用，以完成目标任务。这个被传入的、后又被调用的函数就称为回调函数（callback function）。打个比方，有一家旅馆提供叫醒服务，但是要求旅客自己决定叫醒的方法。可以是打客房电话，也可以是派服务员去敲门，睡得死怕耽误事的，还可以要求往自己头上浇盆水。这里，“叫醒”这个行为是旅馆提供的，相当于库函数，但是叫醒的方式是由旅客决定并告诉旅馆的，也就是回调函数。而旅客告诉旅馆怎么叫醒自己的动作，也就是把回调函数传入库函数的动作，称为登记回调函数（to register a callback function）。如下图所示（图片来源：维基百科）： 可以看到，回调函数通常和应用处于同一抽象层（因为传入什么样的回调函数是在应用级别决定的）。而回调就成了一个高层调用底层，底层再回过头来调用高层的过程。（我认为）这应该是回调最早的应用之处，也是其得名如此的原因。回调机制的优势从上面的例子可以看出，回调机制提供了非常大的灵活性。请注意，从现在开始，我们把图中的库函数改称为中间函数了，这是因为回调并不仅仅用在应用和库之间。任何时候，只要想获得类似于上面情况的灵活性，都可以利用回调。这种灵活性是怎么实现的呢？乍看起来，回调似乎只是函数间的调用，但仔细一琢磨，可以发现两者之间的一个关键的不同：在回调中，我们利用某种方式，把回调函数像参数一样传入中间函数。可以这么理解，在传入一个回调函数之前，中间函数是不完整的。换句话说，程序可以在运行时，通过登记不同的回调函数，来决定、改变中间函数的行为。这就比简单的函数调用要灵活太多了。请看下面这段Python写成的回调的简单示例： even.py 123456789#回调函数1#生成一个2k形式的偶数def double(x): return x * 2 #回调函数2#生成一个4k形式的偶数def quadruple(x): return x * 4 callback_demo.py 1234567891011121314151617181920212223from even import *#中间函数#接受一个生成偶数的函数作为参数#返回一个奇数def getOddNumber(k, getEvenNumber): return 1 + getEvenNumber(k) #起始函数，这里是程序的主函数def main(): k = 1 #当需要生成一个2k+1形式的奇数时 i = getOddNumber(k, double) print(i) #当需要一个4k+1形式的奇数时 i = getOddNumber(k, quadruple) print(i) #当需要一个8k+1形式的奇数时 i = getOddNumber(k, lambda x: x * 8) print(i) if __name__ == "__main__": main() 运行callback_demp.py，输出如下： 123359 上面的代码里，给getOddNumber传入不同的回调函数，它的表现也不同，这就是回调机制的优势所在。值得一提的是，上面的第三个回调函数是一个匿名函数。 编程思想中有一条很重要的原则就是：尽量少的改动已有的代码，原因有很多，比如改动一个被多处使用的函数有可能会对很多地方造成影响。所以我们就要 尽量让我们的代码灵活起来，可重复用起来，Java的反射就起到了这个作用，Spring框架最重要的作用就是让灵活的部分变成配置，程序动态加载配置就能改变代码的行为。回调也同样是在贯彻这一思想。可重用 是编程思想的精髓之一，甚至所有的抽象就都是为了这一目的，无论是变量、函数、对象、数据结构、库、API都是把死的代码变成活的，把不能重复使用的代码变成可以重复使用的代码。阿里和蚂蚁八荣八耻 其实面向对象的语言中传递回调函数并不是直接传函数，而是传对象，然后使用对象就可以引用到里面的回调方法了。 易被忽略的第三方通过上面的论述可知，中间函数和回调函数是回调的两个必要部分，不过人们往往忽略了回调里的第三位要角，就是中间函数的调用者。绝大多数情况下，这个调用者可以和程序的主函数等同起来，但为了表示区别，我这里把它称为起始函数（如上面的代码中注释所示）。之所以特意强调这个第三方，是因为我在网上读相关文章时得到一种印象，很多人把它简单地理解为两个个体之间的来回调用。譬如，很多中文网页在解释“回调”（callback）时，都会提到这么一句话：“If you call me, I will call you back.”我没有查到这句英文的出处。我个人揣测，很多人把起始函数和回调函数看作为一体，大概有两个原因：第一，可能是“回调”这一名字的误导；第二，给中间函数传入什么样的回调函数，是在起始函数里决定的。实际上，回调并不是“你我”两方的互动，而是ABC的三方联动。有了这个清楚的概念，在自己的代码里实现回调时才不容易混淆出错。另外，回调实际上有两种：阻塞式回调和延迟式回调。两者的区别在于：阻塞式回调里，回调函数的调用一定发生在起始函数返回之前；而延迟式回调里，回调函数的调用有可能是在起始函数返回之后。这里不打算对这两个概念做更深入的讨论，之所以把它们提出来，也是为了说明强调起始函数的重要性。网上的很多文章，提到这两个概念时，只是笼统地说阻塞式回调发生在主调函数返回之前，却没有明确这个主调函数到底是起始函数还是中间函数，不免让人糊涂，所以这里特意说明一下。另外还请注意，本文中所举的示例均为阻塞式回调。延迟式回调通常牵扯到多线程。 阿里和蚂蚁八荣八耻以动手实践为荣，以只看不练为耻。 以打印日志为荣，以出错不报为耻。 以局部变量为荣，以全局变量为耻。 以单元测试为荣，以手工测试为耻。 以代码重用为荣，以复制粘贴为耻。 以多态应用为荣，以分支判断为耻。 以定义常量为荣，以魔法数字为耻。 以总结思考为荣，以不求甚解为耻。 以可配置为荣 ，以硬编码为耻 以可互备为荣 ，以单点为耻 以可无状态为荣 ，以有状态为耻 以可随便重启为荣 ，以不能迁移为耻 以整体交付为荣，以部分交付为耻 以标准化为荣，以特殊化为耻 以自动化运维为荣，以人肉化运维为耻 以无人值守为荣，以人工值班为耻]]></content>
      <categories>
        <category>编程概念</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[精通一款编辑器之sublime text 3]]></title>
    <url>%2Fblog%2F2018%2F11%2F04%2F%E7%B2%BE%E9%80%9A%E4%B8%80%E6%AC%BE%E7%BC%96%E8%BE%91%E5%99%A8%E4%B9%8Bsublime%20text%203%2F</url>
    <content type="text"><![CDATA[编辑器常用功能 格式化代码：格式化代码可以让你不用管代码的格式，可以放肆的写程序，你可以少敲很多空格，不用关心代码的格式问题，机器给出的代码格式风格统一且漂亮，一键解决你的格式问题，真是提高码代码效率的非常重要的功能。 查找文件：查找文件是在集成开发的时候非常重要的功能，当文件多起来的时候，快速定位到文件可以节省很多时间，甚至有时候文件实在太多，你只能通过查找的方式找到那个文件。 正则全文件查找和替换：轻松让你更改全局变量和配置，这是一个必须的功能，没有它简直无法想象工作量有多大。 代码收缩和扩展：代码太长怎么办，收缩和扩展啊。 安装卸载插件 cmd+shift+p：打开命令板，输入install，点击：Package Control: Install Package选项，然后搜索你想要的插件。 卸载请在命令板输入：remove，点击：Package Control: Remove Package选项。其实卸载无非就是两个词：remove和uninstall，多试试就行了。 打开命令板之后什么都不想干，怎么关闭命令板呢？其实很简单，再按一次打开命令板的快捷键就行了，开关都用同一个键或者按钮（术语叫：toggle，可开可关），这是比较通用设计理念。 vue 插件 vue-syntax-highlight：可以让.vue文件高亮。 HTML-CSS-JS Prettify：可以格式化这三种语言的代码，特别是单文件的vue，非常需要这个来同时格式化三种语言。不过需要配置一下。工具栏路径：Sublime Text -&gt; Preferences -&gt; Package Settings -&gt; HTML/CSS/JS Prettify -&gt; Plugin Options - Default，然后搜索：allowed_file_extensions，给这个配置项添加一个vue即可，要注意的是有四处有这个配置项，分别是html、css、js、json，如果你想它们全都能格式化，自然是要全都添加vue，但实验证明只加html里面就行了，如果在其他几个里面加反而引起了冲突。然后格式化代码的快捷键是什么呢？同样也有配置文件的，工具栏路径：Sublime Text -&gt; Preferences -&gt; Package Settings -&gt; HTML/CSS/JS Prettify -&gt; Keyboard Shortcuts - Default，可以看到： 12345678910111213141516[&#123; &quot;keys&quot;: [&quot;super+shift+h&quot;], &quot;command&quot;: &quot;htmlprettify&quot;&#125;, &#123; &quot;keys&quot;: [&quot;super+alt+h&quot;, &quot;p&quot;], &quot;command&quot;: &quot;htmlprettify_set_prettify_prefs&quot;&#125;, &#123; &quot;keys&quot;: [&quot;super+alt+h&quot;, &quot;o&quot;], &quot;command&quot;: &quot;htmlprettify_set_plugin_options&quot;&#125;, &#123; &quot;keys&quot;: [&quot;super+alt+h&quot;, &quot;k&quot;], &quot;command&quot;: &quot;htmlprettify_set_keyboard_shortcuts&quot;&#125;, &#123; &quot;keys&quot;: [&quot;super+alt+h&quot;, &quot;n&quot;], &quot;command&quot;: &quot;htmlprettify_set_node_path&quot;&#125;] 第一项即为使用这个插件的快捷键，也就是格式化代码的快捷键。 底栏设置显示文件编码在mac osx上一不小心按了cmd+shift+c，文件的存储格式现在变成了GBK格式，当我再按下cmd+s保存时，提示我UTF-8格式的文件不能用GBK格式来保存。怎么解决这个问题呢？首先我想查看这个文件是什么编码，Sublime Text的默认设置是不开启显示编码的，如果想开启，可通过菜单Perference → Settings – User，在打开的配置文件里 ，在大括号后面，增加以下内容： 1234// Display file encoding in the status bar&quot;show_encoding&quot;: true,// Display line endings in the status bar&quot;show_line_endings&quot;: true, 此时保存该配置文件，就能够看到sublime最底下一行会显示文件编码格式了。以上的配置内容在Perference → Setting─Default都是false的。 然后在底栏点击文件编码，点击reopen with encoding，然后选择utf-8，然后cmd+w关闭窗口，然后cmd+shift+t重新打开刚刚关闭的窗口，就一切恢复正常了。]]></content>
      <categories>
        <category>工具</category>
        <category>编辑器</category>
      </categories>
      <tags>
        <tag>编辑器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CSAPP》读书笔记 -- 第4章：处理器体系结构]]></title>
    <url>%2Fblog%2F2018%2F10%2F13%2F%E5%A4%84%E7%90%86%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[阅读这篇文章必须要对汇编码有足够的了解，如果你对IA32汇编码还不够了解，可以先看看这篇文章：程序的机器级表示 Y86指令集体系结构Y86指令集基本上是IA32指令集的一个子集。这个指令集就是我们处理器实现的目标。如下图： IA32的movl指令分成了4个不同指令：irmovl、rrmovl、mrmovl和rmmovl，i表示立即数Immediate，r表示寄存器Register，m表示存储器Memmory。第一个字母表示源，第二个字母表示目的。 这里不实现的功能有： 存储器引用方式是简单的基址+偏移量形式，不支持变址寄存器（second index register）和任何寄存器伸缩（scaling）。如果对操作数的结构不太了解可以看看这个：操作数指示符 和IA32一样不允许从一个存储器直接传送到另一个存储器地址。 不允许立即数传送到存储器 4个整数操作指令：addl、subl、andl、xorl 7个跳转指令：jmp、jle、jl、je、jne、jge、jg。 6个条件传送指令：cmovle、cmovl、cmove、cmovne、cmovge、cmovg。 另外还有：call、ret、pushl、popl，halt指令停止指令执行。IA32中有一个与之相当的指令hlt，IA32的应用程序不允许使用这条指令，因为它会导致整个系统暂停运行。对于Y86来说，执行halt指令会导致处理器停止，并将状态码设置为HLT。 指令编码与IA32一样使用小端编码。 每条指令的第一个字节表明指令的类型，这个字节分为两部分，每部分4位：高4位是代码（code）部分，低4位是功能（function）部分。代码值为 0~0xB。可以观察到，rrmovl与条件传送指令有同样的代码部分，可以把它看作是一个无条件传送。 寄存器编码如下： 举个例子：用16进制表示指令 rmmvol %esp, 0x12345(%edx)的字节编码。 从上面图中可以看到，rmmovl第一个字节为40，由于%esp是4（占4位），%edx是2（占4位），所以第二个字节是42，最后再加上偏移量 00 01 23 45，小端表示是：45 23 01 00，所以最后得到指令的编码是：404245230100。 指令集的一个重要性质是字节编码必须有唯一解释，任意一个字节序列要么是一个唯一的指令，要么是一个不合法的指令。 相比于IA32，Y86没那么紧凑，IA32对寄存器只用了3位来编码，5位表明指令类型，所以IA32能将出栈入栈放进一个字节里。另外IA32可以将常数值编码成1、2、4字节，Y86总是编码成4字节。 RISC 和 CISC RISC: reduced instruction set computers，精简指令集 CISC: complex instruction set computers，复杂指令集 Y86异常 对于Y86，当遇到这些异常的时候，我们简单的让处理器停止执行指令。在更完善的设计中，处理器通常会调用一个 exception handler（异常处理程序），这个过程被指定用来处理遇到的某种类型的异常，例如放弃程序或调用一个用户自定义的 signal handler（信号处理程序）。 Y86程序12345678910int Sum(int *Start, int Count)&#123; int sum = 0; while (Count) &#123; sum += *Start; Start++; Count--; &#125; return sum; &#125; 可以看到Y86有时候需要两条指令来完成IA32一条指令就能完成的事。然而如果用数组索引来写这个程序，要转换成Y86会很困难，因为Y86没有伸缩寻址。 完整代码如下： 以.开头的是 assembler directive（汇编器命令），命令.pos 0告诉汇编器应该从地址0处开始产生代码。第3、4行使用的Stack标签，在最后有声明，其位置是0x100。第9到13行声明了一个数组，4字节对齐，值分别是：0xd，0xc0，0xb00，0xa000，array标签是起址。 细节问题，pushl %esp（这个指令只能用汇编语言写，C语言无法产生）是先把%esp的值转移到栈，还是先%esp减4再将结果转移到栈，实际上不同版本的intel处理器都会产生不同的结果，所以一个很重要的教训是要保证细节上的一贯性。 逻辑设计和硬件控制语言HCL（Hardware Control Language）逻辑门 组合电路和HCL语言构建一个组合电路有两条限制： 两个或多个逻辑门的输出不能连接在一起。这样会导致线上的信号矛盾，产生不合法的电压或电路故障。 必须是无环的，也就是不能形成回路。 下面是个简单的例子： 用HCL来写这个网的函数就是：bool eq = (a &amp;&amp; b) || (!a &amp;&amp; !b) HCL是用来C语言风格的语法，但这里同C语言不一样，该语句的意思不是执行了一次计算并将结果放入存储器，而是使用一个名字eq来称谓一个表达式。 实际上上面的组合电路就是同或，异或的表达式是：bool eq = (!a &amp;&amp; b) || (a &amp;&amp; !b) 多路复用器（multiplexor，通常称为：MUX）： bool out = (s &amp;&amp; a) || (!s &amp;&amp; b) 字级的组合电路和HCL整数表达式通常我们设计能对字（word）进行操作的组合电路，字级电路中用到的就是HCL整数表达式了。 字级与电路： bool Eq = (A == B); 也可以用异或来实现： 在HCL中，多路复用函数是用情况表达式（case expression）来描述的。情况表达式的通用格式如下： 12345678[ select_1 : expr_1; select_2 : expr_2; . . . select_k : expr_k;] 同C语言的switch语句不同，我们不要求不同的选择表达式之间互斥。从逻辑上讲，这些选择表达式是顺序求值的，且第一个求值为1的情况就会被选中。 字级多路复用电路： 用HCL来描述就是： 1234int Out = [ s: A; 1: B;]; 大多数人第一眼是看不懂这个表达式的，其实里面有个暗含的条件：先执行 s: A; 如果失败（没有输出A）才会再执行 1: B;。而1: B;实际上是!s&amp;&amp;1: B;的简写。没有输出A就已经代表s是0了，那么!s就是1。 四路复用器： 123456int Out4 = [ !s1 &amp;&amp; !s0: A; # 00 !s1 : B; # 01 !s0 : C; # 10 1 : D; # 11]; 第二个表达式可以写成!s1，而不用写的更完整!s1&amp;&amp;s0，是因为另一种可能s0=0已经出现在了第一个选择表达式了，若能到达第二个选择表达式，则s0=1。类似的，第三个表达式可以写成!s0，第四个表达式可以简单的写成1。 来看最后一个例子，假设我们想设计一个逻辑电路来找一组字A、B和C中的最小值，如下图所示： 用HCL来表达： 12345int Min3 = [ A&lt;=B &amp;&amp; A&lt;=C : A; B&lt;=A &amp;&amp; B&lt;=C : B; 1 : C;] 算术逻辑单元（arithmetic/logic unit, ALU） 集合关系 在这个电路中，两位的信号code就可以用来控制对4个数据字A、B、C和D做选择。根据可能的code值，可以用相等测试来表示信号s1和s0的产生： 12bool s1= code==2 || code==3;bool s0= code==1 || code==3; 还有一种更简洁的方式来表示这样的属性：当code在集合{2,3}中s1为1，而code在集合{1,3}中s0为1： 12bool s1= code in &#123;2,3&#125;;bool s0= code in &#123;1,3&#125;; 判断集合关系的通用格式：iexpr in {iexpr1, iexpr2, ... , iexprk} 存储器和时钟组合电路从本质上讲，不存储任何信息，它们只是简单的根据输入信号产生一个输出信号。为了产生时序电路（sequential circuit），也就是有状态并且在这个状态上进行计算的系统，我们必须引入按位存储信息的设备。存储设备都是由同一个时钟控制，时钟是一个周期性信号，决定什么时候要把新值加载到设备中。考虑两类存储器设备： 时钟寄存器（简称寄存器）存储单个位或字。时钟信号控制寄存器加载输入值。 随机访问存储器（简称存储器）存储多个字，用地址来选择该读或该写哪个字。随机访问存储器的例子包括：1.处理器的虚拟存储器系统（由硬件和操作系统结合起来使处理器可以在一个很大的地址空间内访问任意的字，硬件上包括由缓存、内存、外存）。2.寄存器文件，在此，寄存器标识符作为地址。在IA32或Y86处理器中，寄存器文件有8个程序寄存器（%eax、%ecx等）。 正如我们看到的那样，在说到硬件和机器级编程时，“寄存器”这个词是有两个不同的意思的。需要避免歧义的时候，我们分别称呼这两类寄存器为：硬件寄存器和程序寄存器。 下图说明了硬件寄存器是如何工作的： 寄存器是作为电路不同部分中的组合逻辑之间的屏障。我们的Y86处理器会用时钟寄存器保存程序计数器（PC），条件码（CC）和程序状态（Stat）。 下图展示了一个典型的寄存器文件： 寄存器文件有两个读端口，一个写端口。每个端口都有一个地址输入，地址是图4-4中的寄存器标识符。这样一个多端口随机访问存储器允许同时进行多个读和写操作。 虽然寄存器文件不是组合电路，因为它有内部存储。不过在我们的实现中，从寄存器文件中读数据就好像它是一个以地址为输入、数据为输出的一个组合逻辑块。当srcA或srcB被设成某个寄存器ID时，在一段延迟之后，存储在相应寄存器上的值就会出现在valA或valB上。 向寄存器文件写入字是由时钟信号控制的，控制方式类似于将值加载到时钟寄存器。每次时钟上升时，输入valW上的值会被写入dstW指明的寄存器上。当dstW设为特殊的ID值0xF时，不会写任何程序寄存器。 由于寄存器文件既可以读又可以写，一个很自然的问题就是：如果我们同时读和写一个程序寄存器会发生什么？答案简单明了：我们会看到一个旧值到新值的变化。所以在设计处理器的时候要把这个问题考虑进去。 我们的处理器有一个随机访问存储器，如下图所示： 同寄存器文件一样，从存储器中读的操作方式类似于组合逻辑：如果我们在输入address上提供一个地址，并将write控制信号设置为0，那么经过一些延迟之后，存储在那个地址上的值会出现在输出data上。如果地址超出了范围，error信号会置为1，否则就是0。 写存储器是由时钟控制的：我们将address设置为期望的地址，将data in设置为期望的值，而write设置为1。然后我们控制时钟时，只要地址是合法的，就会更新相应的地址中的值，如果是非法地址，error就会置为1。 Y86的顺序实现将处理组织成阶段 取指（fetch）：从存储器取指令，地址为PC所指的地址。从指令中抽取出指令指示符字节的两个四位部分，称为icode（指令代码）和ifun（指令功能）。 译码（decode）：译码阶段从寄存器文件最多读入两个操作数，得到值valA和valB（如果是两个的话）。通常，它读入指令rA和rB字段指明的寄存器，不过有些指令是读寄存器%esp的。 执行（execute） 访存（memory）：访存阶段可以将数据写入存储器，或者从存储器读出数据。读出的值为valM。 写回（write back）：写回阶段最多可以写两个结果到寄存器文件。 更新PC（PC update）：将PC设置成下一条指令的地址。 处理器无限循环，执行这些阶段。在我们简化的实现中，发生任何异常时，处理器就会停止。比如：它执行halt指令或非法指令，或者它试图读或者写非法地址。在更完整的设计中，处理器会进入异常处理模式，开始执行由异常的类型决定的特殊代码。 在硬件上复制逻辑块的成本比软件中有重复代码的成本要大得多。而且在硬件系统中处理许多特殊情况和特性要比用软件来处理困难得多。 我们面临的一个挑战是将每条不同指令所需要的计算放入到上述的通用框架中。我们会使用图4-17中所示的代码来描述不同的Y86指令的处理。图4-18到4-21描述了不同Y86指令在各阶段是怎样处理的。 让我们看一个具体的例子，图4-17中的第三条指令： 图4-17中第五条指令： 图4-17中第六条指令： 图4-21表明了三类控制转义指令的处理：各种跳转、call和ret。 图4-17中第8条指令： 图4-17中第13条指令： SEQ硬件结构]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《CSAPP》</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《CSAPP》读书笔记 -- 第3章：程序的机器级表示]]></title>
    <url>%2Fblog%2F2018%2F10%2F08%2F%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BA%A7%E8%A1%A8%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[从编译C语言文件说起1$ gcc -01 -o p p1.c p2.c 使用了gcc命令来编译，也可以简单写作：cc。 优化层级为1，1级是最低的，层级越高程序优化越好，但增加了编译时间，也使调试变得更难，且跟源程序差异很大不便于理解。 编译的流程是： 预处理器（preprocessor）把诸如：#include、#define、#if、#else、#elif、#ifdef、#endif等预编译指令替换掉。 编译器（compiler）把.c源文件编译成.s的汇编代码文件。 汇编器（assembler）把汇编代码文件转换成相应的二进制目标文件.o，目标文件已经是机器码了，只是没有填入全局变量的地址。 链接器（linker），把多目标文件和库函数链接在一起，形成可执行文件。 instruction set architecture，ISA，指令集体系结构，定义了处理器状态，指令的格式和行为。intel的指令集包括32位的：IA32，以及64位的：x86-64。 编译器做了整个编译流程的大部分工作，汇编代码几乎就是机器码的供人阅读版。所以看懂汇编代码是关键。 IA32程序代码和C语言很不相同，一些在C语言下看不到的处理器状态可以在这里看到： 程序计数器（program counter，PC，也叫：instructor pointer，IP）在IA32中叫：%eip，指出下一条指令在内存中的位置 整数寄存器，可以用来保存数据 状态码寄存器，可以用来实现条件控制代码如：if和while 浮点寄存器，用来计算浮点数 例子1234567int accum = 0;int sum(int x, int y)&#123; int t = x + y; accum += t; return t;&#125; 如果要看到编译出的汇编代码，可以使用-S选项： 1$ gcc -01 -S code.c 这样就会使编译流程停留在 预处理-&gt;编译 阶段，而不是继续进行接下来的汇编和链接，生成的文件是：.s汇编文件。编译后的汇编代码中会包含如下代码： 12345678sum: pushl %ebp movl %esp, %ebp movl 12(%ebp), %eax addl 8(%ebp), %eax addl %eax, accum popl %ebp ret 这段代码中的每一句都对应一个机器指令，比如pushl这句的意思就是把寄存器%ebp的内容push到程序栈（内存中）上。在汇编代码里所有的局部变量都不见了，全局变量还可以看到，因为编译器还没有决定这个变量在内存中的存储位置。 如果我们使用-c选项，GCC就会既编译又汇编： 1$ gcc -01 -c code.c 这样就生成了目标文件code.o，在800bytes的code.o文件中，有17bytes是对应上面的汇编代码的： 155 89 e5 8b 45 0c 03 45 08 01 05 00 00 00 00 5d c3 可以使用反汇编将难懂的目标文件代码转成汇编代码： 1$ objdump -d code.o IA32指令的长度是1到15字节，越常用的，操作数越少的指令越短，反之则越长。 给定一个开始的位置，只对应一种机器指令，比如只有pushl %ebp指令是以55开头的 反汇编只需要根据目标文件就可以翻译出汇编文件 反汇编出来的文件跟直接编译的汇编文件有些不一样，比如所有指令都省略了后缀l。l是大小指示符，而大多数情况下是可以省略l的。 头两个属性跟哈夫曼编码的原理是一致的，可以说这是一种通用的编码原则，第一条用来保证节省字节空间，第二条则保证编码的唯一性。 生成真正可执行的文件还需要链接操作，而且必须包含main函数。假设我们的main.c文件如下： 123int main()&#123; return sum(1, 3);&#125; 我们可以使用如下指令生成可执行文件： 1$ gcc -01 -o prog code.o main.c prog文件增长到了9123bytes，因为它不仅包含我们写的代码，而且包含了用来开始和结束的程序，以及与操作系统进行交互的程序。 可以看到第6行，全局变量在链接的时候定址。 汇编代码的格式假设我们有一个C语言文件simple.c： 12345int simple(int *xp, int y) 2&#123; int t = *xp + y; *xp = t; return t;&#125; 可以得到如下汇编代码： 12345678910111213141516.file &quot;simple.c&quot; .text.globl simple .type simple, @functionsimple: pushl %ebp movl %esp, %ebp movl 8(%ebp), %edx movl 12(%ebp), %eax addl (%edx), %eax movl %eax, (%edx) popl %ebp ret .size simple, .-simple .ident &quot;GCC: (Ubuntu 4.3.2-1ubuntu11) 4.3.2&quot; .section .note.GNU-stack,&quot;&quot;,@progbits 所有以.开头的行都是用来指导汇编器和链接器的，我们不用去管。而这段代码的大概意思如下： 123456789simple: pushl %ebp 保存帧指针 movl %esp, %ebp 创建新的帧指针 movl 8(%ebp), %edx 从内存中读取xp movl 12(%ebp), %eax 从内存中读取y addl (%edx), %eax *xp+y=t movl %eax, (%edx) 把t存到xp指向的地址中 popl %ebp 重新获取帧指针 ret 返回 这段代码对%ebp和%esp的操作涉及到了程序栈模型，看不懂很正常，文章下面会有讲解的。 ATT和intel汇编格式ATT即AT&amp;T，是贝尔实验室旗下的公司。 GCC和OBJDUMP默认生成ATT格式的汇编代码，微软和因特尔的编程工具则默认生成intel格式的汇编代码。 使用如下命令可以让GCC生成intel格式的代码： 1$ gcc -01 -S -masm=intel code.c 两者的区别如下： intel代码省略了用来指定大小的后缀，比如使用mov而不是movl intel代码省略了寄存器前面的%，比如使用esp而不是%esp intel代码用了不同的方式来描述内存地址，比如使用DWORD PTR [ebp+8]而不是8(%ebp) intel代码多操作数指令的操作数顺序跟ATT相反 由于是由16bit架构扩展到32bit架构的，intel管16bit数据类型叫：word，32bit数据类型叫：double words，64bit数据类型叫：quad words。 数据格式 访问数据IA32 CPU 包含了8个寄存器，每个有32bit存储空间，用来存储整形值以及指针。 x86-64则进一步扩展了这些寄存器： 前六个寄存器称为通用寄存器，有其特定的用途： %rax(%eax) 用于做累加，过程调用返回值 %rcx(%ecx) 用于计数 %rdx(%edx) 用于保存数据 %rbx(%ebx) 用于做内存查找的基础地址 %rsi(%esi) 用于保存源索引值 %rdi(%edi) 用于保存目标索引值 操作数指示符 有三种类型的操作数，立即数(Imm)、寄存器值(Reg)、内存值(Mem)。 mov指令 pushl %ebp指令等价于下面的指令： 12subl $4,%esp 减小栈指针movl %ebp,(%esp) 把%ebp中的数据写到%esp指向的内存中 popl %eax指令等价于下面的指令： 12movl (%esp), %ebp 把%esp指向的内存地址中的值读到%eax中addl $4, %esp 增加栈指针 算术和逻辑操作load effective address，leal指令，实际上是一个movl指令。 多个操作数的指令，注意一下两个操作数的顺序即可 位移操作位移的值是用一个单字节来表示，且数值只能是0到31，所以这个字节只有低五位才会被考虑。 扩展乘除指令 控制状态码使用单比特的状态码来描述算数和逻辑运算的状态。最常用的状态码如下： CF: carry flag 进位符，用来表示最高位的进位。通常用来检测无符号运算的溢出 ZF: zero flag，零标志符，最近的操作产生了0 SF: sign flag，符号位，最近的操作产生了负数 OF: overflow flag，溢出符，补码溢出，正负都可以，表示有符号溢出 举个例子：t=a+b，a、b、t都是整形数。 1234CF: (unsigned)t&lt;(unsigned)a 无符号溢出ZF: (t==0) 零SF: (t&lt;0) 负数OF: (a&lt;0 == b&lt;0) &amp;&amp; (t&lt;0 != a&lt;0) 有符号溢出 OF的表达式也可以写作：(a]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《CSAPP》</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《CSAPP》读书笔记 -- 第2章：浮点数原理（小专题）]]></title>
    <url>%2Fblog%2F2018%2F09%2F27%2F%E6%B5%AE%E7%82%B9%E6%95%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[浮点数的作用：区别于整形数，用来表示小数。可以用来表示很大的数，或者非常接近0的小数，或者近似的做实数计算，浮点数的一般形式：$x\times 2^y$。 IEEE（pronounced “Eye-Triple-Eee”）浮点数标准。 rounding：when a number cannot be represented exactly in the format and hence must be adjusted upward or down- ward。可以翻译为：舍入。 十进制的小数表示：$dm d{m-1} \cdots d1 d_0 . d{-1} d{-2} \cdots d{-n}$，写成数学表达式： d = \sum_{i=-n}^m 10^i \times d_i相应的，二进制也可以写成这种形式： b = \sum_{i=-n}^m 2^i \times b_i 浮点数的表示IEEE浮点数的格式：$V = (-1)^s \times M \times 2^E$ s是符号（Sign），s为0时是正，s为1时是负 M是有效数字（Significand，即 尾数） E是 指数，Exponent，也叫 幂数，阶码 隐含的 基数 是2 下图是浮点数的内存分布模型，首先是符号域，然后是指数域，最后是分数域： 符号位s个，符号位只需要一位，s=1 指数位k个，指数域 $exp=e_{k-1}\cdots e_1 e_0$，用来计算指数E 分数为n个，分数域 $frac=f_{n-1}\cdots f_1 f_0$，用来计算有效数字M 32位浮点数（单精度，float型）中，s=1，k=8，n=23；64位浮点数（双精度，double型）中，s=1，k=11，n=52。 正常化值（Normalized Values）当 $exp$ 域既不是全0，也不是全1的时候，就是正常化值。 $E = e - Bias$，其中 $e$ 就是 $exp$ 域：$e_{k-1}\cdots e_1e_0$ 的值（除去全0和全1之后，取值范围是1到$2^k-2$），$Bias=2^{k-1}-1$（单精度的时候是127，双精度的时候是1023），那么 $E$ 的取值范围，单精度的时候是：-126 ~ +127，双精度的时候是：-1022 ~ +1023，其实 $E$ 的算法就是 移码 的计算方法。 $M = 1+f$，$0\le f\lt 1$，内存里只记录f，而1作为一个前导值计算时候再加上，所以f是分数域 $frac$ 的 $0.f_{n-1}\cdots f_1f_0$ 这种形式 非正常化值（Denormalized Values）当指数域全0，就是非正常化格式。 在这种情况下，指数值是 $E = 1-Bias$，也就是固定了，有效数字值 $M = f$ 也就是没有前导1了。这个格式下可以表示0，因为正常化值中，一定有： $M\ge 1$，所以我们无法在正常化值格式下表示0。当符号位是0，有效数字 $M=f=0$，我们得到的就是+0.0，当符号位是1的时候就是-0.0。 除了可以表示0，这个格式的另一个作用就是用来表示非常接近0的数。 特殊值（Special Values）当指数域全1的时候，且分数域是全0，就表示无穷大，如果符号域为0，表示 $+\infty$，如果符号位是1，则表示 $-\infty$。无穷大可以作为溢出的结果，当我们用两个很大的数相乘，或者除以0； 当指数域全1，且分数域并非全0的时候，结果可以叫做：NaN（Not a Number的简写），这种值用来表示不能用实数或者无穷大表示的计算结果，比如计算：$\sqrt{-1}$ 或者 $\infty - \infty$。 下图是在数轴上的显示： 可以看到非正常化值集中在0附近，正常化值散布在整个数轴的空间，特殊值则只表示两个无穷值。 下图是浮点数三种类型的光滑衔接： 看完浮点数的设计和构造我们可以发现以下这些特点： 从编码上有效数字域采用了无符号整数编码，而指数域采用了移码编码 非正常化值均匀分布在0附近 正常化值的间隔随着 $2^E$ 变大而逐渐变大，也就是精度逐渐降低 精度是分组的，以 $2^E$ 增加1为一组，每组有 $2^n$ 个数（n是有效数字域的位数） 最高精度就是两个非正常化值的间隔，最低精度是最大的一组正常化值的相邻两数的间隔。 非正常化值按照精度只占一组，正常化值的数量是非正常化值数量的 $2^{k}-2$ 倍 正常化值的第一组的精度和非正常化值的精度一样，也就是实现了无缝衔接 浮点数的计算舍入 Rounding维基百科 各种Rounding合集图 浮点数中使用的是：舍入到最近的偶数，因为舍入结果放大和缩小各占50%的概率，这样就可以防止最终结果偏大或者偏小。 下面是把浮点数舍入到小数点后两位数： $10.00011_2(2\frac{3}{32})$ -&gt; $10.00_2(2)$ 不到一半，正常四舍五入$10.00110_2(2\frac{3}{16})$ -&gt; $10.01_2(2\frac{1}{4})$ 超过一半，正常四舍五入$10.11100_2(2\frac{7}{8})$ -&gt; $11.00_2(3)$ 正好一半，保证最后一位是偶数，所以向上舍入$10.10100_2(2\frac{5}{8})$ -&gt; $10.10_2(2\frac{1}{2})$ 正好一半，保证最后一位是偶数，所以向下舍入 浮点数加减运算基本性质 相加可能产生 infinity 或者 NaN 不满足交换律，不满足结合律（因为舍入会造成精度上的损失） 加上0等于原来的数 除了 infinity 和 NaN，每个元素都有对应的相反数 除了 infinity 和 NaN，满足单调性，即 $a\ge b \rightarrow a+c\ge b+c$ 1234567891011121314#include &lt;iostream&gt;using namespace std;int main()&#123; // 浮点数加法不满足交换律 cout &lt;&lt; 3.14 + 1e20 - 1e20 &lt;&lt; endl; cout &lt;&lt; 1e20 - 1e20 + 3.14 &lt;&lt; endl; // 浮点数加法不满足结合律 cout &lt;&lt; (3.14 + 1e20) - 1e20 &lt;&lt; endl; cout &lt;&lt; 3.14 + (1e20 - 1e20) &lt;&lt; endl; return 0;&#125; 运行结果: 123403.1403.14 具体细节设两个浮点数 $x$ 和 $y$： \begin{cases} x=(-1)^{s_x} M_x 2^{E_x} \\ y=(-1)^{s_y} M_y 2^{E_y} \end{cases}则浮点数加减运算结果为： x\pm y = \left((-1)^{s_x}M_x 2^{E_x-E_y} \pm (-1)^{s_y}M_y \right)2^{E_y} 对阶：首先要把指数位（阶码）调成一样，并相应的使M移位，由于有效域左移会引起最高有效位丢失，误差大，所以采用右移，此时阶码要增加。所以对阶原则是：小阶向大阶看齐。 有效数加减：简单的无符号数字相加减。 规格化：有效数求和结果可能大于1，那么就向右规格化：尾数右移1位，阶码加1。 舍入：对于右移出去的位，采取舍入 检查阶码是否溢出： 阶码下溢：运算结果为非规格化数 阶码上溢：置溢出标志 浮点数加减实例$x=3.14, y=2.718$ 求 $z=x+y$。 首先算出 $x$ 和 $y$ 的内存表示： $x = 3+0.14$，3的二进制表示是11，0.14的二进制要稍微计算一下，我们让0.14不断的乘以2（也就是左移），得到的整数位部分就是其二进制值的一位： 12345670.14 * 2 = 0.28 00.28 * 2 = 0.56 00.56 * 2 = 1.12 10.12 * 2 = 0.24 0... 我们可以写个程序来完成这个计算工作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;using namespace std;// 获取整形数的位数int getDigits(int num)&#123; int count = 1; while(num/10&gt;0)&#123; num %= 10; count++; &#125; return count;&#125;/** * 获取小数的二进制表示 * @params precision 二进制表示精确到多少位 * @params num 小数的整数表示 */char* getFloatBitset(int precision, int num)&#123; char* res = new char[precision]; int digits = getDigits(num); int mod = pow(10, digits); char printFormat[50]; sprintf(printFormat,"%%0.%df",2); // cout &lt;&lt; printFormat &lt;&lt;endl; for(int i=0;i&lt;precision;i++)&#123; printf(printFormat, num*1.0/mod); cout &lt;&lt; " * 2 = "; num &lt;&lt;= 1; if(num &gt;= mod)&#123; printf(printFormat, num*1.0/mod); cout &lt;&lt; " 1" &lt;&lt; endl; num %= mod; res[i] = '1'; &#125;else&#123; printf(printFormat, num*1.0/mod); cout &lt;&lt; " 0" &lt;&lt; endl; res[i] = '0'; &#125; &#125; return res;&#125;/** * 获取小数的二进制表示 * @params precision 二进制表示精确到多少位 * @params num 浮点型小数 * @params digits 输入的时候浮点型小数的位数 */char* getFloatBitset2(int precision, float num, int digits)&#123; char* res = new char[precision]; int mod = pow(10,digits); // cout&lt;&lt;mod&lt;&lt;endl; char printFormat[50]; sprintf(printFormat,"%%0.%df",2); for(int i=0;i&lt;precision;i++)&#123; printf(printFormat, num); cout &lt;&lt; " * 2 = "; num*=2; num = round(num*mod)/mod; if(num &gt;= 1)&#123; printf(printFormat, num); cout &lt;&lt; " 1" &lt;&lt; endl; num -= 1; res[i] = '1'; &#125;else&#123; printf(printFormat, num); cout &lt;&lt; " 0" &lt;&lt; endl; res[i] = '0'; &#125; &#125; return res;&#125;int main(int argc, char* argv[])&#123; // char* res = getFloatBitset(atoi(argv[1]), atoi(argv[2])); char* res = getFloatBitset2(atoi(argv[1]), atof(argv[2]), atoi(argv[3])); cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; 上面代码保存成：float2Bitset.cpp文件，然后编译，并使用： 12$ g++ -o float2Bitset float2Bitset.cpp$ ./float2Bitset 23 0.14 2 小数位精确到23位的话，3.14的定点浮点数表示是：11.00100011110101110000101。 转成浮点数，首先规格化M，那么整体要右移1位，指数是1，由 $E = e-Bias$，$E=1$, $Bias=127$ 得 $e=128$，也就是：1000 0000。 最终3.14的内存表示是： \underbrace{0}\_{Sign}~\underbrace{10000000}\_{Exponent}~~\underbrace{10010001111010111000011}\_{Significand}同样的方法得到2.718的内存表示： \underbrace{0}\_{Sign}~\underbrace{10000000}\_{Exponent}~~\underbrace{01011011111001110110110}\_{Significand}这两个数恰好是同阶的，那么就不需要对阶操作了。将M相加，但这个数太长了看着眼花，我们写个加法程序： 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;// 将两个相同位数的二进制数相加char* addBitset(char num1[], char num2[], int length)&#123; char* res = new char[length+2]; res[length+1] = '\0'; int carry = 0; for(int i=length-1;i&gt;=0;i--)&#123; res[i+1] = num1[i]-'0'+num2[i]-'0'+carry+'0'; carry = 0; if(res[i+1]&gt;'1')&#123; res[i+1] -= 2; carry = 1; &#125; &#125; if(carry)&#123; res[0]='1'; &#125;else&#123; res[0]='0'; &#125; return res;&#125;int main(int argc, char* argv[])&#123; int i=0; while(argv[1][i]!='\0')&#123; i++; &#125; cout &lt;&lt; i &lt;&lt;endl; char* res = addBitset(argv[1], argv[2], i); cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; 上述代码保存成：addBitset.cpp，编译并使用该程序： 12$ g++ -o addBitset addBitset.cpp$ ./addBitset 10010001111010111000011 01011011111001110110110 相加结果等于：0 11101101110100101111001，最高位没有产生进位，这里用了一个0来代替，但两个前导1相加产生了进位，所以还需要对M右归一下，再对指数加1。所以加法结果的浮点数表示是： \underbrace{0}\_{Sign}~\underbrace{10000001}\_{Exponent}~~\underbrace{01110110111010010111101}\_{Significand}这个数的十进制表示的计算方法是：2^2 \times (1+0\times (\frac{1}{2})^1 + 1\times (\frac{1}{2})^2 + 1\times (\frac{1}{2})^3 +1\times (\frac{1}{2})^4+0\times(\frac{1}{2})^5+\cdots) 我们依然采用程序来计算这一长串二进制对应的十进制小数： 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;using namespace std;double bitset2Float(char* num1, int length)&#123; double res = 0.0; int count=1; for(int i=0;i&lt;length;i++)&#123; double temp = (num1[i]-'0')/pow(2,count); // cout &lt;&lt; temp &lt;&lt; endl; res += temp; count++; &#125; return res;&#125;int main(int argc, char* argv[])&#123; int i=0; while(argv[1][i]!='\0')&#123; i++; &#125; double res = bitset2Float(argv[1],i); cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; 上述代码保存为：Bitset2float.cpp，编译并执行： 12$ g++ -o Bitset2float Bitset2float.cpp$ ./Bitset2float 01110110111010010111101 对得到结果：0.4645，$1.4645\times 2^2 = 5.858$，而 $3.14+2.718=5.858$，这就说明我们的计算无误。 算法流程图 这个流程图并不是完美的，真实的浮点数流程图和浮点数计算电路比这个复杂。另外我忘画了一个东西，这个图最后应该加上溢出处理模块，E可能会上溢（当E加1的时候），也可能会下溢（当E减1的时候）。 最后这个流程图中没有对特殊值的判断，比如：$\infty - \infty = NaN$, $\infty + \infty = \infty$, $NaN + 任何数 = NaN$。 了解了浮点数加法的流程之后，最后我们回到最上面说的 浮点数加减法不满足交换律和结合律，从计算细节分析为什么不行。 首先 3.14 的浮点数表示我们已经计算过了，那么 1e20 的浮点数是多少呢？1e20也就是 $10^{20}$，用辗转相除法可以得到其二进制表示。我们这里使用计算器工具 很遗憾的是64bit只能摆的下 $10^{19}$。我试了一下把源程序中的 1e20 换成 1e19 也是同样的结果。所以我们就使用 1e19 来分析这道题。 首先是M规格化，M右移63位，E加63，舍入M，那么 1e19 最终的双精度浮点数表示是：0 10000111110 0001010110001110010001100000100100010011110100000000 小阶向大阶看齐，3.14的阶是1，M需要右移62位，而M的精度才52，可想而知M就是0了。那么 3.14 + 1e19 的结果就是 1e19。1e20就更加不用说了。 浮点数乘除基本性质 相乘可能产生 infinity 或者 NaN 不满足交换律，结合律，分配率（因为溢出会造成程序无法计算出正确的结果） 乘以1会等于原来的数 除了 infinity 和 NaN，满足单调性：$a\ge b \rightarrow a\times c \ge b \times c$ 具体细节设两个浮点数 $x$ 和 $y$ ： \begin{cases} x = \pm M_x 2^{E_x} \\ y = \pm M_y 2^{E_y} \end{cases}则浮点数乘除运算结果是： xy = \pm (M_x\times M_y)2^{E_x\pm E_y} 计算阶码，判断是否溢出 求有效数的乘积 有效数舍入 计算符号位 浮点数还有相当多的细节，可以参考：IEEE 754]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《CSAPP》</category>
      </categories>
      <tags>
        <tag>信息记法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wsl oh my zsh 字符乱码问题]]></title>
    <url>%2Fblog%2F2018%2F09%2F20%2Fwsl%20oh%20my%20zsh%20%E5%AD%97%E4%BD%93%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[安装 oh my zsh首先检查自己有没有zsh： 1cat /etc/shells 如果有的话就下载oh my zsh 设置默认shell1chsh -s /bin/zsh 有可能会遇到设置不成功的问题，那么我们可以手动修改/etc/passwd，找到自己那一条配置信息，把默认shell改成/bin/zsh就OK了。 字体问题-&gt;等一些其他字符可能显示不出来，这是字体导致的。google一下：wsl oh my zsh font，找到：https://github.com/Microsoft/WSL/issues/1517，下载并设置字体为：DejaVuSansMono。 怎么设置字体右键标题栏，进入属性]]></content>
      <categories>
        <category>解决的问题</category>
      </categories>
      <tags>
        <tag>windows环境</tag>
        <tag>wsl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wsl修改右键bash图标]]></title>
    <url>%2Fblog%2F2018%2F09%2F19%2Fwsl%E4%BF%AE%E6%94%B9%E5%8F%B3%E9%94%AEbash%E5%9B%BE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[使用 windows subsystem for linux (简称：WSL) 的时候，遇到一个小问题，在文件管理器中右键，唤出bash，发现图标不对： 点击之后可以看到调用的是哪个程序： google一下：windows 右键图标，搜到百度经验：https://jingyan.baidu.com/article/7c6fb428321b4a80642c90fd.html，照着修改就行了。 如图： 那么改成什么呢？google一下：wsl bash icon，搜到：https://github.com/Microsoft/WSL/issues/1269，然后又在这个页面找到了这个：https://github.com/cmderdev/cmder/issues/1063#issuecomment-401947209 把icon换成： 1C:\Program Files\WindowsApps\CanonicalGroupLimited.UbuntuonWindows_1804.2018.817.0_x64__79rhkp1fndgsc\ubuntu.exe 再点击右键，就能看到这个图标了。 除了修改右键显示的icon，还可以修改右键显示的名字，以及运行的目标程序。 改为： 1C:\Program Files\WindowsApps\CanonicalGroupLimited.UbuntuonWindows_1804.2018.817.0_x64__79rhkp1fndgsc\ubuntu.exe 但发现无法把工作目录定到当前右键的目录，需要加一个run： 1C:\Program Files\WindowsApps\CanonicalGroupLimited.UbuntuonWindows_1804.2018.817.0_x64__79rhkp1fndgsc\ubuntu.exe run]]></content>
      <categories>
        <category>解决的问题</category>
      </categories>
      <tags>
        <tag>windows环境</tag>
        <tag>wsl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Learning SpringBoot2]]></title>
    <url>%2Fblog%2F2018%2F09%2F02%2FLearning-SpringBoot2%2F</url>
    <content type="text"><![CDATA[随着计算机的发展，很多东西都慢慢工具化了，大量简单重复的工作直接交给计算机就好了，留给人们的只是业务逻辑跟架构调优。spring boot 2 就是一个非常好用的Java web集成框架。学习最好的方法就是通过 例子 来领悟和体会到其中抽象的知识（共性）。对于工具的使用则更加强调动手实践。 先参考一下网上的资料： 知乎：Spring Boot要如何学习？ bilibili：【自用】尚硅谷spring boot全套视频教程 第一步快速入门如果对spring boot一点都不了解的话，要先了解一下spring boot是什么，它的发展历程，从而建立起一个简单的印象。可以先看B站的教学视频的前几个概要介绍的视频。然后大致浏览一下需要学习的内容，你会发现都是按模块划分的，比如：工程配置、日志管理、数据库、缓存等等。 有了大概的了解，就可以动手写一个hello world了。 Spring Boot快速入门 使用Intellij中的Spring Initializr来快速构建Spring Boot/Cloud工程 由于我以前做过spring+springMVC+mybatis的项目，所以学习springboot2对我来说是比较轻松的。]]></content>
      <categories>
        <category>后端</category>
        <category>Java web</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《APUE-3rd》 读书笔记 -- File I/O]]></title>
    <url>%2Fblog%2F2018%2F05%2F28%2FAPUE-3rd-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--File-IO%2F</url>
    <content type="text"><![CDATA[前言这章讲的是文件IO，其中有几个非常重要的概念： File Desriptors，文件描述符 current file offset，当前文件偏移量 File Sharing Data Structure，文件共享数据模型 file descriptor flags ，文件描述位 file status flags ，文件状态位 File Descriptors 对内核来说，所有 打开的文件 都使用file descriptor引用。 文件描述符是一个非负整数。当我们打开一个存在的文件或者创建一个新文件，内核返回一个文件描述符给进程。 当我们想要读或者写一个文件，我们通过文件描述符来确定这个文件，文件描述符是被open或者creat返回的，然后作为read或者write的一个参数。 文件描述符都使用尽可能小的非负整数，File descriptors range from 0 through OPEN_MAX−1. 有三个magic number，0代表STDIN_FILENO，1代表STDOUT_FILENO，2代表STDERR_FILENO。虽然这已经是POSIX.1所定义的标准，但为了程序的可读性，还是不建议直接写数字。这三个常量定义在&lt;unistd.h&gt;中。 open and openat FunctionsA file is opened or created by calling either the open function or the openat function. 1234#include &lt;fcntl.h&gt;int open(const char *path, int oflag, ... /* mode_t mode */ );int openat(int fd, const char *path, int oflag, ... /* mode_t mode */ );// Both return: file descriptor if OK, −1 on error 最后一个参数是...，这是ISO C定义剩下的多个参数的方式。对这些函数来说，只有当新文件被创建时，最后一个参数才被使用，后面我们会讲。在这个原型中我们把这个参数写作一个注释。 path这个参数是要打开或者要创建的文件的名字。这个函数有多种操作，定在在oflag参数里。这个参数由下列一个或者多个定义在&lt;fcntl.h&gt;头文件中的常量通过 或(一种逻辑操作) 操作构成： O_RDONLY Open for reading only O_WRONLY Open for writing only O_RDWR Open for reading and writing Most implementations define O_RDONLY as 0, O_WRONLY as 1, and O_RDWR as 2, for compatibility with older programs. 为了兼容老程序，许多实现定义O_RDONLY as 0, O_WRONLY as 1, and O_RDWR as 2。 O_EXEC Open for execute only O_SEARCH Open for search only(applies to directories) The purpose of the O_SEARCH constant is to evaluate search permissions at the time a directory is opened. Further operations using the directory’s file descriptor will not reevaluate permission to search the directory. None of the versions of the operating systems covered in this book support O_SEARCH yet. One and only one of the previous five constants must be specified. The following constants are optional: 上面的五个常量有且只有一个必须被明确。接下来的是可选常量： O_APPEND Append to the end of file on each write. We describe this option in detail in Section 3.11. O_CLOEXEC Set the FD_CLOEXEC file descriptor flag. We discuss file descriptor flags in Section 3.14. O_CREAT Create the file if it doesn’t exist. This option requires a third argument to the open function (a fourth argument to the openat function) — the mode, which specifies the access permission bits of the new file. (When we describe a file’s access permission bits in Section 4.5, we’ll see how to specify the mode and how it can be modified by the umask value of a process.) 创建一个文件，如果不存在。这个操作需要open函数的第三个参数（openat函数的第四个参数）— mode，它明确了这个新文件的访问权限位。（当我们在第4.5章节讨论文件的访问权限位，我们将看到如何明确mode，以及它如何修改进程的umask值。） O_DIRECTORY Generate an error if path doesn’t refer to a directory. O_EXCL Generate an error if O_CREAT is also specified and the file already exists. This test for whether the file already exists and the creation of the file if it doesn’t exist is an atomic operation. We describe atomic operations in more detail in Section 3.11. 如果O_CREAT被使用了且文件已经存在就会生成一个错误。这个常量的作用是检测文件是否存在如果文件不存在就创建，这是一个原子操作。我们将在第3.11章节讨论更多原子操作的细节。 O_NOCTTY If path refers to a terminal device, do not allocate the device as the controlling terminal for this process. We talk about controlling terminals in Section 9.6. 如果这个路径指向的是终端设备，则不将这个设备分配为此进程的控制终端。 O_NONBLOCK If path refers to a FIFO, a block special file, or a character special file, this option sets the nonblocking mode for both the opening of the file and subsequent I/O. We describe this mode in Section 14.2. 如果path指向FIFO（先进先出），一个块特殊文件，一个字符特殊文件，这个选项设置了非阻塞模式为本次的打开操作和后续的I/O操作。 In earlier releases of System V, the O_NDELAY (no delay) flag was introduced. This option is similar to the O_NONBLOCK (nonblocking) option, but an ambiguity was introduced in the return value from a read operation. The no-delay option causes a read operation to return 0 if there is no data to be read from a pipe, FIFO, or device, but this conflicts with a return value of 0, indicating an end of file. SVR4-based systems still support the no-delay option, with the old semantics, but new applications should use the nonblocking option instead. 在早期的System V，有一个O_NDELAY(no delay)符号。这个符号和O_NONBLOCK(nonblocking)选项相似，但他的读操作返回值具有二义性。如果管道，先进先出，或者设备没有数据可读，no-delay选项就会造成read操作返回0，这与end of file造成的返回值0冲突了。虽然基于SVR4的系统还支持这个no-delay选项，但新的应用应该使用nonblocking选项。 O_SYNC Have each write wait for physical I/O to complete, including I/O necessary to update file attributes modified as a result of the write. We use this option in Section 3.14. 使每次write都等物理I/O完成，包括更新文件属性所需要的I/O。 O_TTY_INIT When opening a terminal device that is not already open, set the nonstandard termios parameters to values that result in behavior that conforms to the Single UNIX Specification. We discuss the termios structure when we discuss terminal I/O in Chapter 18. 当打开一个新的终端设备的时候，设置非标准参数 termios。 The following two flags are also optional. They are part of the synchronized input and output option of the Single UNIX Specification (and thus POSIX.1). O_DSYNC Have each write wait for physical I/O to complete, but don’t wait for file attributes to be updated if they don’t affect the ability to read the data just written. 让所有write都等待物理I/O完成，但是不用等文件属性更新，如果不影响刚刚写完的数据的读操作的话。 O_RSYNC Have each read operation on the file descriptor wait until any pending writes for the same portion of the file are complete. 使每个使用文件描述符的的读操作等待，直到对文件的同一部分的所有写操作完成。 Solaris 10 supports all three synchronization flags. Historically, FreeBSD (and thus Mac OS X) have used the O_FSYNC flag, which has the same behavior as O_SYNC. Because the two flags are equivalent, they define the flags to have the same value. FreeBSD 8.0 doesn’t support the O_DSYNC or O_RSYNC flags. Mac OS X doesn’t support the O_RSYNC flag, but defines the O_DSYNC flag, treating it the same as the O_SYNC flag. Linux 3.2.0 supports the O_DSYNC flag, but treats the O_RSYNC flag the same as O_SYNC. The file descriptor returned by open and openat is guaranteed to be the lowest- numbered unused descriptor. This fact is used by some applications to open a new file on standard input, standard output, or standard error. For example, an application might close standard output—normally, file descriptor 1—and then open another file, knowing that it will be opened on file descriptor 1. We’ll see a better way to guarantee that a file is open on a given descriptor in Section 3.12, when we explore the dup2 function. The fd parameter distinguishes the openat function from the open function. There are three possibilities: The path parameter specifies an absolute pathname. In this case, the fd parameter is ignored and the openat function behaves like the open function. The path parameter specifies a relative pathname and the fd parameter is a file descriptor that specifies the starting location in the file system where the relative pathname is to be evaluated. The fd parameter is obtained by opening the directory where the relative pathname is to be evaluated. The path parameter specifies a relative pathname and the fd parameter has the special value AT_FDCWD. In this case, the pathname is evaluated starting in the current working directory and the openat function behaves like the open function. The openat function is one of a class of functions added to the latest version of POSIX.1 to address two problems. First, it gives threads a way to use relative pathnames to open files in directories other than the current working directory. As we’ll see in Chapter 11, all threads in the same process share the same current working directory, so this makes it difficult for multiple threads in the same process to work in different directories at the same time. Second, it provides a way to avoid time-of-check- to-time-of-use (TOCTTOU) errors. openat函数是在最后一个版本的POSIX.1加入的，为了解决两个问题。首先，它给线程以相对路径而非当前路径。我们将在第11章看到，在同一进程中的所有线程共享同一个当前目录，所以要让同一进程中的多线程同时在不同的目录工作是非常困难的。第二，它提供了避免 time-of-check-to-time-of-use（TOCTTOU） 错误。 The basic idea behind TOCTTOU errors is that a program is vulnerable if it makes two file-based function calls where the second call depends on the results of the first call. Because the two calls are not atomic, the file can change between the two calls, thereby invalidating the results of the first call, leading to a program error. TOCTTOU errors in the file system namespace generally deal with attempts to subvert file system permissions by tricking a privileged program into either reducing permissions on a privileged file or modifying a privileged file to open up a security hole. Wei and Pu [2005] discuss TOCTTOU weaknesses in the UNIX file system interface. TOCTTOU错误的意思是，一个调用横叉一脚影响了另一个调用，本来另一个调用应该是一个原子操作。 Filename and Pathname TruncationWhat happens if NAME_MAX is 14 and we try to create a new file in the current directory with a filename containing 15 characters? Traditionally, early releases of System V, such as SVR2, allowed this to happen, silently truncating the filename beyond the 14th character. BSD-derived systems, in contrast, returned an error status, with errno set to ENAMETOOLONG. Silently truncating the filename presents a problem that affects more than simply the creation of new files. If NAME_MAX is 14 and a file exists whose name is exactly 14 characters, any function that accepts a pathname argument, such as open or stat, has no way to determine what the original name of the file was, as the original name might have been truncated. 如果NAME_MAX是14怎么办？传统上，早期的System V系统，允许这发生，静默的将文件名截断成14字符。相反的，BSD派生的系统，返回一个错误状态，并把errno设置成ENAMETOOLONG。静默的截断文件名呈现的问题不仅仅是创建了一个新文件。如果NAME_MAX是14且文件存在，且它的名字就是14字符，任何接收一个路径名作为参数的函数，比如open或者stat，没办法判断文件原来的名字是什么，因为原始文件名可能已经被截断。 With POSIX.1, the constant _POSIX_NO_TRUNC determines whether long filenames and long components of pathnames are truncated or an error is returned. As we saw in Chapter 2, this value can vary based on the type of the file system, and we can use fpathconf or pathconf to query a directory to see which behavior is supported. 在POSIX.1标准里，常量 _POSIX_NO_TRUNC 决定长文件名和路径名中长的组件是否被截断或者是否返回一个错误。正如我们在第二章中看到的，这个值在文件系统中是非常基本的，我们可以使用 fpathconf 或 pathconf查询一个目录看看它支持哪种行为。 Whether an error is returned is largely historical. For example, SVR4-based systems do not generate an error for the traditional System V file system, S5. For the BSD-style file system (known as UFS), however, SVR4-based systems do generate an error. Figure 2.20 illustrates another example: Solaris will return an error for UFS, but not for PCFS, the DOS-compatible file system, as DOS silently truncates filenames that don’t fit in an 8.3 format. BSD-derived systems and Linux always return an error. If _POSIX_NO_TRUNC is in effect, errno is set to ENAMETOOLONG, and an error status is returned if any filename component of the pathname exceeds NAME_MAX. Most modern file systems support a maximum of 255 characters for filenames. Because filenames are usually shorter than this limit, this constraint tends to not present problems for most applications. creat FunctionA new file can also be created by calling the creat function. 123#include &lt;fcntl.h&gt;int creat(const char *path, mode_t mode);// Returns: file descriptor opened for write-only if OK, −1 on error Note that this function is equivalent to 1open(path, O_WRONLY | O_CREAT | O_TRUNC, mode); Historically, in early versions of the UNIX System, the second argument to open could be only 0, 1, or 2. There was no way to open a file that didn’t already exist. Therefore, a separate system call, creat, was needed to create new files. With the O_CREAT and O_TRUNC options now provided by open, a separate creat function is no longer needed. 这个函数诞生的原因是：历史上open函数的第二个参数只支持0，1，2这三个值，也就是读，写，读写。没办法打开一个不存在的文件。而现在有了O_CREAT and O_TRUNC options，creat函数也就没有存在的必要了。 We’ll show how to specify mode in Section 4.5 when we describe a file’s access permissions in detail. One deficiency with creat is that the file is opened only for writing. Before the new version of open was provided, if we were creating a temporary file that we wanted to write and then read back, we had to call creat, close, and then open. A better way is to use the open function, as in 1open(path, O_RDWR | O_CREAT | O_TRUNC, mode); close FunctionAn open file is closed by calling the close function. 1234#include &lt;unistd.h&gt; // Returns: 0 if OK, −1 on errorint close(int fd); Closing a file also releases any record locks that the process may have on the file. We’ll discuss this point further in Section 14.3. 关闭一个文件同样会释放进程对该文件的所有锁。 When a process terminates, all of its open files are closed automatically by the kernel. Many programs take advantage of this fact and don’t explicitly close open files. See the program in Figure 1.4, for example. 当一个进程终止，所有它打开的文件都会被内核自动关闭。许多程序利用了这一点，不明确关闭文件。 lseek FunctionEvery open file has an associated “current file offset,” normally a non-negative integer that measures the number of bytes from the beginning of the file. (We describe some exceptions to the ‘‘non-negative’’ qualifier later in this section.) Read and write operations normally start at the current file offset and cause the offset to be incremented by the number of bytes read or written. By default, this offset is initialized to 0 when a file is opened, unless the O_APPEND option is specified. 每个打开的文件都与 “current file offset”关联，正常情况下它是一个非负整形数，表示从文件开始到目前位置的字节数。读和写操作都是从 current file offset开始的，并且会让offset增加，随着读和写的进行。默认的，当文件被打开时，这个位移初始化时0，除非指明了O_APPEND选项。 An open file’s offset can be set explicitly by calling lseek. 通过调用 lseek函数，一个打开的文件的offset可以被设定。 123#include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence);// Returns: new file offset if OK, −1 on error The interpretation of the offset depends on the value of the whence argument. If whence is SEEK_SET, the file’s offset is set to offset bytes from the beginning of the file. If whence is SEEK_CUR, the file’s offset is set to its current value plus the offset. The offset can be positive or negative. If whence is SEEK_END, the file’s offset is set to the size of the file plus the offset. The offset can be positive or negative. Because a successful call to lseek returns the new file offset, we can seek zero bytes from the current position to determine the current offset: 12off_t currpos;currpos = lseek(fd, 0, SEEK_CUR); This technique can also be used to determine if a file is capable of seeking. If the file descriptor refers to a pipe, FIFO, or socket, lseek sets errno to ESPIPE and returns −1. The three symbolic constants—SEEK_SET, SEEK_CUR, and SEEK_END—were introduced with System V. Prior to this, whence was specified as 0 (absolute), 1 (relative to the current offset), or 2 (relative to the end of file). Much software still exists with these numbers hard coded. The character l in the name lseek means ‘‘long integer.’’ Before the introduction of the off_t data type, the offset argument and the return value were long integers. lseek was introduced with Version 7 when long integers were added to C. (Similar functionality was provided in Version 6 by the functions seek and tell.) ExampleThe program in Figure 3.1 tests its standard input to see whether it is capable of seeking. Figure 3.1 Test whether standard input is capable of seeking 123456789#include "apue.h"int main(void)&#123; if (lseek(STDIN_FILENO, 0, SEEK_CUR) == -1) printf("cannot seek\n"); else printf("seek OK\n"); exit(0); &#125; Normally, a file’s current offset must be a non-negative integer. It is possible, however, that certain devices could allow negative offsets. But for regular files, the offset must be non-negative. Because negative offsets are possible, we should be careful to compare the return value from lseek as being equal to or not equal to −1, rather than testing whether it is less than 0. The /dev/kmem device on FreeBSD for the Intel x86 processor supports negative offsets. Because the offset (off_t) is a signed data type (Figure 2.21), we lose a factor of 2 in the maximum file size. If off_t is a 32-bit integer, the maximum file size is $2^{31}$−1 bytes. lseek only records the current file offset within the kernel — it does not cause any I/O to take place. This offset is then used by the next read or write operation. The file’s offset can be greater than the file’s current size, in which case the next write to the file will extend the file. This is referred to as creating a hole in a file and is allowed. Any bytes in a file that have not been written are read back as 0. 文件偏移量可以大于文件的目前大小，在这种情况下下一次写文件将扩展文件。也就是说在文件中创建一个空洞是被允许的。在文件中任何没被写入的部分都将被读作0。 A hole in a file isn’t required to have storage backing it on disk. Depending on the file system implementation, when you write after seeking past the end of a file, new disk blocks might be allocated to store the data, but there is no need to allocate disk blocks for the data between the old end of file and the location where you start writing. 文件中的空洞并不需要存储到磁盘上。根据文件系统的实现，当你在end of file之后写，为了存储数据新的磁盘空间可能会分配，但没有必要分配磁盘块给end of file和你开始写的地方之间的这些数据。 ExampleThe program shown in Figure 3.2 creates a file with a hole in it. Figure 3.2 Create a file with a hole in it 1234567891011121314151617181920#include "apue.h"#include &lt;fcntl.h&gt;char buf1[] = "abcdefghij";char buf2[] = "ABCDEFGHIJ";int main(void)&#123; int fd; if ((fd = creat("file.hole", FILE_MODE)) &lt; 0) err_sys("creat error"); if (write(fd, buf1, 10) != 10) err_sys("buf1 write error"); /* offset now = 10 */ if (lseek(fd, 16384, SEEK_SET) == -1) err_sys("lseek error"); /* offset now = 16384 */ if (write(fd, buf2, 10) != 10) err_sys("buf2 write error"); /* offset now = 16394 */ exit(0); &#125; read FunctionData is read from an open file with the read function. 12#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t nbytes); Returns: numbers of bytes read, 0 if end of file, -1 on error If the read is successful, the number of bytes read is returned. If the end of file is encountered, 0 is returned. There are several cases in which the number of bytes actually read is less than the amount requested: 有以下几种情况，read读取的字节会比指定的字节数少 When reading from a regular file, if the end of file is reached before the requested number of bytes has been read. For example, if 30 bytes remain until the end of file and we try to read 100 bytes, read returns 30. The next time we call read, it will return 0 (end of file). When reading from a terminal device. Normally, up to one line is read at a time. (We’ll see how to change this default in Chapter 18.) When reading from a network. Buffering within the network may cause less than the requested amount to be returned. When reading from a pipe or FIFO. If the pipe contains fewer bytes than requested, read will return only what is available. When reading from a record-oriented device. Some record-oriented devices, such as magnetic tape, can return up to a single record at a time. When interrupted by a signal and a partial amount of data has already been read. We discuss this further in Section 10.5. The read operation starts at the file’s current offset. Before a successful return, the offset is incremented by the number of bytes actually read. read操作是从文件的当前偏移量开始的。在成功返回前，偏移量会随读取的字节增加。 POSIX.1 changed the prototype for this function in several ways. The classic definition is 1int read(int fd, char *buf, unsigned nbytes); First, the second argument was changed from char to void to be consistentwith ISO C: the type void * is used for generic pointers. Next, the return value was required to be a signed integer (ssize_t) to return a positive byte count, 0 (for end of file), or −1 (for an error). Finally, the third argument historically has been an unsigned integer, to allow a 16-bit implementation to read or write up to 65,534 bytes at a time. With the 1990 POSIX.1 standard, the primitive system data type ssize_t was introduced to provide the signed return value, and the unsigned size_t was used for the third argument. (Recall the SSIZE_MAX constant from Section 2.5.2.) write FunctionData is written to an open file with the write function. 12#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t nbytes); The return value is usually equal to the nbytes argument; otherwise, an error has occurred. A common cause for a write error is either filling up a disk or exceeding the file size limit for a given process (Section 7.11 and Exercise 10.11). 返回值一般会等于nbytes这个参数的大小，否则就是出错了。一般导致写错误的原因是磁盘满了或者超出给定进程的文件大小限制。 For a regular file, the write operation starts at the file’s current offset. If the O_APPEND option was specified when the file was opened, the file’s offset is set to the current end of file before each write operation. After a successful write, the file’s offset is incremented by the number of bytes actually written. I/O EfficiencyThe program in Figure 3.5 copies a file, using only the read and write functions. Figure 3.5 Copy standard input to standard output 12345678910111213#include &quot;apue.h&quot;#define BUFFSIZE 4096int main(void)&#123; int n; char buf[BUFFSIZE]; while ((n = read(STDIN_FILENO, buf, BUFFSIZE)) &gt; 0) if (write(STDOUT_FILENO, buf, n) != n) err_sys(&quot;write error&quot;); if (n &lt; 0) err_sys(&quot;read error&quot;); exit(0);&#125; The following caveats apply to this program. It reads from standard input and writes to standard output, assuming that these have been set up by the shell before this program is executed. Indeed, all normal UNIX system shells provide a way to open a file for reading on standard input and to create (or rewrite) a file on standard output. This prevents the program from having to open the input and output files, and allows the user to take advantage of the shell’s I/O redirection facilities. The program doesn’t close the input file or output file. Instead, the program uses the feature of the UNIX kernel that closes all open file descriptors in a process when that process terminates. This example works for both text files and binary files, since there is no difference between the two to the UNIX kernel. One question we haven’t answered, however, is how we chose the BUFFSIZE value. Before answering that, let’s run the program using different values for BUFFSIZE. Figure 3.6 shows the results for reading a 516,581,760-byte file, using 20 different buffer sizes. The file was read using the program shown in Figure 3.5, with standard output redirected to /dev/null. The file system used for this test was the Linux ext4 file system with 4,096-byte blocks. (The st_blksize value, which we describe in Section 4.12, is 4,096.) This accounts for the minimum in the system time occurring at the few timing measurements starting around a BUFFSIZE of 4,096. Increasing the buffer size beyond this limit has little positive effect. Most file systems support some kind of read-ahead to improve performance. When sequential reads are detected, the system tries to read in more data than an application requests, assuming that the application will read it shortly. The effect of read-ahead can be seen in Figure 3.6, where the elapsed time for buffer sizes as small as 32 bytes is as good as the elapsed time for larger buffer sizes. We’ll return to this timing example later in the text. In Section 3.14, we show the effect of synchronous writes; in Section 5.8, we compare these unbuffered I/O times with the standard I/O library. Beware when trying to measure the performance of programs that read and write files. The operating system will try to cache the file incore, so if you measure the performance of the program repeatedly, the successive timings will likely be better than the first. This improvement occurs because the first run causes the file to be entered into the system’s cache, and successive runs access the file from the system’s cache instead of from the disk. (The term incore means in main memory. Back in the day, a computer’s main memory was built out of ferrite core. This is where the phrase ‘‘core dump’’ comes from: the main memory image of a program stored in a file on disk for diagnosis.) In the tests reported in Figure 3.6, each run with a different buffer size was made using a different copy of the file so that the current run didn’t find the data in the cache from the previous run. The files are large enough that they all don’t remain in the cache (the test system was configured with 6 GB of RAM). File SharingThe UNIX System supports the sharing of open files among different processes. Before describing the dup function, we need to describe this sharing. To do this, we’ll examine the data structures used by the kernel for all I/O. The following description is conceptual; it may or may not match a particular implementation. Refer to Bach [1986] for a discussion of these structures in System V. McKusick et al. [1996] describe these structures in 4.4BSD. McKusick and Neville-Neil [2005] cover FreeBSD 5.2. For a similar discussion of Solaris, see McDougall and Mauro [2007]. The Linux 2.6 kernel architecture is discussed in Bovet and Cesati [2006]. The kernel uses three data structures to represent an open file, and the relationships among them determine the effect one process has on another with regard to file sharing. Every process has an entry in the process table. Within each process table entry is a table of open file descriptors, which we can think of as a vector, with one entry per descriptor. Associated with each file descriptor are The file descriptor flags (close-on-exec; refer to Figure 3.7 and Section 3.14) A pointer to a file table entry The kernel maintains a file table for all open files. Each file table entry contains The file status flags for the file, such as read, write, append, sync, and nonblocking; more on these in Section 3.14 The current file offset A pointer to the v-node table entry for the file Each open file (or device) has a v-node structure that contains information about the type of file and pointers to functions that operate on the file. For most files, the v-node also contains the i-node for the file. This information is read from disk when the file is opened, so that all the pertinent information about the file is readily available. For example, the i-node contains the owner of the file, the size of the file, pointers to where the actual data blocks for the file are located on disk, and so on. (We talk more about i-nodes in Section 4.14 when we describe the typical UNIX file system in more detail.) Linux has no v-node. Instead, a generic i-node structure is used. Although the implementations differ, the v-node is conceptually the same as a generic i-node. Both point to an i-node structure specific to the file system. We’re ignoring some implementation details that don’t affect our discussion. For example, the table of open file descriptors can be stored in the user area (a separate per- process structure that can be paged out) instead of the process table. Also, these tables can be implemented in numerous ways—they need not be arrays; one alternate implementation is a linked lists of structures. Regardless of the implementation details, the general concepts remain the same. Figure 3.7 shows a pictorial arrangement of these three tables for a single process that has two different files open: one file is open on standard input (file descriptor 0), and the other is open on standard output (file descriptor 1). The arrangement of these three tables has existed since the early versions of the UNIX System [Thompson 1978]. This arrangement is critical to the way files are shared among processes. We’ll return to this figure in later chapters, when we describe additional ways that files are shared. The v-node was invented to provide support for multiple file system types on a single computer system. This work was done independently by Peter Weinberger (Bell Laboratories) and Bill Joy (Sun Microsystems). Sun called this the Virtual File System and called the file system–independent portion of the i-node the v-node [Kleiman 1986]. The v-node propagated through various vendor implementations as support for Sun’s Network File System (NFS) was added. The first release from Berkeley to provide v-nodes was the 4.3BSD Reno release, when NFS was added. In SVR4, the v-node replaced the file system–independent i-node of SVR3. Solaris is derived from SVR4 and, therefore, uses v-nodes. Instead of splitting the data structures into a v-node and an i-node, Linux uses a file system–independent i-node and a file system–dependent i-node. If two independent processes have the same file open, we could have the arrangement shown in Figure 3.8. We assume here that the first process has the file open on descriptor 3 and that the second process has that same file open on descriptor 4. Each process that opens the file gets its own file table entry, but only a single v-node table entry is required for a given file. One reason each process gets its own file table entry is so that each process has its own current offset for the file. Given these data structures, we now need to be more specific about what happens with certain operations that we’ve already described. After each write is complete, the current file offset in the file table entry is incremented by the number of bytes written. If this causes the current file offset to exceed the current file size, the current file size in the i-node table entry is set to the current file offset (for example, the file is extended). If a file is opened with the O_APPEND flag, a corresponding flag is set in the file status flags of the file table entry. Each time a write is performed for a file with this append flag set, the current file offset in the file table entry is first set to the current file size from the i-node table entry. This forces every write to be appended to the current end of file. 如果一个文件打开时使用O_APPEND标志，相应的标志会设置到文件表项的文件状态符。每次进行写操作时，文件表项就会首先将当前文件偏移量设置为i结点表项的当前文件大小。这样就可以强制每次都写到文件末尾了。 If a file is positioned to its current end of file using lseek, all that happens is the current file offset in the file table entry is set to the current file size from the i-node table entry. (Note that this is not the same as if the file was opened with the O_APPEND flag, as we will see in Section 3.11.) The lseek function modifies only the current file offset in the file table entry. No I/O takes place. It is possible for more than one file descriptor entry to point to the same file table entry, as we’ll see when we discuss the dup function in Section 3.12. This also happens after a fork when the parent and the child share the same file table entry for each open descriptor (Section 8.3). Note the difference in scope between the file descriptor flags and the file status flags. The former apply only to a single descriptor in a single process, whereas the latter apply to all descriptors in any process that point to the given file table entry. When we describe the fcntl function in Section 3.14, we’ll see how to fetch and modify both the file descriptor flags and the file status flags. Everything that we’ve described so far in this section works fine for multiple processes that are reading the same file. Each process has its own file table entry with its own current file offset. Unexpected results can arise, however, when multiple processes write to the same file. To see how to avoid some surprises, we need to understand the concept of atomic operations. Atomic OperationsAppending to a FileConsider a single process that wants to append to the end of a file. Older versions of the UNIX System didn’t support the O_APPEND option to open, so the program was coded as follows: 1234if (lseek(fd, 0L, 2) &lt; 0) /* position to EOF */trueerr_sys("lseek error");if (write(fd, buf, 100) != 100) /* and write */trueerr_sys("write error"); This works fine for a single process, but problems arise if multiple processes use this technique to append to the same file. (This scenario can arise if multiple instances of the same program are appending messages to a log file, for example.) Assume that two independent processes, A and B, are appending to the same file. Each has opened the file but without the O_APPEND flag. This gives us the same picture as Figure 3.8. Each process has its own file table entry, but they share a single v-node table entry. Assume that process A does the lseek and that this sets the current offset for the file for process A to byte offset 1,500 (the current end of file). Then the kernel switches processes, and B continues running. Process B then does the lseek, which sets the current offset for the file for process B to byte offset 1,500 also (the current end of file). Then B calls write, which increments B’s current file offset for the file to 1,600. Because the file’s size has been extended, the kernel also updates the current file size in the v-node to 1,600. Then the kernel switches processes and A resumes. When A calls write, the data is written starting at the current file offset for A, which is byte offset 1,500. This overwrites the data that B wrote to the file. The problem here is that our logical operation of ‘‘position to the end of file and write’’ requires two separate function calls (as we’ve shown it). The solution is to have the positioning to the current end of file and the write be an atomic operation with regard to other processes. Any operation that requires more than one function call cannot be atomic, as there is always the possibility that the kernel might temporarily suspend the process between the two function calls (as we assumed previously). The UNIX System provides an atomic way to do this operation if we set the O_APPEND flag when a file is opened. As we described in the previous section, this causes the kernel to position the file to its current end of file before each write. We no longer have to call lseek before each write. pread and pwrite FunctionsThe Single UNIX Specification includes two functions that allow applications to seek and perform I/O atomically: pread and pwrite. 1234567#include &lt;unistd.h&gt;// Returns: number of bytes read, 0 if end of file, −1 on errorssize_t pread(int fd, void *buf, size_t nbytes, off_t offset);// Returns: number of bytes written if OK, −1 on errorssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset); Calling pread is equivalent to calling lseek followed by a call to read, with the following exceptions. There is no way to interrupt the two operations that occur when we call pread. The current file offset is not updated. Calling pwrite is equivalent to calling lseek followed by a call to write, with similar exceptions. Creating a FileWe saw another example of an atomic operation when we described the O_CREAT and O_EXCL options for the open function. When both of these options are specified, the open will fail if the file already exists. We also said that the check for the existence of the file and the creation of the file was performed as an atomic operation. If we didn’t have this atomic operation, we might try 1234567if ((fd = open(path, O_WRONLY)) &lt; 0) &#123; if (errno == ENOENT) &#123; if ((fd = creat(path, mode)) &lt; 0) err_sys("creat error"); &#125; else &#123; err_sys("open error");&#125; &#125; The problem occurs if the file is created by another process between the open and the creat. If the file is created by another process between these two function calls, and if that other process writes something to the file, that data is erased when this creat is executed. Combining the test for existence and the creation into a single atomic operation avoids this problem. In general, the term atomic operation refers to an operation that might be composed of multiple steps. If the operation is performed atomically, either all the steps are performed (on success) or none are performed (on failure). It must not be possible for only a subset of the steps to be performed. We’ll return to the topic of atomic operations when we describe the link function (Section 4.15) and record locking (Section 14.3). dup and dup2 FunctionsAn existing file descriptor is duplicated by either of the following functions: 12345#include &lt;unistd.h&gt;// Both return: new file descriptor if OK, −1 on errorint dup(int fd);int dup2(int fd, int fd2); The new file descriptor returned by dup is guaranteed to be the lowest-numbered available file descriptor. With dup2, we specify the value of the new descriptor with the fd2 argument. If fd2 is already open, it is first closed. If fd equals fd2, then dup2 returns fd2 without closing it. Otherwise, the FD_CLOEXEC file descriptor flag is cleared for fd2, so that fd2 is left open if the process calls exec. The new file descriptor that is returned as the value of the functions shares the same file table entry as the fd argument. We show this in Figure 3.9. In this figure, we assume that when it’s started, the process executes 1newfd = dup(1); We assume that the next available descriptor is 3 (which it probably is, since 0, 1, and 2 are opened by the shell). Because both descriptors point to the same file table entry, they share the same file status flags—read, write, append, and so on—and the same current file offset. Each descriptor has its own set of file descriptor flags. As we describe in Section 3.14, the close-on-exec file descriptor flag for the new descriptor is always cleared by the dup functions. Another way to duplicate a descriptor is with the fcntl function, which we describe in Section 3.14. Indeed, the call 1dup(fd); is equivalent to 1fcntl(fd, F_DUPFD, 0); Similarly, the call 1dup2(fd, fd2); is equivalent to 12close(fd2);fcntl(fd, F_DUPFD, fd2); In this last case, the dup2 is not exactly the same as a close followed by an fcntl. The differences are as follows: dup2 is an atomic operation, whereas the alternate form involves two function calls. It is possible in the latter case to have a signal catcher called between the close and the fcntl that could modify the file descriptors. (We describe signals in Chapter 10.) The same problem could occur if a different thread changes the file descriptors. (We describe threads in Chapter 11.) There are some errno differences between dup2 and fcntl. The dup2 system call originated with Version 7 and propagated through the BSD releases. The fcntl method for duplicating file descriptors appeared with System III and continued with SystemV. SVR3.2 picked up the dup2 function, and 4.2BSD picked up the fcntl function and the F_DUPFD functionality. POSIX.1 requires both dup2 and the F_DUPFD feature of fcntl. sync, fsync, and fdatasync FunctionsTraditional implementations of the UNIX System have a buffer cache or page cache in the kernel through which most disk I/O passes. When we write data to a file, the data is normally copied by the kernel into one of its buffers and queued for writing to disk at some later time. This is called delayed write. (Chapter 3 of Bach [1986] discusses this buffer cache in detail.) The kernel eventually writes all the delayed-write blocks to disk, normally when it needs to reuse the buffer for some other disk block. To ensure consistency of the file system on disk with the contents of the buffer cache, the sync, fsync, and fdatasync functions are provided. 1234567#include &lt;unistd.h&gt; // Both Returns: 0 if OK, −1 on errorint fsync(int fd); int fdatasync(int fd);void sync(void); The sync function simply queues all the modified block buffers for writing and returns; it does not wait for the disk writes to take place. The function sync is normally called periodically (usually every 30 seconds) from a system daemon, often called update. This guarantees regular flushing of the kernel’s block buffers. The command sync(1) also calls the sync function. The function fsync refers only to a single file, specified by the file descriptor fd, and waits for the disk writes to complete before returning. This function is used when an application, such as a database, needs to be sure that the modified blocks have been written to the disk. The fdatasync function is similar to fsync, but it affects only the data portions of a file. With fsync, the file’s attributes are also updated synchronously. All four of the platforms described in this book support sync and fsync. However, FreeBSD 8.0 does not support fdatasync. fcntl FunctionThe fcntl function can change the properties of a file that is already open. 1234#include &lt;fcntl.h&gt;// Returns: depends on cmd if OK (see following), −1 on errorint fcntl(int fd, int cmd, ... /* int arg */ ); In the examples in this section, the third argument is always an integer, corresponding to the comment in the function prototype just shown. When we describe record locking in Section 14.3, however, the third argument becomes a pointer to a structure. The fcntl function is used for five different purposes. Duplicate an existing descriptor (cmd = F_DUPFD or F_DUPFD_CLOEXEC) Get/set file descriptor flags (cmd = F_GETFD or F_SETFD) Get/set file status flags (cmd = F_GETFL or F_SETFL) Get/set asynchronous I/O ownership (cmd = F_GETOWN or F_SETOWN) Get/set record locks (cmd = F_GETLK, F_SETLK, or F_SETLKW) We’ll now describe the first 8 of these 11 cmd values. (We’ll wait until Section 14.3 to describe the last 3, which deal with record locking.) Refer to Figure 3.7, as we’ll discuss both the file descriptor flags associated with each file descriptor in the process table entry and the file status flags associated with each file table entry. F_DUPFD Duplicate the file descriptor fd. The new file descriptor is returned as the value of the function. It is the lowest-numbered descriptor that is not already open, and that is greater than or equal to the third argument (taken as an integer). The new descriptor shares the same file table entry as fd. (Refer to Figure 3.9.) But the new descriptor has its own set of file descriptor flags, and its FD_CLOEXEC file descriptor flag is cleared. (This means that the descriptor is left open across an exec, which we discuss in Chapter 8.) F_DUPFD_CLOEXEC Duplicate the file descriptor and set the FD_CLOEXEC file descriptor flag associated with the new descriptor. Returns the new file descriptor. F_GETFD Return the file descriptor flags for fd as the value of the function. Currently, only one file descriptor flag is defined: the FD_CLOEXEC flag. F_SETFD Set the file descriptor flags for fd. The new flag value is set from the third argument (taken as an integer). Be aware that some existing programs that deal with the file descriptor flags don’t use the constant FD_CLOEXEC. Instead, these programs set the flag to either 0 (don’t close-on-exec, the default) or 1 (do close-on-exec). F_GETFL Return the file status flags for fd as the value of the function. We described the file status flags when we described the open function. They are listed in Figure 3.10. Unfortunately, the five access-mode flags—O_RDONLY, O_WRONLY, O_RDWR, O_EXEC, and O_SEARCH—are not separate bits that can be tested. (As we mentioned earlier, the first three often have the values 0, 1, and 2, respectively, for historical reasons. Also, these five values are mutually exclusive; a file can have only one of them enabled.) Therefore, we must first use the O_ACCMODE mask to obtain the access-mode bits and then compare the result against any of the five values. F_SETFL Set the file status flags to the value of the third argument (taken as an integer). The only flags that can be changed are O_APPEND, O_NONBLOCK, O_SYNC, O_DSYNC, O_RSYNC, O_FSYNC, and O_ASYNC. F_GETOWN Get the process ID or process group ID currently receiving the SIGIO and SIGURG signals. We describe these asynchronous I/O signals in Section 14.5.2. F_SETOWN Set the process ID or process group ID to receive the SIGIO and SIGURG signals. A positive arg specifies a process ID. A negative arg implies a process group ID equal to the absolute value of arg. The return value from fcntl depends on the command. All commands return −1 on an error or some other value if OK. The following four commands have special return values: F_DUPFD, F_GETFD, F_GETFL, and F_GETOWN. The first command returns the new file descriptor, the next two return the corresponding flags, and the final command returns a positive process ID or a negative process group ID. ExampleThe program in Figure 3.11 takes a single command-line argument that specifies a file descriptor and prints a description of selected file flags for that descriptor. Figure 3.11 Print file flags for specified descriptor 1234567891011121314151617181920212223242526272829303132333435#include "include/apue.h"#include &lt;fcntl.h&gt;int main(int argc, char *argv[])&#123; int val; if (argc != 2) err_quit("usage: a.out &lt;descriptor#&gt;"); if ((val = fcntl(atoi(argv[1]), F_GETFL, 0)) &lt; 0) err_sys("fcntl error for fd %d", atoi(argv[1])); switch (val &amp; O_ACCMODE) &#123; case O_RDONLY: printf("read only"); break; case O_WRONLY: printf("write only"); break; case O_RDWR: printf("read write"); break; default: err_dump("unknown access mode"); &#125; if (val &amp; O_APPEND) printf(", append"); if (val &amp; O_NONBLOCK) printf(", nonblocking"); if (val &amp; O_SYNC) printf(", synchronous writes"); #if !defined(_POSIX_C_SOURCE) &amp;&amp; defined(O_FSYNC) &amp;&amp; (O_FSYNC != O_SYNC) if (val &amp; O_FSYNC) printf(", synchronous writes"); #endif putchar('\n'); exit(0); &#125; Note that we use the feature test macro _POSIX_C_SOURCE and conditionally compile the file access flags that are not part of POSIX.1. The following script shows the operation of the program, when invoked from bash (the Bourne-again shell). Results will vary, depending on which shell you use. 123456789➜ apue.3e ./fig3.11 0 &lt; /dev/ttyread only➜ apue.3e ./fig3.11 1 &gt; temp.foo➜ apue.3e cat temp.foowrite only➜ apue.3e ./fig3.11 2 2&gt;&gt;temp.foowrite only, append➜ apue.3e ./fig3.11 5 5&lt;&gt;temp.fooread write The clause 5&lt;&gt;temp.foo opens the file temp.foo for reading and writing on file descriptor 5. ExampleWhen we modify either the file descriptor flags or the file status flags, we must be careful to fetch the existing flag value, modify it as desired, and then set the new flag value. We can’t simply issue an F_SETFD or an F_SETFL command, as this could turn off flag bits that were previously set. Figure 3.12 shows a function that sets one or more of the file status flags for a descriptor. Figure 3.12 Turn on one or more of the file status flags for a descriptor 1234567891011#include "apue.h"#include &lt;fcntl.h&gt;void set_fl(int fd, int flags) /* flags are file status flags to turn on */&#123;trueint val;trueif ((val = fcntl(fd, F_GETFL, 0)) &lt; 0)true err_sys("fcntl F_GETFL error");trueval |= flags; /* turn on flags */trueif (fcntl(fd, F_SETFL, val) &lt; 0)true err_sys("fcntl F_SETFL error");&#125; If we change the middle statement to 1val &amp;= ̃flags; /* turn flags off */ we have a function named clr_fl, which we’ll use in some later examples. This statement logically ANDs the one’s complement of flags with the current val. If we add the line 1set_fl(STDOUT_FILENO, O_SYNC); to the beginning of the program shown in Figure 3.5, we’ll turn on the synchronous- write flag. This causes each write to wait for the data to be written to disk before returning. Normally in the UNIX System, a write only queues the data for writing; the actual disk write operation can take place sometime later. A database system is a likely candidate for using O_SYNC, so that it knows on return from a write that the data is actually on the disk, in case of an abnormal system failure. We expect the O_SYNC flag to increase the system and clock times when the program runs. To test this, we can run the program in Figure 3.5, copying 492.6 MB of data from one file on disk to another and compare this with a version that does the same thing with the O_SYNC flag set. The results from a Linux system using the ext4 file system are shown in Figure 3.13. The six rows in Figure 3.13 were all measured with a BUFFSIZE of 4,096 bytes. The results in Figure 3.6 were measured while reading a disk file and writing to /dev/null, so there was no disk output. The second row in Figure 3.13 corresponds to reading a disk file and writing to another disk file. This is why the first and second rows in Figure 3.13 are different. The system time increases when we write to a disk file, because the kernel now copies the data from our process and queues the data for writing by the disk driver. We expect the clock time to increase as well when we write to a disk file. When we enable synchronous writes, the system and clock times should increase significantly. As the third row shows, the system time for writing synchronously is not much more expensive than when we used delayed writes. This implies that the Linux operating system is doing the same amount of work for delayed and synchronous writes (which is unlikely), or else the O_SYNC flag isn’t having the desired effect. In this case, the Linux operating system isn’t allowing us to set the O_SYNC flag using fcntl, instead failing without returning an error (but it would have honored the flag if we were able to specify it when the file was opened). The clock time in the last three rows reflects the extra time needed to wait for all of the writes to be committed to disk. After writing a file synchronously, we expect that a call to fsync will have no effect. This case is supposed to be represented by the last row in Figure 3.13, but since the O_SYNC flag isn’t having the intended effect, the last row behaves the same way as the fifth row. Figure 3.14 shows timing results for the same tests run on Mac OS X 10.6.8, which uses the HFS file system. Note that the times match our expectations: synchronous writes are far more expensive than delayed writes, and using fsync with synchronous writes makes very little difference. Note also that adding a call to fsync at the end of the delayed writes makes little measurable difference. It is likely that the operating system flushed previously written data to disk as we were writing new data to the file, so by the time that we called fsync, very little work was left to be done. Compare fsync and fdatasync, both of which update a file’s contents when we say so, with the O_SYNC flag, which updates a file’s contents every time we write to the file. The performance of each alternative will depend on many factors, including the underlying operating system implementation, the speed of the disk drive, and the type of the file system. With this example, we see the need for fcntl. Our program operates on a descriptor (standard output), never knowing the name of the file that was opened on that descriptor. We can’t set the O_SYNC flag when the file is opened, since the shell opened the file. With fcntl, we can modify the properties of a descriptor, knowing only the descriptor for the open file. We’ll see another need for fcntl when we describe nonblocking pipes (Section 15.2), since all we have with a pipe is a descriptor. ioctl FunctionThe ioctl function has always been the catchall for I/O operations. Anything that couldn’t be expressed using one of the other functions in this chapter usually ended up being specified with an ioctl. Terminal I/O was the biggest user of this function. (When we get to Chapter 18, we’ll see that POSIX.1 has replaced the terminal I/O operations with separate functions.) 12345#include &lt;unistd.h&gt; /* System V */#include &lt;sys/ioctl.h&gt; /* BSD and Linux */// Returns: −1 on error, something else if OKint ioctl(int fd, int request, ...); The ioctl function was included in the Single UNIX Specification only as an extension for dealing with STREAMS devices [Rago 1993], but it was moved to obsolescent status in SUSv4. UNIX System implementations use ioctl for many miscellaneous device operations. Some implementations have even extended it for use with regular files. The prototype that we show corresponds to POSIX.1. FreeBSD 8.0 and Mac OS X 10.6.8 declare the second argument as an unsigned long. This detail doesn’t matter, since the second argument is always a #defined name from a header. For the ISO C prototype, an ellipsis is used for the remaining arguments. Normally, however, there is only one more argument, and it’s usually a pointer to a variable or a structure. In this prototype, we show only the headers required for the function itself. Normally, additional device-specific headers are required. For example, the ioctl commands for terminal I/O, beyond the basic operations specified by POSIX.1, all require the header. Each device driver can define its own set of ioctl commands. The system, however, provides generic ioctl commands for different classes of devices. Examples of some of the categories for these generic ioctl commands supported in FreeBSD are summarized in Figure 3.15. The mag tape operations allow us to write end-of-file marks on a tape, rewind a tape, space forward over a specified number of files or records, and the like. None of these operations is easily expressed in terms of the other functions in the chapter (read, write, lseek, and so on), so the easiest way to handle these devices has always been to access their operations using ioctl. We use the ioctl function in Section 18.12 to fetch and set the size of a terminal’s window, and in Section 19.7 when we access the advanced features of pseudo terminals. /dev/fdNewer systems provide a directory named /dev/fd whose entries are files named 0, 1, 2, and so on. Opening the file /dev/fd/n is equivalent to duplicating descriptor n, assuming that descriptor n is open. The /dev/fd feature was developed by Tom Duff and appeared in the 8th Edition of the Research UNIX System. It is supported by all of the systems described in this book: FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10. It is not part of POSIX.1. In the function call 1fd = open("/dev/fd/0", mode); most systems ignore the specified mode, whereas others require that it be a subset of the mode used when the referenced file (standard input, in this case) was originally opened. Because the previous open is equivalent to 1fd = dup(0); the descriptors 0 and fd share the same file table entry (Figure 3.9). For example, if descriptor 0 was opened read-only, we can only read on fd. Even if the system ignores the open mode and the call 1fd = open("/dev/fd/0", O_RDWR); succeeds, we still can’t write to fd. The Linux implementation of /dev/fd is an exception. It maps file descriptors into symbolic links pointing to the underlying physical files. When you open /dev/fd/0, for example, you are really opening the file associated with your standard input. Thus the mode of the new file descriptor returned is unrelated to the mode of the /dev/fd file descriptor. We can also call creat with a /dev/fd pathname argument as well as specify O_CREAT in a call to open. This allows a program that calls creat to still work if the pathname argument is /dev/fd/1, for example. Beware of doing this on Linux. Because the Linux implementation uses symbolic links to the real files, using creat on a /dev/fd file will result in the underlying file being truncated. Some systems provide the pathnames /dev/stdin, /dev/stdout, and /dev/stderr. These pathnames are equivalent to /dev/fd/0, /dev/fd/1, and /dev/fd/2, respectively. The main use of the /dev/fd files is from the shell. It allows programs that use pathname arguments to handle standard input and standard output in the same manner as other pathnames. For example, the cat(1) program specifically looks for an input filename of - and uses it to mean standard input. The command 1filter file2 | cat file1 - file3 | lpr is an example. First, cat reads file1, then its standard input (the output of the filter program on file2), and then file3. If /dev/fd is supported, the special handling of - can be removed from cat, and we can enter 1filter file2 | cat file1 /dev/fd/0 file3 | lpr The special meaning of - as a command-line argument to refer to the standard input or the standard output is a kludge that has crept into many programs. There are also problems if we specify - as the first file, as it looks like the start of another command-line option. Using /dev/fd is a step toward uniformity and cleanliness. SummaryThis chapter has described the basic I/O functions provided by the UNIX System. These are often called the unbuffered I/O functions because each read or write invokes a system call into the kernel. Using only read and write, we looked at the effect of various I/O sizes on the amount of time required to read a file. We also looked at several ways to flush written data to disk and their effect on application performance. Atomic operations were introduced when multiple processes append to the same file and when multiple processes create the same file. We also looked at the data structures used by the kernel to share information about open files. We’ll return to these data structures later in the text. We also described the ioctl and fcntl functions. We return to both of these functions later in the book. In Chapter 14, we’ll use fcntl for record locking. In Chapter 18 and Chapter 19, we’ll use ioctl when we deal with terminal devices. Exercises When reading or writing a disk file, are the functions described in this chapter really unbuffered? Explain. Write your own dup2 function that behaves the same way as the dup2 function described in Section 3.12, without calling the fcntl function. Be sure to handle errors correctly. Assume that a process executes the following three function calls: 123fd1 = open(path, oflags);fd2 = dup(fd1);fd3 = open(path, oflags); Draw the resulting picture, similar to Figure 3.9. Which descriptors are affected by an fcntl on fd1 with a command of F_SETFD? Which descriptors are affected by an fcntl on fd1 with a command of F_SETFL? The following sequence of code has been observed in various programs: 1234dup2(fd, 0);dup2(fd, 1);dup2(fd, 2);if (fd &gt; 2) close(fd); To see why the if test is needed, assume that fd is 1 and draw a picture of what happens to the three descriptor entries and the corresponding file table entry with each call to dup2. Then assume that fd is 3 and draw the same picture.]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《APUE-3rd》</category>
      </categories>
      <tags>
        <tag>Unix</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《APUE-3rd》 读书笔记 -- Unix System Overview]]></title>
    <url>%2Fblog%2F2018%2F05%2F22%2FAPUE-3rd-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--Unix%20System%20Overview%2F</url>
    <content type="text"><![CDATA[前言Unix系统中非常重要的概念： 内核 系统调用 库函数 shell 文件、目录、路径、工作路径、权限管理 文件描述符 进程、线程 错误处理 信号 1.1 IntroductionAll operating systems provide services for programs they run. Typical services include executing a new program, opening a file, reading a file, allocating a region of memory, getting the current time of day, and so on. The focus of this text is to describe the services provided by various versions of the UNIX operating system. 所有的操作系统都提供一些服务让程序能够在其上运行，典型的服务包括：执行一个新程序，打开一个文件，读取一个文件，分配一块内存，获取当前时间，等等。 这本书所关注的重点就是众多种类的unix操作系统能提供服务。 Describing the UNIX System in a strictly linear fashion, without any forward references to terms that haven’t been described yet, is nearly impossible (and would probably be boring). 这里道出了一个众所周知的难题，想要线性的给读者讲授一个新课程，在讲授一个知识点时却又不引进任何其他的未知概念，这几乎是不可能的。 但我认为能不能做到，不用去管，做教育的就是要尽可能的降低学习者的难度，将新知识点尽可能的用学习者已有的知识结构描述清楚。所以我们可以看到我们的课程都是有选修课的。 1.2 Unix Architecture 内核（kernel）：In a strict sense, an operating system can be defined as the software that controls the hardware resources of the computer and provides an environment under which programs can run. Generally, we call this software the kernel, since it is relatively small and resides at the core of the environment. 内核控制硬件资源，并给其上的程序提供运行环境，内核相对（相对是指相对于上面这张图，整个软件环境：包括内核、系统调用、公用函数库、shell(命令解释器)、应用程序）来说比较小，并处于整个环境的中心。 系统调用（system calls）：The interface to the kernel is a layer of software called the system calls . 系统调用是内核对外的接口。 Libraries of common functions are built on top of the system call interface, but applications are free to use both. The shell is a special application that provides an interface for running other applications. 公共库是建立在系统调用之上的，但应用程序既可以使用公共库也可以使用系统调用。shell是一种特殊的应用程序，给执行命令(运行其他程序)提供接口。 In a broad sense, an operating system consists of the kernel and all the other software that makes a computer useful and gives the computer its personality. This other software includes system utilities, applications, shells, libraries of common functions, and so on. For example, Linux is the kernel used by the GNU operating system. Some people refer to this combination as the GNU/Linux operating system, but it is more commonly referred to as simply Linux. Although this usage may not be correct in a strict sense, it is understandable, given the dual meaning of the phrase operating system. (It also has the advantage of being more succinct.) 1.3 Logging InLogin NameWhen we log in to a UNIX system, we enter our login name, followed by our password. The system then looks up our login name in its password file, usually the file /etc/passwd. If we look at our entry in the password file, we see that it’s composed of seven colon-separated fields: the login name, encrypted password, numeric user ID (205), numeric group ID (105), a comment field, home directory (/home/sar), and shell program (/bin/ksh).口令文件（password file） ：当我们使用用户名和密码登陆unix的时候，系统会在/etc/passwd文件(password file，又叫：口令文件)中查找我们的用户名，口令文件中每个条目占一行，格式是： 1登录名:加密过的密码:user ID:group ID:注解:home目录:shell All contemporary systems have moved the encrypted password to a different file. In Chapter 6, we’ll look at these files and some functions to access them. 不过加密过的密码现在也不显示在这个文件里了，而是用一个*号或者x号之类的取代，home目录又称为起始目录，新开一个shell，pwd一下，就是home目录。 例子： 1sar:x:205:105:Stephen Rago:/home/sar:/bin/ksh 登录名是sar，加密过的密码是x（不显示在这里），user ID是205，group ID是105，注解是Stephen Rago，home目录是/home/sar，使用的shell是/bin/ksh ShellsA shell is a command-line interpreter that reads user input and executes commands. The user input to a shell is normally from the terminal (an interactive shell) or sometimes from a file (called a shell script). shell是一种命令解释器，可以读取用户的输入，并执行命令，用户可以交互式的输入命令，也可以把命令预先全部写在一个文本文件（shell脚本）中让shell执行。 常见的shell有： The system knows which shell to execute for us based on the final field in our entry in the password file. 系统是通过口令文件的最后一个字段知道我们登陆时使用哪个shell。 bash的全称是Bourne-again shell The Bourne-again shell is the GNU shell provided with all Linux systems. It was designed to be POSIX conformant, while still remaining compatible with the Bourne shell. It supports features from both the C shell and the Korn shell. 1.4 Files and DirectoriesFile System 根目录（root）：The UNIX file system is a hierarchical arrangement of directories and files. Everything starts in the directory called root, whose name is the single character /. unix文件系统是目录和文件的层级安排，所有东西都从一个叫root的目录开始，root的名字是一个单字符：/。 目录（directory）：A directory is a file that contains directory entries. Logically, we can think of each directory entry as containing a filename along with a structure of information describing the attributes of the file. The attributes of a file are such things as the type of file (regular file, directory), the size of the file, the owner of the file, permissions for the file (whether other users may access this file), and when the file was last modified. 目录是一个包含目录条目的文件。逻辑上，我们可以认为每一个目录条目包含一个文件名和一个描述文件属性的结构信息。文件属性包括：文件类型（普通文件还是目录），文件大小，文件所属者，文件权限（其他用户是否能访问），文件最后被修改的时间。 The stat and fstat functions return a structure of information containing all the attributes of a file. stat和fstat函数可以返回一个结构信息，包含文件的所有属性。 We make a distinction between the logical view of a directory entry and the way it is actually stored on disk. Most implementations of UNIX file systems don’t store attributes in the directory entries themselves, because of the difficulty of keeping them in synch when a file has multiple hard links. 也就是说上面目录条目只是逻辑上的，实际上在硬盘存储上并不是直接将目录条目中的那些属性存储在目录文件中的，因为如果文件有硬链接的话，很难让这些属性信息保持同步。 Filename文件名：The names in a directory are called filenames. The only two characters that cannot appear in a filename are the slash character (/) and the null character. The slash separates the filenames that form a pathname (described next) and the null character terminates a pathname. Nevertheless, it’s good practice to restrict the characters in a filename to a subset of the normal printing characters. (If we use some of the shell’s special characters in the filename, we have to use the shell’s quoting mechanism to reference the filename, and this can get complicated.) Indeed, for portability, POSIX.1 recommends restricting filenames to consist of the following characters: letters (a-z, A-Z), numbers (0-9), period (.), dash (-), and underscore (_).一个目录中的诸多名字（包括文件和目录）称为文件名，只有两个字符不能出现在文件名中：斜杠/(slash)和空字符(null character)，斜杠用来分割路径名(pathname)中的文件名，空字符用来结束一个路径名（实际上编程语言中字符串就是由空字符来结束的）。然而，我们命名文件的时候最好不要使用一些乱七八糟的字符，如果我们使用了shell的特殊字符，我们就必须使用shell的引用机制去引用文件名。实际上，为了可移植性，POSIX.1标准推荐严格使用以下字符来命名文件：字母(a-z, A-Z)，数字(0-9)，点(.)，中杠(-)，下划线(_)。 Two filenames are automatically created whenever a new directory is created: . (called dot) and .. (called dot-dot). Dot refers to the current directory, and dot-dot refers to the parent directory. In the root directory, dot-dot is the same as dot. 有两个文件名在目录被创建的时候自动创建：.和..，.指向当前目录，..指向父目录，在根目录中，..和.一样（都指向当前目录）。 The Research UNIX System and some older UNIX System V file systems restricted a filename to 14 characters. BSD versions extended this limit to 255 characters. Today, almost all commercial UNIX file systems support at least 255-character filenames. 现如今的unix文件系统都支持至少255字符的文件名。 PathnameA sequence of one or more filenames, separated by slashes and optionally starting with a slash, forms a pathname. A pathname that begins with a slash is called an absolute pathname; otherwise, it’s called a relative pathname. Relative pathnames refer to files relative to the current directory. 一系列的由斜杠分割而开的文件名组成一个路径名，一个路径名可以由一个斜杠开始，这叫做：绝对路径，反之就是相对路径，相对路径是相对于当前路径的。 ExampleListing the names of all the files in a directory is not difficult. There is a bare-bones implementation of the ls(1) command: Figure 1.3 List all the files in a directory 12345678910111213141516#include "apue.h"#include &lt;dirent.h&gt;int main(int argc, char *argv[])&#123; DIR *dp; struct dirent *dirp; if (argc != 2) err_quit("usage: ls directory_name"); if ((dp = opendir(argv[1])) == NULL) err_sys("can’t open %s", argv[1]); while ((dirp = readdir(dp)) != NULL) printf("%s\n", dirp-&gt;d_name); closedir(dp); exit(0);&#125; The notation ls(1) is the normal way to reference a particular entry in the UNIX system manuals. It refers to the entry for ls in Section 1. The sections are normally numbered 1 through 8, and all the entries within each section are arranged alphabetically. Throughout this text, we assume that you have a copy of the manuals for your UNIX system. 熟悉unix的人应该都知道，unix有个man命令，可以查看其它命令的说明书，当然也可以man man查看自己的说明书。 man命令有8个section，每个section里的条目按照字幕顺序排列。 Historically, UNIX systems lumped all eight sections together into what was called the UNIX Programmer’s Manual. As the page count increased, the trend changed to distributing the sections among separate manuals: one for users, one for programmers, and one for system administrators, for example. Some UNIX systems further divide the manual pages within a given section, using an uppercase letter. For example, all the standard input/output (I/O) functions in AT&amp;T [1990e] are indicated as being in Section 3S, as in fopen(3S). Other systems have replaced the numeric sections with alphabetic ones, such as C for commands. Today, most manuals are distributed in electronic form. If your manuals are online, the way to see the manual pages for the ls command would be something like 1man 1 ls or 1man -s1 ls Figure 1.3 is a program that just prints the name of every file in a directory, and nothing else. If the source file is named myls.c, we compile it into the default a.out executable file by running 1cc myls.c Historically, cc(1) is the C compiler. On systems with the GNU C compilation system, the C compiler is gcc(1). Here, cc is usually linked to gcc. 但在实际的操作过程中，遇到了如下错误： 1234567Undefined symbols for architecture x86_64: &quot;_err_quit&quot;, referenced from: _main in fig1-457251.o &quot;_err_sys&quot;, referenced from: _main in fig1-457251.old: symbol(s) not found for architecture x86_64clang: error: linker command failed with exit code 1 (use -v to see invocation) 这是个链接错误，具体的解决办法请看这篇博客：OS X下UNIX环境高级编程（第三版）学习日志－第一章ChapterI，编译apue包与第一个例程 实际上要先单独编译myls.c，使用命令： 1gcc -c myls.c 得到myls.o，然后与依赖的其他目标文件组合成一个可执行文件，我们可以把本书要用到的所有依赖组合成一个静态库，在apue源代码的根目录下面make一下，编译完成后就可以在lib目录下找到静态库：libapue.a了。使用命令： 1gcc -o myls myls.o -Llib -lapue 如果编译失败，使用make clean可以清空编译结果，然后就可以使用make重新编译了。不要将程序命名为.cpp文件，这样的话即便你使用gcc编译myls.cpp，也会出错，更不要使用g++去编译myls.cpp，因为库是用gcc编译的。 When the program is done, it calls the function exit with an argument of 0. The function exit terminates a program. By convention, an argument of 0 means OK, and an argument between 1 and 255 means that an error occurred. 0代表OK，1到255代表各种类型的错误。 Working Directory工作目录（working directory）：Every process has a working directory, sometimes called the current working directory. This is the directory from which all relative pathnames are interpreted. A process can change its working directory with the chdir function. 每个进程都有一个工作目录，又叫做：当前工作目录，相对路径就是相对于当前工作目录的来解释的，可以调用chdir函数来改变工作目录。 For example, the relative pathname doc/memo/joe refers to the file or directory joe, in the directory memo, in the directory doc, which must be a directory within the working directory. From looking just at this pathname, we know that both doc and memo have to be directories, but we can’t tell whether joe is a file or a directory. The pathname /usr/lib/lint is an absolute pathname that refers to the file or directory lint in the directory lib, in the directory usr, which is in the root directory. 这里有趣的一点是，我们无法判断joe是文件还是目录。 Home DirectoryWhen we log in, the working directory is set to our home directory. Our home directory is obtained from our entry in the password file (Section 1.3). 当我们登陆的时候，工作目录会设定为home目录，而我们的home目录设置在口令文件中。 1.5 Input and OutputFile Descriptors文件描述符（file descriptor）：File descriptors are normally small non-negative integers that the kernel uses to identify the files accessed by a process. Whenever it opens an existing file or creates a new file, the kernel returns a file descriptor that we use when we want to read or write the file. 文件描述符是一个小的非负整数，内核用它来标识正在被进程访问的文件。打开或者创建文件的时候内核会返回一个文件描述符，我们可以使用这个文件描述符来对文件进行读写。 Standard Input, Standard Output, and Standard Error标准输入，标准输出，标准错误：By convention, all shells open three descriptors whenever a new program is run: standard input, standard output, and standard error. If nothing special is done, as in the simple command 1ls then all three are connected to the terminal. Most shells provide a way to redirect any or all of these three descriptors to any file. For example, 1ls &gt; file.list executes the ls command with its standard output redirected to the file named file.list. 按照惯例，当新程序运行的时候，shell会打开三个文件描述符：标准输入，标准输出，标准错误。如果没有进行指明，那么三个文件描述符都会连接到终端。 Unbuffered I/OUnbuffered I/O is provided by the functions open, read,write, lseek, and close. These functions all work with file descriptors. unbuffered I/O意思是系统不提供buffer管理，要你自己申请buffer，并传递给系统函数。 ExampleIf we’re willing to read from the standard input and write to the standard output, then the program in Figure 1.4 copies any regular file on a UNIX system. Figure 1.4 Copy standard input to standard output 12345678910111213#include "apue.h"#define BUFFSIZE 4096int main(void)&#123; int n; char buf[BUFFSIZE]; while ((n = read(STDIN_FILENO, buf, BUFFSIZE)) &gt; 0) if (write(STDOUT_FILENO, buf, n) != n) err_sys("write error"); if (n &lt; 0) err_sys("read error");trueexit(0); &#125; 下面是对程序的解释： The &lt;unistd.h&gt; header, included by apue.h, and the two constants STDIN_FILENO and STDOUT_FILENO are part of the POSIX standard (about which we’ll have a lot more to say in the next chapter). This header contains function prototypes for many of the UNIX system services, such as the read and write functions that we call. The constants STDIN_FILENO and STDOUT_FILENO are defined in and specify the file descriptors for standard input and standard output. These values are 0 and 1, respectively, as required by POSIX.1, but we’ll use the names for readability. POSIX.1标准：标准输入是0，标准输出是1，标准错误是2。 The read function returns the number of bytes that are read, and this value is used as the number of bytes to write. When the end of the input file is encountered, read returns 0 and the program stops. If a read error occurs, read returns −1. Most of the system functions return −1 when an error occurs. read函数返回的是读入字节的个数，把这个返回值传给write函数，就可以读多少写多少了，当遇到输入文件结束时，read函数返回0，当遇到错误时，read函数返回-1。许多系统函数返回-1，当它们遇到错误时。 If we compile the program into the standard name (a.out) and execute it as 1./a.out &gt; data standard input is the terminal, standard output is redirected to the file data, and standard error is also the terminal. If this output file doesn’t exist, the shell creates it by default. The program copies lines that we type to the standard output until we type the end-of-file character (usually Control-D). If we run 1./a.out &lt; infile &gt; outfile then the file named infile will be copied to the file named outfile. 如果文件不存在，shell默认给我们创建一个。标准输入和标准错误都是终端，我们可以一直输入，直到输入一个文件结束符，也就是ctrl+d。 Standard I/OThe standard I/O functions provide a buffered interface to the unbuffered I/O functions. Using standard I/O relieves us from having to choose optimal buffer sizes, such as the BUFFSIZE constant in Figure 1.4. The standard I/O functions also simplify dealing with lines of input (a common occurrence in UNIX applications). The fgets function, for example, reads an entire line. The read function, in contrast, reads a specified number of bytes. As we shall see in Section 5.4, the standard I/O library provides functions that let us control the style of buffering used by the library. 标准I/O函数给unbuffered I/O 函数提供了缓冲接口，使用标准I/O函数可以让我们从优化buffer大小中解脱出来，举个例子，fgets函数直接读取一整行，而read函数读取固定个数的字节。 The most common standard I/O function is printf. In programs that call printf, we’ll always include —normally by including apue.h—as this header contains the function prototypes for all the standard I/O functions. ExampleThe program in Figure 1.5, which we’ll examine in more detail in Section 5.8, is like the previous program that called read and write. This program copies standard input to standard output and can copy any regular file. Figure 1.5 Copy standard input to standard output, using standard I/O 1234567891011#include "apue.h"int main(void)&#123;trueint c; while ((c = getc(stdin)) != EOF) if (putc(c, stdout) == EOF) err_sys("output error"); if (ferror(stdin)) err_sys("input error");trueexit(0);&#125; The function getc reads one character at a time, and this character is written by putc. After the last byte of input has been read, getc returns the constant EOF (defined in ). The standard I/O constants stdin and stdout are also defined in the header and refer to the standard input and standard output. 1.6 Programs and ProcessesProgramA program is an executable file residing on disk in a directory. A program is read into memory and is executed by the kernel as a result of one of the seven exec functions. Processes and Process IDAn executing instance of a program is called a process, a term used on almost every page of this text. Some operating systems use the term task to refer to a program that is being executed. 程序运行的一个实例叫做：进程，也有些操作系统使用：task这个术语来描述被执行的程序。 The UNIX System guarantees that every process has a unique numeric identifier called the process ID. The process ID is always a non-negative integer. unix系统保证每个进程都有独一无二的进程ID，这个进程ID是一个非负整数。 ExampleThe program in Figure 1.6 prints its process ID. Figure 1.6 Print the process ID 123456#include "apue.h"int main(void)&#123; printf("hello world from process ID %ld\n", (long)getpid()); exit(0); &#125; 输出结果： 1234➜ apue.3e ./fig1.6hello world from process ID 8080➜ apue.3e ./fig1.6hello world from process ID 8086 Process ControlThere are three primary functions for process control: fork, exec, and waitpid. (The exec function has seven variants, but we often refer to them collectively as simply the exec function.) 有三个进程控制的基本函数：fork，exec和waitpid，虽然exec函数有7种变体，但我们往往简单的用一个exec来表示它们。 ExampleThe process control features of the UNIX System are demonstrated using a simple program (Figure 1.7) that reads commands from standard input and executes the commands. This is a bare-bones implementation of a shell-like program. Figure 1.7 Read commands from standard input and execute them 1234567891011121314151617181920212223242526272829#include "include/apue.h"#include &lt;sys/wait.h&gt;int main(void)&#123; char buf[MAXLINE]; /* from apue.h */ pid_t pid; int status; printf("%% "); /* print prompt (printf requires %% to print %) */ while (fgets(buf, MAXLINE, stdin) != NULL) &#123; if (buf[strlen(buf) - 1] == '\n') buf[strlen(buf) - 1] = 0; /* replace newline with null */ if ((pid = fork()) &lt; 0) &#123; err_sys("fork error"); &#125; else if (pid == 0) &#123; /* child */ execlp(buf, buf, (char *)0); // or // execlp(buf, buf, (char *)NULL); err_ret("couldn’t execute: %s", buf); exit(127);truetrue&#125; /* parent */ if ((pid = waitpid(pid, &amp;status, 0)) &lt; 0) err_sys("waitpid error"); printf("%% ");true&#125;trueexit(0); &#125; There are several features to consider in this 30-line program. We use the standard I/O function fgets to read one line at a time from the standard input. When we type the end-of-file character (which is often Control-D) as the first character of a line, fgets returns a null pointer, the loop stops, and the process terminates. In Chapter 18, we describe all the special terminal characters—end of file, backspace one character, erase entire line, and so on—and how to change them. 我们使用了标准I/O函数fgets来一次读取标准输入的一行。当我们直接输入一个EOF时，fgets返回一个空指针，循环停止，进程终止。在第18章，我们将讲述特殊终止符，比如：end of file，backspace one character, erase entire line, 等等，以及如何改变它们。 Because each line returned by fgets is terminated with a newline character, followed by a null byte, we use the standard C function strlen to calculate the length of the string, and then replace the newline with a null byte. We do this because the execlp function wants a null-terminated argument, not a newline-terminated argument. 因为fgets返回的每一行都被一个换行符终止，换行符之后是一个空字符，我们使用标准C函数strlen来计算string的长度，然后将换行符替换成空字符（这样末尾就两个空字符了）。我们这样做是因为execlp函数希望有一个空字符来作为结尾参数，而不是一个换行符。 We call fork to create a new process, which is a copy of the caller. We say that the caller is the parent and that the newly created process is the child. Then fork returns the non-negative process ID of the new child process to the parent, and returns 0 to the child. Because fork creates a new process, we say that it is called once—by the parent—but returns twice—in the parent and in the child. 我们调用fork创建一个新进程，这个新进程是调用进程的一个复制。我们说，调用者是父进程，新创建出来的进程是子进程。然后fork返回子进程的非负进程ID给父进程，并返回0给子进程。因为fork创建了一个新进程，我们说它调用了一次（被父进程），但是返回了两次，在父进程和子进程里面。 In the child, we call execlp to execute the command that was read from the standard input. This replaces the child process with the new program file. The combination of fork followed by exec is called spawning a new process on some operating systems. In the UNIX System, the two parts are separated into individual functions. We’ll say a lot more about these functions in Chapter 8. 在子进程中，我们调用execlp来执行从标注输入中读取来的命令。这就把子进程替换成了新执行的程序。fork后面跟个exec这种结合方式被叫做 spawning a new process 在某些操作系统中。在unix系统中，这两部分被分别放到了两个单独的函数中。我们将在第8章中讨论更多的这类函数。 Because the child calls execlp to execute the new program file, the parent wants to wait for the child to terminate. This is done by calling waitpid, specifying which process to wait for: the pid argument, which is the process ID of the child. The waitpid function also returns the termination status of the child—the status variable—but in this simple program, we don’t do anything with this value. We could examine it to determine how the child terminated. 因为子进程调用了execlp来执行新程序文件，父进程想要等子进程结束。通过调用waitpid可以完成这个任务，用pid（子进程的进程ID）参数来明确需要等待哪个进程。waitpid函数同样也返回子进程的终止状态（记录在status这个参数），但在这个简单的程序里，我们没有用到这个值。我们通过这个值得知子进程是如何结束的。 The most fundamental limitation of this program is that we can’t pass arguments to the command we execute. We can’t, for example, specify the name of a directory to list. We can execute ls only on the working directory. To allow arguments would require that we parse the input line, separating the arguments by some convention, probably spaces or tabs, and then pass each argument as a separate parameter to the execlp function. Nevertheless, this program is still a useful demonstration of the UNIX System’s process control functions. 这个程序最大的限制就是，我们不能传递参数给我们要执行的命令。比如，我们不能给定一个目录给list程序（展示目录下的所有目录和文件的程序）。我们只能在当前目录下执行ls。如果要允许传递参数，就需要我们分析输入行，按照惯例，比如空格或者制表符，把参数分割开来，然后把参数传给execlp函数。不管怎么说，这个程序已经很好的展示了unix系统是如何控制函数的。 If we run this program, we get the following result. Note that our program has a different prompt—the percent sign—to distinguish it from the shell’s prompt. 123456789➜ apue.3e ./fig1.7% pwd/Users/liuqinh2s/Downloads/apue.3e% wholiuqinh2s console May 21 12:09liuqinh2s ttys000 May 21 12:10% date2018年 5月24日 星期四 15时26分59秒 CST% % ➜ apue.3e The notation ˆD is used to indicate a control character. Control characters are special characters formed by holding down the control key—often labeled Control or Ctrl—on your keyboard and then pressing another key at the same time. Control-D, or ˆD, is the default end-of-file character. We’ll see many more control characters when we discuss terminal I/O in Chapter 18. ^D这种记法用于表示控制字符，控制字符是一类特殊的字符，由ctrl键加一个其他键组成，Control-D或者说^D是默认的文件终止符。我们将在第18章讨论输入输出终止符的时候看到更多的控制字符。 Threads and Thread IDsUsually, a process has only one thread of control—one set of machine instructions executing at a time. Some problems are easier to solve when more than one thread of control can operate on different parts of the problem. Additionally, multiple threads of control can exploit the parallelism possible on multiprocessor systems. All threads within a process share the same address space, file descriptors, stacks, and process-related attributes. Each thread executes on its own stack, although any thread can access the stacks of other threads in the same process. Because they can access the same memory, the threads need to synchronize access to shared data among themselves to avoid inconsistencies. 属于同一个进程的多个线程共享同一块内存空间，文件描述符，栈，以及和进程相关的属性。每个线程都在自己的栈里面执行，但每个线程又能访问其他线程的栈（同属于一个进程的多个线程）。因为它们能访问同一块内存，所以为了避免不一致性，需要保护好临界资源。 Like processes, threads are identified by IDs. Thread IDs, however, are local to a process. A thread ID from one process has no meaning in another process. We use thread IDs to refer to specific threads as we manipulate the threads within a process. 就像进程一样，线程也用ID标识。然而线程ID是局部的，只在某个进程内有效，出了这个进程，对其他进程来说这个线程ID就没有任何意义了。 threads were added to the UNIX System long after the process model was established 1.7 Error HandlingWhen an error occurs in one of the UNIX System functions, a negative value is often returned, and the integer errno is usually set to a value that tells why. For example, the open function returns either a non-negative file descriptor if all is OK or −1 if an error occurs. An error from open has about 15 possible errno values, such as file doesn’t exist, permission problem, and so on. Some functions use a convention other than returning a negative value. For example, most functions that return a pointer to an object return a null pointer to indicate an error. 当unix系统函数出错时，会返回一个负数，整形变量errno会设置为一个值，这个值告诉我们为什么出错。例如，open函数返回一个非负的文件描述符，如果成功的话，如果出现错误则返回一个-1。open函数返回的错误有15个可能的errno值，比如：文件不存在，权限问题，等等。有些函数使用另一个传统而非返回一个负数。例如，很多函数返回一个对象指针，或者一个空指针如果出现错误。 The file defines the symbol errno and constants for each value that errno can assume. Each of these constants begins with the character E. Also, the first page of Section 2 of the UNIX system manuals, named intro(2), usually lists all these error constants. For example, if errno is equal to the constant EACCES, this indicates a permission problem, such as insufficient permission to open the requested file. &lt;errno.h&gt;文件定义了变量errno和一系列常量（errno可能的值）。每个常量都以字符E开头。unix系统手册intro(2)展示了这些常量。例如，如果errno等于常量EACCES，就表示是权限问题，没有足够的权限去打开这个文件。 On Linux, the error constants are listed in the errno(3) manual page. POSIX and ISO C define errno as a symbol expanding into a modifiable lvalue of type integer. This can be either an integer that contains the error number or a function that returns a pointer to the error number. The historical definition is 1extern int errno; But in an environment that supports threads, the process address space is shared among multiple threads, and each thread needs its own local copy of errno to prevent one thread from interfering with another. Linux, for example, supports multithreaded access to errno by defining it as 12extern int *__errno_location(void); #define errno (*__errno_location()) POSIX和ISO C把errno定义为一个可以修改的左值。可以定义为一个整形值，也可以定义为一个指针，指针指向错误码（String类型）。如果是多线程环境下，每个线程都有自己的一个errno拷贝。通过宏定义把errno给替换成函数：int *__errno_location(void);了。 There are two rules to be aware of with respect to errno. First, its value is never cleared by a routine if an error does not occur. Therefore, we should examine its value only when the return value from a function indicates that an error occurred. Second, the value of errno is never set to 0 by any of the functions, and none of the constants defined in has a value of 0. 第一，如果没有出错，errno的值不会被重置，因此，我们只有在函数返回出错的时候才检查errno；第二，errno不会等于0。 Two functions are defined by the C standard to help with printing error messages. 123#include &lt;string.h&gt;char *strerror(int errnum); //Returns: pointer to message string This function maps errnum, which is typically the errno value, into an error message string and returns a pointer to the string. The perror function produces an error message on the standard error, based on the current value of errno, and returns. 123#include &lt;stdio.h&gt;void perror(const char* msg); It outputs the string pointed to by msg, followed by a colon and a space, followed by the error message corresponding to the value of errno, followed by a newline. ExampleFigure 1.8 shows the use of these two error functions. Figure 1.8 Demonstrate strerror and perror 123456789#include "apue.h"#include &lt;errno.h&gt;int main(int argc, char *argv[])&#123; fprintf(stderr, "EACCES: %s\n", strerror(EACCES)); errno = ENOENT; perror(argv[0]); exit(0);&#125; 输出结果： 1234➜ apue.3e ./fig1.8EACCES: Permission denied./fig1.8: No such file or directory➜ apue.3e argv[0] 表示输入的第一个参数，也就是命令名 Error RecoveryThe errors defined in can be divided into two categories: fatal and nonfatal. A fatal error has no recovery action. The best we can do is print an error message on the user’s screen or to a log file, and then exit. Nonfatal errors, on the other hand, can sometimes be dealt with more robustly. Most nonfatal errors are temporary, such as a resource shortage, and might not occur when there is less activity on the system. 定义在&lt;errno.h&gt;中的错误可以分为两类：fatal和nonfatal，致命和非致命。致命错误没有恢复动作，我们最多能做的就是把错误信息在用户显示屏上打印出来，或者写到log文件里，然后退出。非致命错误，可以更妥善的处理，许多非致命错误都是暂时的，比如：资源短缺，当系统活动较少时这类错误可能不会发生。 Resource-related nonfatal errors include EAGAIN, ENFILE, ENOBUFS, ENOLCK, ENOSPC, EWOULDBLOCK, and sometimes ENOMEM. EBUSY can be treated as nonfatal when it indicates that a shared resource is in use. Sometimes, EINTR can be treated as a nonfatal error when it interrupts a slow system call (more on this in Section 10.5). The typical recovery action for a resource-related nonfatal error is to delay and retry later. This technique can be applied in other circumstances. For example, if an error indicates that a network connection is no longer functioning, it might be possible for the application to delay a short time and then reestablish the connection. Some applications use an exponential backoff algorithm, waiting a longer period of time in each subsequent iteration. 典型的资源相关性非致命错误的处理办法是先等一下，之后再重试。 Ultimately, it is up to the application developer to determine the cases where an application can recover from an error. If a reasonable recovery strategy can be used, we can improve the robustness of our application by avoiding an abnormal exit. 1.8 User IdentificationUser IDThe user ID from our entry in the password file is a numeric value that identifies us to the system. This user ID is assigned by the system administrator when our login name is assigned, and we cannot change it. The user ID is normally assigned to be unique for every user. We’ll see how the kernel uses the user ID to check whether we have the appropriate permissions to perform certain operations. 用户ID来自口令文件中对应的条目，它是以数字的形式帮助系统对我们进行标识。用户ID是系统管理员给我们分配的（当分配登录名时，同时也必须分配用户ID），我们自己无法改。每个人的用户ID应该是唯一的，内核使用用户ID来检查我们是否有合适的权限来进行一个操作。 We call the user whose user ID is 0 either root or the superuser. The entry in the password file normally has a login name of root, and we refer to the special privileges of this user as superuser privileges. As we’ll see in Chapter 4, if a process has superuser privileges, most file permission checks are bypassed. Some operating system functions are restricted to the superuser. The superuser has free rein over the system. 我们把用户ID为0的用户称为：root或者superuser。口令文件中有一个条目的登录名是root，root用户拥有特殊权限。拥有superuser特权的进程可以自由的使用任意文件，而且有些操作系统函数是只对superuser开放的。superuser拥有对系统的绝对的权限（可以把系统弄残）。 Client versions of Mac OS X ship with the superuser account disabled; server versions ship with the account already enabled. Instructions are available on Apple’s Web site describing how to enable it. See http://support.apple.com/kb/HT1528. Group IDOur entry in the password file also specifies our numeric group ID. This, too, is assigned by the system administrator when our login name is assigned. Typically, the password file contains multiple entries that specify the same group ID. Groups are normally used to collect users together into projects or departments. This allows the sharing of resources, such as files, among members of the same group. We’ll see in Section 4.5 that we can set the permissions on a file so that all members of a group can access the file, whereas others outside the group cannot. Group ID的作用就是让相同组的人共享资源。 There is also a group file that maps group names into numeric group IDs. The group file is usually /etc/group. The use of numeric user IDs and numeric group IDs for permissions is historical. With every file on disk, the file system stores both the user ID and the group ID of a file’s owner. Storing both of these values requires only four bytes, assuming that each is stored as a two-byte integer. If the full ASCII login name and group name were used instead, additional disk space would be required. In addition, comparing strings during permission checks is more expensive than comparing integers. 使用数字的用户ID和组ID是有历史原因的。对于每个存放在磁盘上的文件，文件系统都存储了该文件的拥有者的用户ID和组ID。存储这两个数字需要4字节（每个2字节），如果使用ASCII编码的登录名和组名，需要多用掉很多额外的磁盘空间。另外在检查权限是否合格时，整形数字比较要比字符串比较更快。 Users, however, work better with names than with numbers, so the password file maintains the mapping between login names and user IDs, and the group file provides the mapping between group names and group IDs. The ls -l command, for example, prints the login name of the owner of a file, using the password file to map the numeric user ID into the corresponding login name. 然而对于用户来说名字比数字更好记，所以password file和group file分别记录了登录名和用户ID的映射，组名和组ID的映射。使用ls -l命令，可以看到打印出了文件所属者和所属的组，其原理就是查找了password file和group file，把相应的数字ID换成名字。 Early UNIX systems used 16-bit integers to represent user and group IDs. Contemporary UNIX systems use 32-bit integers. ExampleThe program in Figure 1.9 prints the user ID and the group ID. Figure 1.9 Print user ID and group ID 1234567#include "apue.h"int main(void)&#123;trueprintf("uid = %d, gid = %d\n", getuid(), getgid());trueexit(0); &#125; Supplementary Group IDs附加组（supplementary group）：In addition to the group ID specified in the password file for a login name, most versions of the UNIX System allow a user to belong to other groups. This practice started with 4.2BSD, which allowed a user to belong to up to 16 additional groups. These supplementary group IDs are obtained at login time by reading the file /etc/group and finding the first 16 entries that list the user as a member. As we shall see in the next chapter, POSIX requires that a system support at least 8 supplementary groups per process, but most systems support at least 16. 许多unix系统允许用户属于多个组，最多16个。主组，也就是登陆时的默认组记录在/etc/passwd中。 /etc/group格式如下： 12_analyticsusers:*:250:_analyticsd,_networkd,_timed_analyticsd:*:263:_analyticsd 解释： 1组名:口令:组ID:组内用户列表 1.9 SignalSignals are a technique used to notify a process that some condition has occurred. For example, if a process divides by zero, the signal whose name is SIGFPE (floating-point exception) is sent to the process. The process has three choices for dealing with the signal. 信号是一种用来通知进程发生了某些事的技术。举个例子：当进程除以0时，就会有一个SIGFPE (floating-point exception)发送到这个进程。进程处理信号有三种选择： Ignore the signal. This option isn’t recommended for signals that denote a hardware exception, such as dividing by zero or referencing memory outside the address space of the process, as the results are undefined. 忽视信号。如果是硬件异常不推荐这个选择，例如：被0除，引用进程外的内存，因为这些结果都是不确定的。 Let the default action occur. For a divide-by-zero condition, the default is to terminate the process. 让默认动作出现，比如被0除的情况下，默认是终止该进程。 Provide a function that is called when the signal occurs (this is called ‘‘catching’’ the signal). By providing a function of our own, we’ll know when the signal occurs and we can handle it as we wish. 我们自己提供一个函数捕获信号，这样我们就能让程序以我们的意愿处理异常。 Many conditions generate signals. Two terminal keys, called the interrupt key— often the DELETE key or Control-C—and the quit key—often Control-backslash—are used to interrupt the currently running process. Another way to generate a signal is by calling the kill function. We can call this function from a process to send a signal to another process. Naturally, there are limitations: we have to be the owner of the other process (or the superuser) to be able to send it a signal. 很多条件下可以生成信号，终端键有两种，interrupt key（delete键或者ctrl+c）和 quit key（ctrl+\）。另一个生成信号的方法是调用kill函数，我们可以在一个进程里调用kill函数来结束另一个进程，但我们需要有权限（如果我们是另一个进程的拥有者，或者是超级用户，就可以）。 ExampleRecall the bare-bones shell example (Figure 1.7). If we invoke this program and press the interrupt key, the process terminates because the default action for this signal, named SIGINT, is to terminate the process. The process hasn’t told the kernel to do anything other than the default with this signal, so the process terminates. 如果直接执行Figure 1.7的代码，我们按下中断键，程序就会终止，因为这个SIGINT信号的默认动作就是终止进程。 To catch this signal, the program needs to call the signal function, specifying the name of the function to call when the SIGINT signal is generated. The function is named sig_int; when it’s called, it just prints a message and a new prompt. Adding 11 lines to the program in Figure 1.7 gives us the version in Figure 1.10. (The 11 new lines are indicated with a plus sign at the beginning of the line.) 为了捕获这个信号，程序需要调用一个信号函数。我们给它命名为：sig_int函数，在捕获到SIGINT信号之后，打印信息并打印一个新的提示符。下面的程序相比Figure 1.7多了11行，用+号标识了。 Figure 1.10 Read commands from standard input and execute them 123456789101112131415161718192021222324252627282930313233343536 #include "include/apue.h" #include &lt;sys/wait.h&gt; + static void sig_int(int); /* our signal-catching function */+ int main(void) &#123; char buf[MAXLINE]; /* from apue.h */ pid_t pid; int status; + if(signal(SIGINT, sig_int) == SIG_ERR) err_sys("signal error"); printf("%% "); /* print prompt (printf requires %% to print %) */ while (fgets(buf, MAXLINE, stdin) != NULL) &#123; if (buf[strlen(buf) - 1] == '\n') buf[strlen(buf) - 1] = 0; /* replace newline with null */ if ((pid = fork()) &lt; 0) &#123; err_sys("fork error"); &#125; else if (pid == 0) &#123; /* child */ execlp(buf, buf, (char *)0); err_ret("couldn’t execute: %s", buf); exit(127);truetrue &#125; /* parent */ if ((pid = waitpid(pid, &amp;status, 0)) &lt; 0) err_sys("waitpid error"); printf("%% ");true &#125;true exit(0); &#125;++ void sig_int(int signo)&#123;+ printf("interrupt\n%% ");+ &#125; 1.10 Time ValuesHistorically, UNIX systems have maintained two different time values: Calendar time. This value counts the number of seconds since the Epoch: 00:00:00 January 1, 1970,Coordinated Universal Time (UTC). (Older manuals refer to UTC as Greenwich Mean Time.) These time values are used to record the time when a file was last modified, for example. The primitive system data type time_t holds these time values. Process time. This is also called CPU time and measures the central processor resources used by a process. Process time is measured in clock ticks, which have historically been 50, 60, or 100 ticks per second. The primitive system data type clock_t holds these time values. (We’ll show how to obtain the number of clock ticks per second with the sysconf function in Section 2.5.4.) 有两种类型的时间：日历时间和进程时间，日历时间也就是UTC。 When we measure the execution time of a process, as in Section 3.9, we’ll see that the UNIX System maintains three values for a process: Clock time User CPU time System CPU time The clock time, sometimes called wall clock time, is the amount of time the process takes to run, and its value depends on the number of other processes being run on the system. Whenever we report the clock time, the measurements are made with no other activities on the system. The user CPU time is the CPU time attributed to user instructions. The system CPU time is the CPU time attributed to the kernel when it executes on behalf of the process. For example, whenever a process executes a system service, such as read or write, the time spent within the kernel performing that system service is charged to the process. The sum of user CPU time and system CPU time is often called the CPU time. 度量进程执行时间，有三种： 墙上时钟，也就是进程执行花费的总时间。 用户CPU时间，是用户模式（非内核）下的CPU使用时间 系统CPU时间，是进程进入内核执行的CPU使用时间 It is easy to measure the clock time, user time, and system time of any process: simply execute the time(1) command, with the argument to the time command being the command we want to measure. For example: 12$ cd /usr/include$ time -p grep _POSIX_SOURCE */*.h &gt; /dev/null 结果： 123real 0m0.81suser 0m0.11ssys 0m0.07s The output format from the time command depends on the shell being used, because some shells don’t run /usr/bin/time, but instead have a separate built-in function to measure the time it takes commands to run. time命令的输出格式取决于使用什么shell，因为有些shell并不运行：/usr/bin/time，而是运行自己内置的一个time函数。 1.11 System Calls and Library FunctionsAll operating systems provide service points through which programs request services from the kernel. All implementations of the UNIX System provide a well-defined, limited number of entry points directly into the kernel called system calls (recall Figure 1.1). Version 7 of the Research UNIX System provided about 50 system calls, 4.4BSD provided about 110, and SVR4 had around 120. The exact number of system calls varies depending on the operating system version. More recent systems have seen incredible growth in the number of supported system calls. Linux 3.2.0 has 380 system calls and FreeBSD 8.0 has over 450. 随着时间的推移，系统调用越来越多，可见系统是越来越完善的。 The system call interface has always been documented in Section 2 of the UNIX Programmer’s Manual. Its definition is in the C language, no matter which implementation technique is actually used on any given system to invoke a system call. This differs from many older operating systems, which traditionally defined the kernel entry points in the assembly language of the machine. 系统调用的文档总是在unix编程手册的第二个章节里。它是用C语言定义的，不管系统具体是如何实现系统调用的。这一点与很多老操作系统不同（老操作系统使用汇编语言定义内核接口） The technique used on UNIX systems is for each system call to have a function of the same name in the standard C library. The user process calls this function, using the standard C calling sequence. This function then invokes the appropriate kernel service, using whatever technique is required on the system. For example, the function may put one or more of the C arguments into general registers and then execute some machine instruction that generates a software interrupt in the kernel. For our purposes, we can consider the system calls to be C functions. 每个系统调用都对应一个相同名字的函数在标准C库里。用户进程调用这个函数，然后这个函数调用相应的内核服务。举个例子，这个函数可能会把一个或多个C参数放到通用寄存器，并执行机器指令在内核中产生一个软件中断。从我们的角度看，我们可以直接认为系统调用就是C函数。 Section 3 of the UNIX Programmer’s Manual defines the general-purpose library functions available to programmers. These functions aren’t entry points into the kernel, although they may invoke one or more of the kernel’s system calls. For example, the printf function may use the write system call to output a string, but the strcpy (copy a string) and atoi (convert ASCII to integer) functions don’t involve the kernel at all. 在unix编程手册第三章定义了通用库函数给程序员。这些函数不是内核入口，虽然它们可能会调用一个或几个内核的系统调用。举个例子，printf函数可能会使用write系统调用来输出一个字符串，但是strcpy（拷贝一个字符串）和atoi（吧ASCII字符转成整形）函数根本没有调用内核。 From an implementor’s point of view, the distinction between a system call and a library function is fundamental. From a user’s perspective, however, the difference is not as critical. From our perspective in this text, both system calls and library functions appear as normal C functions. Both exist to provide services for application programs. We should realize, however, that we can replace the library functions, if desired, whereas the system calls usually cannot be replaced. 从实现者的角度来看，系统调用和库函数的区别是很大的。然而从使用者的角度来看，这个区别并不重要。在这本书中，在我们看来，系统调用和库函数都以C函数的形式出现。两者的存在都是为了给应用开发者提供服务。然而我们应该意识到，虽然我们能替换库函数（如果我们想这样做），但系统调用不能被替换。 Consider the memory allocation function malloc as an example. There are many ways to do memory allocation and its associated garbage collection (best fit, first fit, and so on). No single technique is optimal for all programs. The UNIX system call that handles memory allocation, sbrk(2), is not a general-purpose memory manager. It increases or decreases the address space of the process by a specified number of bytes. How that space is managed is up to the process. The memory allocation function, malloc(3), implements one particular type of allocation. If we don’t like its operation, we can define our own malloc function, which will probably use the sbrk system call. In fact, numerous software packages implement their own memory allocation algorithms with the sbrk system call. Figure 1.11 shows the relationship between the application, the malloc function, and the sbrk system call. 让我们来看看内存分配函数malloc这个例子。有很多内存分配和相关的垃圾回收方法（最好适应算法，最先适应算法，等等）。没有哪个技术是对所有程序优化的。unix系统调用sbrk(2)不是一个通用的存储管理器。它给进程增加和减少内存空间都是固定的字节数。怎么管理空间其实还要取决于进程自己。内存分配函数malloc(3)，实现了特定类型的分配。如果我们不喜欢它的做法，我们可以定义自己的malloc函数，但也是要用到sbrk系统调用的。实际上大量的软件包都通过直接使用sbrk系统调用实现了自己的内存管理算法。图1.11展示了应用，malloc函数，和sbrk系统调用之间的关系。 Here we have a clean separation of duties: the system call in the kernel allocates an additional chunk of space on behalf of the process. The malloc library function manages this space from user level. 这里职责是分明的：系统调用代表进程在内核里分配了额外的一块空间。malloc库函数在用户层级上管理这块空间。 Another example to illustrate the difference between a system call and a library function is the interface the UNIX System provides to determine the current time and date. Some operating systems provide one system call to return the time and another to return the date. Any special handling, such as the switch to or from daylight saving time, is handled by the kernel or requires human intervention. The UNIX System, in contrast, provides a single system call that returns the number of seconds since the Epoch: midnight, January 1, 1970, Coordinated Universal Time. Any interpretation of this value, such as converting it to a human-readable time and date using the local time zone, is left to the user process. The standard C library provides routines to handle most cases. These library routines handle such details as the various algorithms for daylight saving time. 另一个描述系统调用和库函数不同的例子是当前时间和日期。某些操作系统提供一个系统调用返回时间，另一个系统调用返回日期。任何特殊的处理，比如正常时制与夏令时的切换，需要内核的处理或者人为干预。Unix系统则相反，只提供一个系统调用，返回UTC（UTC是指从1970年的第一秒开始算起到现在经过的总时间）。任何对UTC这个值的解释，例如把它转成人类可读的时间日期使用当地时间，就留给了用户进程。标准C库提供了诸多例程来处理大多数情况。这些库例程处理这些细节，就像大多数算法处理夏令时切换一样。 An application can either make a system call or call a library routine. Also realize that many library routines invoke a system call. This is shown in Figure 1.12. 一个应用可以使用系统调用或者调用库例程，同样要意识到许多库例程调用了系统调用。 Another difference between system calls and library functions is that system calls usually provide a minimal interface, whereas library functions often provide more elaborate functionality. We’ve seen this already in the difference between the sbrk system call and the malloc library function. We’ll see this difference again later, when we compare the unbuffered I/O functions (Chapter 3) and the standard I/O functions (Chapter 5). 另一个系统调用和库函数的区别就是，系统调用往往只提供一个很小的接口，然而库函数经常提供更多精细的功能。 The process control system calls (fork, exec, and waitpid) are usually invoked by the user’s application code directly. (Recall the bare-bones shell in Figure 1.7.) But some library routines exist to simplify certain common cases: the system and popen library routines, for example. In Section 8.13, we’ll show an implementation of the system function that invokes the basic process control system calls. We’ll enhance this example in Section 10.18 to handle signals correctly. To define the interface to the UNIX System that most programmers use, we have to describe both the system calls and some of the library functions. If we described only the sbrk system call, for example, we would skip the more programmer-friendly malloc library function that many applications use. In this text, we’ll use the term function to refer to both system calls and library functions, except when the distinction is necessary.]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《APUE-3rd》</category>
      </categories>
      <tags>
        <tag>Unix</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mathjax常用公式记录]]></title>
    <url>%2Fblog%2F2018%2F04%2F30%2Fmathjax%E5%B8%B8%E7%94%A8%E5%85%AC%E5%BC%8F%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[角度记法 度数：60^\circ，$60^\circ$ 度数分：60^\prime，$60^\prime$ 弧度：\frac{\pi}{2}，$\frac{\pi}{2}$ 角度记法：\angle A，$\angle A$ 三重环积分无法渲染的问题在网上找了半天资料最终解决了，参考这个答案：How do you render a closed surface double integral?，做法是直接使用Unicode编码：\unicode{x222F}，三重环积分的编码，参考这里：unicode-search.net，所以只要将\oiiint换成\unicode{x2230}即可正确显示三重环积分。如下： \unicode{x2230}行内limit1$\lim\limits_&#123;x\rightarrow 0&#125; \frac&#123;\sin x&#125;&#123;x&#125; = 1$ 效果：$\lim\limits_{x\rightarrow 0} \frac{\sin x}{x} = 1$ 1$\lim_&#123;x\rightarrow 0&#125; \frac&#123;\sin x&#125;&#123;x&#125; = 1$ 效果：$\lim_{x\rightarrow 0} \frac{\sin x}{x} = 1$ 凭个人喜好，我就更喜欢第一种。 弧1$\overset&#123;\frown&#125; &#123;AB&#125;$ $\overset{\frown} {AB}$]]></content>
      <categories>
        <category>工具</category>
        <category>LaTex</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Markdown+MathJax搭建个人博客]]></title>
    <url>%2Fblog%2F2018%2F04%2F25%2FHexo%2BMarkdown%2BMathJax%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[为什么搭建个人博客其实有想过用简书写博客，但简书不支持 mathjax，而我写作的时候要用到不少数学公式。 以前也用过 leanote，也就是现在的 蚂蚁笔记，但蚂蚁笔记的博客中，[TOC] 是有 mathjax 渲染的，但右上角的目录导航却是没有加 mathjax 渲染的，这样看着会相当别扭。另外还有几个原因： leanote收费 无法彻底的自定义 博客不像使用静态网站引擎那样直观的以文件的形式展示在我面前 为什么选 hexo为什么选择 hexo，而不是 jekyll，或者 hugo。 其实我以前的博客是用的 jekyll，弃用 jekyll 是因为这东西实在是太慢了，我更新文章之后无法立即看到结果，要刷新很多次，或者说要等很久，git pages 上才会显示新的东西。听说 hexo 和 hugo 的速度都比较快，所以就换了 hexo，hexo 的主题比 hugo 多，另外 hugo 的官网和主题网站访问实在太慢了，成功恶心到了我。所以我最后选了 hexo，用上了经典主题 next。现在来说，主要是next主题吸引我，而hugo的next主题太简陋了。 hexo 是用 nodejs 写的，jekyll 是用 ruby 写的，hugo 是用 go 语言写的，wordpress 是用 php 实现的。 那为什么不用 wordpress 呢，因为我想用 git pages 这个平台，而这个平台只支持静态博客。 搭建过程环境配置首先你要安装 git 和 npm，git 是一种版本控制工具，npm 则是 nodejs 的包管理工具。 mac 上，使用 brew 和 brew cask 可以像许多 Linux 系统一样直接通过命令行安装软件。 12brew install gitbrew install node 另外很不幸的是 git 和 npm 在国内都是无法愉快的使用的，虽然没有被墙，但是速度奇慢无比。于是我们需要做些工作： 给 git 挂代理： 12git config --global http.proxy https://127.0.0.1:1087git config --global https.proxy https://127.0.0.1:1087 但为了实现上面的功能，首先你得有个翻墙代理。关于翻墙都可以额外写篇文章了。 想看详细的解决办法： https://www.zhihu.com/question/27159393 https://www.zhihu.com/question/27159393/answer/141047266 然后给 npm 换源： 12npm config set registry https://registry.npm.taobao.orgnpm info underscore （这个只是为了检验上面的设置命令是否成功，若成功，会返回[指定包]的信息） 想看更详细的解决办法： https://segmentfault.com/a/1190000007829080 好了，之后就是 hexo 安装 初始化 blog 目录 然后 hexo server 开启本地服务器，一个 demo 就出现啦。 命令如下： 123npm install hexo-cli -ghexo init bloghexo server 基本的建站过程从 jekyll 迁移到 hexo我是从 jekyll 迁移过来的，所以先把文章全都拷贝进 source/_posts 目录下面，然后修改 _config.yml，把： 1new_post_name: :title.md 变成： 1new_post_name: :year-:month-:day-:title.md 官网迁移教程：https://hexo.io/zh-cn/docs/migration.html 下载 next 主题并添加 mathjax然后下载一个 next 主题： 1git clone https://github.com/iissnan/hexo-theme-next themes/next 然后修改 _config.yml，把： 1theme: landscape 变成： 1theme: next 然后修改 next 的 _config.yml，把： 1234mathjax: enable: false per_page: false cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config#TeX-AMS-MML_HTMLorMML 变成： 1234mathjax: enable: true per_page: false cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config#TeX-AMS-MML_HTMLorMML 注意per_page不能是true，一定要是false。 解决 markdown 与 mathjax 的冲突为了解决 markdown 下划线转义成 &lt;em&gt; 标签（HTML标签），从而导致 mathjax 的下标无法使用，这个问题，我们修改 marked.js 文件，如果你使用的是 sublime text 或者 Atom 编辑器，cmd+o打开你的博客目录，然后 cmd+p 输入你要在此目录下找的文件名：marked.js 就可以找到这个文件。这个文件的是：node_modules/marked/lib/marked.js。 总共发现 mathjax 中的三处冲突： _变成了&lt;em&gt;，造成数学公式下标无法显示 \\变成了单个\，数学公式\begin{case}...\end{case}之间换行需要用到\\ &lt; xxx &gt;大于号小于号之间会新增一个 #&quot;&quot; 将 1escape: /^\\([\\`*&#123;&#125;\[\]()# +\-.!_&gt;])/, 改为 1escape: /^\\([`*&#123;&#125;\[\]()# +\-.!_&gt;])/, 这样就去掉了，双斜杠转义。 把 1em: /^\b_((?:[^_]|__)+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 改为 1em:/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 这样就禁掉了 _ 变 &lt;em&gt;（斜体标记）。 最后，为了解决第三个冲突，我把 &gt; 写成了 HTML 实体形式：&amp;gt;，这样就无法组成一对尖括号了，终于不会冲突了。 我为什么不装个 hexo-renderer-pandoc + pandoc ，说出来都是泪啊，装了啊，一执行就报错，google 了一圈，没有有用的解答，遂作罢。 2019-01-11更新：这种修改源码的方式其实是及其不推荐的，因为如果重新npm install的话，修改就作废了。现在的hexo-renderer-marked已经修复了_和&gt;的问题，但是依然存在\\的问题。有一个渲染器hexo-renderer-kramed，以上三个问题都完美解决。 解决语言不正确的问题我发现有些地方居然默认的是德语还是什么其他语言，反正不是英语，所以我们需要改： 根目录下的 _config.yml next 主题的 _config.yml 两个都改成： 1language: en 生成 public 静态网站目录 和 部署到 github生成静态网站目录： 1hexo g 下载 hexo-deployer-git 插件： 1npm install hexo-deployer-git --save 再修改 _config.yml，把： 12deploy: type: 变成： 1234deploy: type: git repo: https://github.com/liuqinh2s/liuqinh2s.github.io branch: master 然后，用命令 hexo d 部署就行了，不过首先你得有个 github 账号，然后还得有个叫 liuqinh2s.github.io 的项目，然后你还得配置好 github 环境： 12git config --global user.name &quot;Your Name Here&quot;git config --global user.email &quot;your_email@example.com&quot; 然后把公钥的内容传给 github 就行了。这里只说原理，具体的操作懒得贴了。 只有多懂原理（哪怕只是基本的原理），你才能顺利解决遇到的诸多问题。 官网的部署教程：https://hexo.io/zh-cn/docs/deployment.html 基本的建站就结束了，然后就是慢慢把博客进行个性化吧。 hexo 个性化配置 hexo-reference，用来支持 markdown 脚注的 hexo-generator-seo-friendly-sitemap，sitemap用来喂给搜索引擎的，更好的爬取网站 hexo-generator-search，博客内部搜索 hexo-wordcount，统计字数用的 然后就是调 next 主题，把自己喜欢的特性用上。 然后就是加上 不蒜子，百度统计这类统计工具，和 disqus 评论等等。 遇到的问题以及解决方案如何使用HTML锚点如果不了解HTML锚点，可以参考这个： w3school — HTML 链接 百度百科 — 锚点。HTML可以在页面内跳转，只需要定义一个锚点，访问的时候 将 # 符号和锚名称添加到 URL 的末端。 markdown本身是没有这个功能的，所以我们直接把标题用HTML写出来就行了。标题的对应是 # 到 ###### 总共6级，分别对应 &lt;h1&gt; 到 &lt;h6&gt;。 举个例子：&lt;h4 id=&quot;3.2.3&quot;&gt;解决 markdown 与 mathjax 的冲突&lt;/h4&gt; 这里要注意的是：不要使用name属性，而必须使用id属性，否则会不起作用 实际上可以使用一个markdown插件来实现：上标、下标、锚点、脚注。 12npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --save 锚点的用法，其实可以先hexo g一下，然后看看生成的HTML长什么样，就知道改怎么引用锚点了，经我观察，空格会被渲染成-，比如一个四级标题： 1#### 解决 markdown 与 mathjax 的冲突 会被渲染成： 1&lt;h4 id="解决-markdown-与-mathjax-的冲突"&gt;&lt;a class="header-anchor" href="#解决-markdown-与-mathjax-的冲突"&gt;¶&lt;/a&gt;解决 markdown 与 mathjax 的冲突&lt;/h4&gt;]]></content>
      <categories>
        <category>动手实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数学基础公式推导]]></title>
    <url>%2Fblog%2F2018%2F04%2F25%2F%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[今天看到下面这个公式，突然想我好像不会推导啊： $\sin(\beta-\alpha) = \sin\beta\cos\alpha - \cos\beta\sin\alpha$ 遂想如何推导，在youtube上找了一个视频：三角函数正余弦和角公式推导 思路是先推导出：$\cos(\beta-\alpha) = \cos\alpha\cos\beta + \sin\alpha\sin\beta$ 然后根据这个再结合正弦余弦之间的关系就很容易推 $\sin(\beta-\alpha) = \sin\beta\cos\alpha - \cos\beta\sin\alpha$ 那么怎么推导上面这个公式呢？ 需要用到解析几何： 结合 勾股定理 和 余弦定理 可以推导出。 根据勾股定理： \begin{align} \overline{PQ}^2 & = (\sin\alpha - \sin\beta)^2 + (\cos\beta - \cos\alpha)^2 \\ & = 2 - 2(\cos\alpha\cos\beta + \sin\alpha\sin\beta) \\ \end{align}根据余弦定理（$a^2 = b^2 + c^2 -2ab\cos A$）： \begin{align} \overline{PQ}^2 & = 1^2 + 1^2 - 2\cdot1\cdot1\cdot\cos(\alpha-\beta) \end{align}由此推出： \cos(\alpha-\beta) = \sin\alpha\sin\beta+\cos\alpha\cos\beta也即： \cos(\beta-\alpha) = \sin\alpha\sin\beta+\cos\alpha\cos\beta然后： \begin{align} \sin(\beta-\alpha) &= \cos(\frac{\pi}{2}-(\beta-\alpha)) \\ &= \cos((\frac{\pi}{2}+\alpha) - \beta) \\ &= \sin(\frac{\pi}{2}+\alpha)\sin\beta + \cos(\frac{\pi}{2}+\alpha)\cos\beta \\ &= \cos\alpha\sin\beta - \sin\alpha\cos\beta \\ &= \sin\beta\cos\alpha - \cos\beta\sin\alpha \end{align} 勾股定理和余弦定理的证明比较简单，读者可以试着自证。]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Override Overload Overwrite]]></title>
    <url>%2Fblog%2F2017%2F11%2F14%2FOverride-Overload-Overwrite%2F</url>
    <content type="text"><![CDATA[我们都知道有些东西容易混淆，在加上中文翻译得乱七八糟，更加让人困惑。今天我要讲的这三位可就真是绝了。 它们是：Override、Overload、Overwrite。 这是我查有道词典时候看到的可怕一幕： Override 一个把三个名字都占了，你怕不怕？反正我是看的心里一紧。 如果把概念都煮成了一锅粥，那还不如不要记这些概念，你应该向更深层次去探寻。就这三个的区别来说，我觉得主要理解两个概念就行了： 函数签名（signature） 多态（polymorphism、polymorphic） 函数签名函数签名是什么，其实就是用来区别函数的，两个函数怎么样认定是不同的两个函数呢，只有两个方面： 函数名 参数 有人说还有返回值啊，不行，返回值不能作为函数签名的一部分，因为你调用一个函数的时候，返回值根本不能帮助编译器来识别你用的是哪个函数，比如： 1234int func(int a, int b);float func(int a, int b);func(); 请问我使用的是哪个函数？你看返回值确实不行吧。 多态多态是面向对象编程的概念，你可以看看它的准确定义： Polymorphism)。 定义很简短：polymorphism is the provision of a single interface to entities of different types. The Java™ Tutorials 如果父类有一个函数，子类也定义了一个完全相同的函数（函数签名相同），那么你可以用父类指针（或者说父类对象）作为统一的接口，来调用子类的方法。比如： 123456789101112131415161718192021222324252627class Vehicle&#123; public void move()&#123; System.out.println(“Vehicles can move!!”); &#125;&#125;class MotorBike extends Vehicle&#123; public void move()&#123; System.out.println(“MotorBike can move and accelerate too!!”); &#125;&#125;class Car extends Vehicle&#123; public void move()&#123; System.out.println(“Hi! I am a car!”); &#125;&#125;class Test&#123; public static void main(String[] args)&#123; Vehicle vh = new MotorBike(); vh.move(); // prints MotorBike can move and accelerate too!! vh = new Vehicle(); vh.move(); // prints Vehicles can move!! vh = new Car(); vh.move(); // prints Hi! I am a car! &#125;&#125; 多态的好处是可以扩展啊，比如我后来又多了个 truck 类，我不需要去动已经写好的代码，只要把 truck 模块写好，加进去就行了。 Override、Overload、Overwrite 的区别好了，知道了这两个概念，我们再来看看上面的那三个混在一起的东西： Override（推翻，对英文意思就是这个）subclass method overrides base class method means: in different range (in derived class and base class) the same function signature the base class method is virtual（if in C++） overload（超载）function overloading means: the same range (in the same class) the same function name but different function signature overwrite（重写）subclass method hides base class method means: in different range (in derived class and base class) the same function name 我们应该记住只有 Override 才跟多态有关。 Overload 是本class 里面的不同函数（只不过函数名一样罢了，其实是两个不同的函数，看两个函数是否是同一个函数就看函数签名就行了），其实没啥稀奇的，不就是函数名一样嘛。函数签名一样，区分出是用父类还是子类的函数，这才是面向对象和多态要解决的问题。 Override 和 Overwrite 的区别 比较容易混淆的其实是 Override 和 Overwrite，但你只要死记住：Override 必须函数签名要一样，而 Overwrite 只需函数名一样即可。另外 C++ 中一定要用virtual才算 Override，而 Java 默认就是 Override，不需要修饰词。 这里关于 Java 和 C++ 面向对象的细节区别可以写一大堆，比如：C++ class 后面是要加分号的，而 Java 不需要；但 Java 的类名是和文件名要一致的，而且只能有一个 public 类，而 C++不需要；Java 直接就能用 Override，而 C++必须要使用 virtual 关键字才能使用 Override（虚函数）；Java 的抽象方法跟 C++的纯虚函数对应。Java 是单继承，由接口来实现“多继承”，C++是多继承，没有接口，只有抽象类。C++还有个虚基类的概念。具体的写法上还有很多的不同，多用这两种语言写面向对象的代码，就慢慢会知道了。 C++ 有一个 virtual 关键字和 virtual table 这个概念，没有加 virtual 的父类函数是不可能形成多态的，如果这时候你碰到父类和子类两个里面有同名的函数，那么就属于 Overwrite 这个概念了，你其实也可以称这种覆盖掉父类函数的行为为：hide 隐藏。Java 这种语言里面没有 virtual 这一套，Java 也可以表现出 Overwrite，但要注意函数签名如果一样的话，那又不叫 Overwrite 了，应该叫 Override 了（Java 如果要在子类中使用父类的同函数签名方法，则必须使用 super 关键字）。而 C++ 不一样，即便是函数签名一样，如果前面不加 virtual 是不能叫 Override 的，仍然属于 Overwrite 的概念。请看下面的例子： 用 C++ 写的话： 12345678910111213141516171819202122232425#include &lt;iostream&gt;using std::cout;using std::endl;class A&#123;public: void func(int a)&#123; cout &lt;&lt; "A" &lt;&lt; endl; &#125;&#125;;class B:public A&#123;public: void func(int a)&#123; cout &lt;&lt; "B" &lt;&lt; endl; &#125;&#125;;int main()&#123; A *a = new B(); a-&gt;func(1); ((B*)a)-&gt;func(1); return 0;&#125; 结果输出： 12AB 可以看到，C++必须要用子类类型的指针才能访问到子类的部分（建议看一本书，叫：Inside the C++ Object Model，中文叫：深入C++对象模型，里面讲对象的内存布局讲的很清楚），java 也一样，必须转成子类型的指针才能访问，否则 IDE 会报错提示你。 Java 代码： 1234567891011121314151617181920public class test &#123; class A&#123; void func(int a)&#123; System.out.println("A"); &#125; &#125; class B extends A&#123; void func(int a, int b)&#123; System.out.println("B"); &#125; &#125; public static void main(String[] args)&#123; test t = new test(); A a = t.new B(); a.fun(1); ((B)a).func(1,2); &#125;&#125; 结果输出： 12AB 为什么 Java 代码里不像 C++ 代码里面那样，使用两个函数签名相同的函数？因为前面说过了，那样的话就变成 Override 了，只有在 C++ 里才能实现函数签名相同的 Overwrite（不使用virtual即可）。]]></content>
      <categories>
        <category>编程概念</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Inside the C++ Object Model 系列笔记 四 -- The Semantics of Function]]></title>
    <url>%2Fblog%2F2017%2F10%2F23%2FInside-the-C%2B%2B-Object-Model-%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0--The-Semantics-of-Function%2F</url>
    <content type="text"><![CDATA[c++支持三种类型的成员函数，分别为static,nostatic,virtual。每一种调用方式都不尽相同。 nonstatic member functionC++的设计准则之一就是:nonstatic member function至少必须和一般的nonmember function 有相同的效率。实际上，nonstatic member function 会被编译器进行如下的转换，变成一个普通函数: Type1 X::foo(Type2 arg1) { … } 会被转换为如下的普通函数: void foo(X *const this, Type1 &amp;__result, Type2 arg1) { … } 改写函数原型，在参数中增加this指针，对每一个”nonstatic data member的存取操作”改为由this指针来存取 将member function重写为一个外部函数，经过”mangling”处理（不需要处理的加上 extern “C”） 实际上，普通函数、普通成员函数、静态成员函数到最后都会变成与C语言函数类似的普通函数，只是编译器在这些不同类型的函数身上做了不同的扩展，并放在不同的 scope 里面而已。 编译器内部会将成员函数等价转换为非成员函数，具体是这样做的: 1.改写成员函数的签名，使得其可以接受一个额外参数，这个额外参数即是this指针： 123float Point::X();//成员函数X被插入额外参数thisfloat Point:: X(Point* this ); 当然如果成员函数是const的，插入的参数类型将为 const Point* 类型。 2.将每一个对非静态数据成员的操作都改写为经过this操作。 3.将成员函数写成一个外部函数，对函数名进行“mangling”处理，使之成为独一无二的名称。 可以看出，将一个成员函数改写成一个外部函数的关键在于两点，一是给函数提供一个可以直接读写成员数据的通道；二是解决好有可能带来的名字冲突。第一点通过给函数提供一个额外的指针参数来解决，第二点则是通过一定的规则将名字转换，使之独一无二。 于是在VC中对于上面的例子中的成员函数的调用将发生如下的转换： 1234//p-&gt;X();被转化为?X@Point@@QAEMXZ(p);//obj.X();被转化为?X@Point@@QAEMXZ(&amp;obj); 覆盖（override）、重载（overload）、隐藏（hide, overwrite）的区别： 覆盖（也叫重写）是指在派生类中重新对基类中的虚函数（注意是虚函数）重新实现。即函数名和参数都一样（函数签名一样），只是函数的实现体不一样。 重载是指 在同一个类中 不同的函数使用相同的函数名，但是函数的参数个数或类型不同。调用的时候根据函数的参数来区别不同的函数。 隐藏是指派生类中的函数把基类中相同名字的函数屏蔽掉了。隐藏与另外两个概念表面上看来很像，很难区分，其实他们的关键区别就是在多态的实现上。 C++多态（polymorphism）表示”以一个public base class的指针（或者reference），寻址出一个derived class object” 我专门写了一篇关于这些容易弄混的概念的文章：Override Overload Overwrite Virtual Member Function如果function()是一个虚拟函数，那么用指针或引用进行的调用将发生一点特别的转换——一个中间层被引入进来。例如： 123// p-&gt;function()//将转化为(*p-&gt;vptr[1])(p); 其中vptr为指向虚函数表的指针，它由编译器产生。vptr也要进行名字处理，因为一个继承体系可能有多个vptr。 1是虚函数在虚函数表中的索引，通过它关联到虚函数function(). 何时发生这种转换？答案是在必需的时候 — 一个再熟悉不过的答案。当通过指针调用的时候，要调用的函数实体无法在编译期决定，必需待到执行期才能获得，所以上面引入一个间接层的转换必不可少。但是当我们通过对象（不是引用，也不是指针）来调用的时候，进行上面的转换就显得多余了，因为在编译器要调用的函数实体已经被决定。此时调用发生的转换，与一个非静态成员函数(Nonstatic Member Functions)调用发生的转换一致。p.function()的处理就跟非静态成员函数一样了。 Static Member Function 不能够直接存取其类中的非静态成员（nostatic members），包括不能调用非静态成员函数(Nonstatic Member Functions)。 不能声明为const、volatile或virtual 参数没有this 可以不用对象访问，直接 类名::静态成员函数 访问，当然，通过对象调用也被允许 需要注意的是通过一个表达式或函数对静态成员函数进行调用，被C++ Standard要求对表达式进行求值。如： 12(a+=b).static_fuc();func().static_fuc(); 虽然省去对a+b求值对于static_fuc()的调用并没有影响，但是程序员肯定会认为表达式a+=b已经执行，一旦编译器为了效率省去了这一步，很难说会浪费多少程序员多少时间去查找这个bug。这无疑是一个明智的规定。func()返回一个对象。 vtable的内容： virtual class offset（有虚基类才有） topoffset typeinfo 继承基类所声明的虚函数实例，或者是覆盖（override）基类的虚函数 新的虚函数（或者是纯虚函数占位） 虚函数表的构造挺简单的： 从内存布局的角度看，类对象继承基类的时候只把基类的 nonstatic data member和member function（函数入口，也可以说是函数指针） 放进自己内存里，static data member和static function都在global address里面。然后就是虚函数表是复制了一份基类的虚函数表，然后把virtual实现了的部分替换掉，没实现的就不改，依然用父类的。然后虚函数表指针自然也要不一样，毕竟指向的内存地址不一样，对吧。 Inside the C++ Object Model 系列笔记向导 Inside the C++ Object Model 系列笔记 一 — Object Lessons Inside the C++ Object Model 系列笔记 二 — The Semantics of constructors Inside the C++ Object Model 系列笔记 三 — The Semantics of Data Inside the C++ Object Model 系列笔记 四 — The Semantics of Function]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《Inside the C++ Object Model》</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inside the C++ Object Model 系列笔记 三 -- The Semantics of Data]]></title>
    <url>%2Fblog%2F2017%2F10%2F21%2FInside-the-C%2B%2B-Object-Model-%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0--The-Semantics-of-Data%2F</url>
    <content type="text"><![CDATA[C++对象模型的细节，讨论了 data members 的处理。 空类在内存中有空间吗 一个实例引出的思考： 1234class X&#123;&#125;;class Y:virtual public X&#123;&#125;;class Z:virtual public X&#123;&#125;;class A:public Y, public Z&#123;&#125;; 猜猜sizeof上面各个类都为多少？ Lippman的一个法国读者的结果是： 1234sizeof X yielded 1sizeof Y yielded 8sizeof Z yielded 8sizeof A yielded 12 Lippman自己的结果是： 1234sizeof X yielded 1sizeof Y yielded 4sizeof Z yielded 4sizeof A yielded 8 事实上，对于像X这样的一个空类，编译器会对其动点手脚——隐晦的插入一个字节。为什么要这样做呢？插入了这一个字节，那么X的每一个对象都将有一个独一无二的地址。如果不插入这一个字节呢？哼哼，那对X的对象取地址的结果是什么？两个不同的X对象间地址的比较怎么办？ 我们再来看Y和Z。首先我们要明白的是实现虚继承，将要带来一些额外的负担——额外需要一个某种形式的指针。到目前为止，对于一个32位的机器来说Y、Z的大小应该为5，而不是8或者4。我们需要再考虑两点因素：内存对齐（alignment—）和编译器的优化。 空类也有1Byte的大小，因为这样才能使得这个class的2个objects在内存中有独一无二的地址。 The Binding of a Data Member考虑下面这样的代码： 1234567891011extern float x;class Point3d&#123;public:truePoint3d(float, float, float);true//问题是 x 到底是哪个 x 呢truefloat X() const &#123;return x;&#125;truevoid X(float new_x) const&#123;x = new_x;&#125;private:truefloat x;&#125; 对member functions本身的分析会直到整个class的声明都出现了才开始（直到看到代表 class 结束的}右大括号）。所以class的 member functions 可以引用声明在后面的成员，C 语言就做不到。 和member functions对比，需要十分注意的一点是:class中的typedef并不具备这个性质。因此，类中的 typedef 的影响会受到函数与 typedef 的先后顺序的影响。 1234567typedef int length;class Point3d&#123;public:truevoid f1(length l)&#123; cout &lt;&lt; l &lt;&lt; endl; &#125;truetypedef string length;truevoid f2(length l)&#123; cout &lt;&lt; l &lt;&lt; endl; &#125;&#125;; 这样 f1 绑定的 length 类型是 int;而 f2 绑定的 length 类型才是 string。 所以，对于 typedef 需要防御性的程序风格:始终把 nested type 声明(即 typedef)放在 class 起始处! Data Member LayoutC++只保证处于同一个 access section（也就是private,public,protected片段）的数据，一定会以声明的次序出现在内存布局当中(要求较晚出现的数据成员处在较大的内存地址中)。C++标准只提供了这一点点的保证。允许编译器将多个Acess Section的顺序自由排列，而不必在乎它们的声明次序。但似乎没有编译器这样做。对于继承类，C++标准并未指定是其基类成员在前还是自己的成员在前。 12345678class X &#123;public: int i; int j;private: int k; int n;&#125; 数据 i 一定在 j 之前，k 一定在 n 之前。具体什么顺序就看编译器了。 传统上，vptr被安放在所有被明确声明的member的最后，不过也有些编译器把vptr放在最前面(MSVC++就是把 vptr 放在最前面，而 G++ 是把 vptr 放在最后面)。 Access of a Data Member在C++中，直观上来说，由一个对象存取一个member会比由一个指针存取一个member更快捷。但是对于经由一个对象来存取和由一个指针来存取一个静态的 member 来说，是完全一样的，都会被编译器所扩展。 经由 member selection operators（也就是 “.” 运算符）对一个 static data member 进行存取操作只是一种语法上的便宜行事而已。member 其实并不在 class object 中，因此存取并不需要通过 class object。 经由一个函数调用的结果来存取静态成员，C++标准要求编译器必须对这个函数进行求值，虽然这个求值的结果并无用处。 foo().static_member = 100; foo()返回一个类型为 X 的对象，含有一个 static_member，foo()其实可以不用求值而直接访 问这个静态成员，但是 C++标准保证了 foo()会被求值，可能的代码扩展为: 12(void) foo();X::static_member = 100; static data members如果有两个 class ，每个都声明了一个 static member freelist，那么当他们都被放在程序的 data segment时，就会导致名称冲突。编译器的解决方法是暗中对每一个 static data member 编码（这种手法有个很美的名称：name-mangling），以获得一个独一无二的程序识别代码。有多少种编译器就有多少种 name-mangling 做法！通常不外乎是表格啦，语法措辞啦等等。任何 name-mangling 都有两个要点： 一种算法，推导出独一无二的名称。 万一编译系统（或环境工具）必须和使用者交谈，那些独一无二的名称可以轻易被推导回原来的名称。 nonstatic data membersNonstatic data members are stored directly within each class object and cannot be accessed except through an explicit or implicit class object. An implicit class object is present whenever the programmer directly accesses a nonstatic data member within a member function. For example, in the following code: 123456Point3dPoint3d::translate( const Point3d &amp;pt ) &#123; x += pt.x; y += pt.y; z += pt.z;&#125; the seemingly direct access of x, y, and z is actually carried out through an implicit class object representedby the this pointer. Internally, the function is augmented as follows: 1234567// internal augmentation of member function Point3d Point3d::translate( const Point3d* this, const Point3d &amp;pt ) &#123; this-&gt;x += pt.x; this-&gt;y += pt.y; this-&gt;z += pt.z;&#125; 地址：&amp;origin._y;和&amp;origin + ( &amp;Point3d::_y - 1 );是一样的。指向 data member 的指针，其 offset 值总是被加上1。这样可以使编译系统区分出 “一个指针 data member 的指针，用以指向 class 的第一个 member”和“一个指向 data member 的指针，但是没有指向任何 member”两种情况(成员指针也需要有个表示 NULL 的方式，0 相当于用来表示 NULL 了，其它的就都要加上 1 了)。 Inheritance and the Data MemberC++ Standard 保证:“出现在派生类中的 base class subobject 有其完整原样性!” 子类会被放在父类的对齐空白字节之后，因为父类的完整性必须得以保证，父类的对齐空白字节 也是父类的一部分，也是不可分割的。 请看下面例子： 12345678910class X&#123;public: int x; char c;&#125;;class X2:public X&#123;public: char c2;&#125;; X2的布局应当是x(4),c(1),c2(1),这么说来sizeof(X2)的值应该是8？错了，实际上是12。原因在于X后面的三个字节的填充空白不能为c2所用。也就是说X2的大小实际上为：X(8)+c2(1)+填补（3）=12。这样看来编译器似乎是那么的呆板，其实不然，看一下下面的语句会发生什么？ 123X2 x2;X x;x2=x; 如果X后面的填充空白可以被c2使用的话，那么X2和X都将是8字节。上面的语句执行后x2.c2的值会是多少？一个不确定的值！这样的结果肯定不是我们想要的。 在多重继承的派生体系中，将派生类的地址转换为第 1 基类时成本与单继承是相同的，只需要改换地址的解释方式而已；而对于转换为非第 1 基类的情况，则需要对地址进行一定的 offset 操作 才行。C++ Standard 并未明确 base classes 的特定排列次序，但是目前的编译器都是按照声明的次序来安放他们的。(有一个优化:如果第 1 基类没有 vtable 而后继基类有，则可能把它们调 个位置)。多重继承中，可能会有多个 vptr 指针，视其继承体系而定:派生类中 vptr 的数目最多等于所有基类的 vptr 数目的总和。 Inside the C++ Object Model 系列笔记向导 Inside the C++ Object Model 系列笔记 一 — Object Lessons Inside the C++ Object Model 系列笔记 二 — The Semantics of constructors Inside the C++ Object Model 系列笔记 三 — The Semantics of Data Inside the C++ Object Model 系列笔记 四 — The Semantics of Function]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《Inside the C++ Object Model》</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inside the C++ Object Model 系列笔记 二 -- The Semantics of constructors]]></title>
    <url>%2Fblog%2F2017%2F10%2F19%2FInside-the-C%2B%2B-Object-Model-%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0--The-Semantics-of-constructors%2F</url>
    <content type="text"><![CDATA[这一章详细的讨论了 constructor 如何工作，讨论构造一个对象的过程以及构造一个对象给程序带来的影响。 区分trivial和notrivial 只有编译器需要的时候(为什么会需要?后面讲的很清楚)，合成操作才是nontrivial的， 这样的构造函数才会被真正的合成出来; 如果编译器不需要，而程序员又没有提供，这时的默认构造函数就是trivial的。虽然它在概念上存在，但是编译器实际上根本不会去合成出来，因为他不做任何没有意义的事情，所以当然可以忽略它不去合成。trivial 的函数只存在于概念上，实际上不存在这个函数。 default constructorA default constructor is a constructor which can be called with no arguments (either defined with an empty parameter list, or with default arguments provided for every parameter). 通常很多C++程序员存在两种误解 没有定义默认构造函数的类都会被编译器生成一个默认构造函数。 编译器生成的默认构造函数会明确初始化类中每一个数据成员。 被声明：declared，被定义：defined。声明代表分配内存空间，定义代表初始化，也就是分配具体的值。 注意如果声明的是一个指针（或者在其他语言里声明了一个对象或者数组的引用），那么只会开辟一个指针的空间，真正的对象要到定义的时候，也就是初始化的时候，分配内存并初始化。 所以所有成员都在声明的时候被分配内存，构造函数的作用是初始化它们，non-object 成员需要程序员自己初始化，编译器不帮忙。 C++中对于默认构造函数的解释是:默认的构造函数会在需要的时候被编译器产生出来。这里非常重要的一点是:谁需要?是程序的需要还是编译器的需要?如果是程序的需要，那是程序员的责任;只有在是编译器的需要时，默认构造函数才会被编译器产生出来，而且被产生出来的默认构造函数只会执行编译器所需要的行动，而且这个产生操作只有在默认构造函数真正被调用时才会进行合成。 例如:成员变量初始化为 0 操作，这个操作就是程序的需要，而不是编译器的需要。 总结变量的初始化: Global objects are guaranteed to have their associated memory “zeroed out” at program start-up. Local objects allocated on the program stack and heap objects allocated on the free-store do not have their associated memory zeroed out; rather, the memory retains the arbitrary bit pattern of its previous use. 只有全局变量和静态变量才会保证初始化，其中静态变量可以视为全局变量的一种，因为静态变量也是保存在全局变量的存储空间上的。Golbal objects 的内存保证会在程序激活的时候被清 0；Local objects 配置于程序的堆栈中，Heap objects 配置于自由空间中，都不一定会被清为 0,它们的内容将是内存上次被使用后的痕迹! 全局变量和静态变量都放在 global data Segment 上，且在类被声明的时候就已经分配内存和初始化，也就是 在任何对象被定义之前静态变量就已经存在了（即使该 class 没有任何 object 实体，static data members也已经存在）。 123456789class Foo &#123; public: int val; Foo *pnext; &#125;;void foo_bar()&#123; // Oops: program needs bar's members zeroed out Foo bar; if ( bar.val || bar.pnext ) // ... do something // ...&#125; When is a default constructor synthesized, then? Only when the implementation needs it. Moreover, the synthesized constructor performs only those activities required by the implementation. That is, even if there were a need to synthesize a default constructor for class Foo, that constructor would not include code to zero out the two data members val and pnext. For the previous program fragment to execute correctly, the designer of class Foo needs to provide an explicit default constructor that properly initializes the class’s two members. 意思是初始化 val 和 pnext 是程序员的责任，编译器不负责，所以你这里不初始化它们，它们存储的结果就是内存遗留的痕迹。 什么时候编译器会给你生成默认构造函数首先你得没有写默认构造函数，编译器才会给你生成。有四类情况，编译器会给你加代码： 类中有一个对象（成员变量），这个对象包含了默认构造函数 继承自带有默认构造函数的基类的类 带有虚函数的类 继承自虚基类的类 如果class A内含一个或以上的member objects，那么A的constructor必须调用每一个 member class 的默认构造函数。具体方法是:编译器会扩张 constructors（注意：是所有的构造函数，不仅仅是默认构造函数会被扩张），在其中安插代码使得在 user code 被调用之前先调 用 member objects 的默认构造函数(当然如果需要调用基类的默认构造函数，则放在基类的 默认构造函数调用之后:基类构造函数-&gt;成员构造函数-&gt;user code)。C++要求以“member objects 在 class 中的声明次序”来调用各个 construtors。这就是声明的次序决定了初始化次序(构造函数初始化列表一直要求以声明顺序来初始化)的根本原因!所以你打乱 member initialization list 的顺序根本没有用哦~ 理解了初始化列表中的实际执行顺序中“以 member 声明的次序”来决定的，就可以理解一些很 微妙的错误了。比如: 12A() : i(99), j(66), value(foo()) &#123;... &#125;int i, value, j; 这会不会产生错误取决于成员函数 foo()是依赖于 i 还是 j:如果 foo 依赖于 i，由于 i 声明在 value 之前，所以不会产生错误;如果 foo 依赖于 j，由于 j 声明在 value 之后，就产生了使用未初始化成员的错误。 带有virtual functions的类的默认构造函数毫无疑问是nontrivial的，需要编译器安插额外的成员 vptr 并在构造函数中正确的设置好 vptr，这是编译器的重要职责之一。继承自 virtual base class 的类的默认构造函数同样也毫无疑问的 nontrivial，编译器需要正确设置相关的信息以使得这些虚基类的信息能够在执行时准备妥当，这些设置取决于编译器实现虚基类的手法。 编译器有4种情况会使得编译器真正的为class生成nontrivial的默认构造函数，这个 nontrivial 的默认构造函数只满足编译器的需要(调用 member objects 或 base class 的默认构造函数、初始化 virtual function 或 virutal base class 机制)。其它情况时，类在概念上拥有默认构造函数，但是实际上根本不会被产生出来(前面的区分 trivial 和 nontrivial)。 对于一个trivial默认构造函数，编译器的态度是，既然它全无用处，干脆就不合成它。在这儿要厘清的是概念与实现的差别，概念上追求缜密完善，在实现上则追求效率，可以不要的东西就不要。 copy constructor有一个参数的类型是其类类型的构造函数是为拷贝构造函数。如下： 123X::X( const X&amp; x);Y::Y( const Y&amp; y, int =0 );//可以是多参数形式，但其第二个即后继参数都有一个默认值 什么时候编译器会给你生成拷贝构造函数 其实和前面默认构造函数一样，四种情况 如果一个类没有定义拷贝构造函数，通常按照“成员逐一初始化(Default Memberwise Initialization)”的手法来解决“一个类对象以另一个同类实体作为初值”——也就是说把内建或派生的数据成员从某一个对象拷贝到另一个对象身上，如果数据成员是一个对象，则递归使用“成员逐一初始化(Default Memberwise Initialization)”的手法。 成员逐一初始化(Default Memberwise Initialization)具体的实现方式则是位逐次拷贝（Bitwise copy semantics） Copy constructors和默认构造函数一样，只有在必须的时候才会被产生出来，对于大部分的class 来说，拷贝构造函数仅仅需要按位拷贝就可以。满足 bitwise copy semantics 的拷贝构造函数是 trivial 的，就不会真正被合成出来(与默认构造函数一样，只有 nontrivial 的拷贝构 造函数才会被真正合成出来)。对大多数类按位拷贝就够了，什么时候一个 class 不展现出 bitwise copy semantics 呢? 分为 4 种情况，前 2 种很明显，后 2 种是由于编译器必须保证正确设置虚机制而引起的。 当class内含一个member object而后者声明了(也可能由于nontrivial语意从而编译器 真正合成出来的)一个 copy constructor 时; 当class继承自一个存在有copy constructor的base class(同样也可能是合成)时; 当class声明了一个或多个virtual functions时;(vf影响了位语意，进而影响效率) 当class派生自一个继承串链，其中一个或多个virtual base classes时。 对于前两种情况，不论是基类还是对象成员，既然后者声明有拷贝构造函数时，就表明其类的设计者或者编译器希望以其声明的拷贝构造函数来完成“一个类对象以另一个同类实体作为初值”的工作，而设计者或编译器这样做——声明拷贝构造函数，总有它们的理由，而通常最直接的原因莫过于因为他们想要做一些额外的工作或“位逐次拷贝”无法胜任。 对于有虚函数的类，如果两个对象的类型相同那么位逐次拷贝其实是可以胜任的。但问题将出现在，如果基类由其继承类进行初始化时，此时若按照位逐次拷贝来完成这个工作，那么基类的vptr将指向其继承类的虚函数表，这将导致无法预料的后果——调用一个错误的虚函数实体是无法避免的，轻则带来程序崩溃，更糟糕的问题可能是这个错误被隐藏了。所以对于有虚函数的类编译器将会明确的使被初始化的对象的vptr指向正确的虚函数表。因此有虚函数的类没有声明拷贝构造函数，编译将为之合成一个，来完成上述工作，以及初始化各数据成员，声明有拷贝构造函数的话也会被插入完成上述工作的代码。 1234567891011121314151617181920212223#include &lt;iostream&gt;using namespace std;class A &#123;public: virtual void f() &#123; cout &lt;&lt; "A::f()" &lt;&lt; endl; &#125; int i;&#125;;class B : public A &#123;public: void f()&#123; cout &lt;&lt; "B::f()" &lt;&lt; endl; &#125;&#125;;int main(int argc, char const *argv[])&#123; B b; b.i=1; A a = b; A *p = &amp;a; p-&gt;f(); cout &lt;&lt; p-&gt;i &lt;&lt; endl; return 0;&#125; 上面例子可以看出，如果 A a = b;是 bitwise copy semantics 的话，a 内放置的就是 b 的 vptr。但其实不是，编译器给 a 生成了拷贝构造函数，初始化了 a 的 vptr。b 的 vptr 是由编译器给 b 生成的默认构造函数初始化的。但对于其他成员变量 bitwise copy semantics依然有效，所以 i 的结果是1。我在做这个试验的时候发现了一个有趣的现象： 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class A &#123;public: virtual void f() &#123; cout &lt;&lt; "A::f()" &lt;&lt; endl; &#125; int i;&#125;;class B : public A &#123;public: void f()&#123; cout &lt;&lt; "B::f()" &lt;&lt; endl; &#125; int i;&#125;;int main(int argc, char const *argv[])&#123; B b; b.i=1; A a = b; A *p = &amp;a; p-&gt;f(); cout &lt;&lt; p-&gt;i &lt;&lt; endl; return 0;&#125; 两个 i 不是同一个 i，b.i=1;优先给 b 中的同名变量赋值了。这样的代码简直可怕。那么怎么访问到从 A 继承来的成员变量 i 呢，请看： 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class A &#123;public: virtual void f() &#123; cout &lt;&lt; "A::f()" &lt;&lt; endl; &#125; int i;&#125;;class B : public A &#123;public: void f()&#123; cout &lt;&lt; "B::f()" &lt;&lt; endl; &#125; int i;&#125;;int main(int argc, char const *argv[])&#123; B b; b.A::i=6; b.B::i=1; A a = b; A *p = &amp;a; cout &lt;&lt; p-&gt;i &lt;&lt; endl; return 0;&#125; 命名返回值优化对于一个如foo()这样的函数，它的每一个返回分支都返回相同的对象，编译器有可能对其做Named return Value优化（下文都简称NRV优化），方法是以一个参数result取代返回对象。 foo()的原型： 12345678X foo()&#123; X xx; if(...) return xx; else return xx;&#125; 优化后的foo()以result取代xx： 1234567891011121314void foo(X &amp;result)&#123; result.X::X(); if(...) &#123; //直接处理result return; &#125; else &#123; //直接处理result return; &#125;&#125; 对比优化前与优化后的代码可以看出，对于一句类似于X a = foo()这样的代码，NRV优化后的代码相较于原代码节省了一个临时对象的空间（省略了xx）,同时减少了两次函数调用（减少xx对象的默认构造函数和析构函数，以及一次拷贝构造函数的调用，增加了一次对a的默认构造函数的调用）。 Inside the C++ Object Model 系列笔记向导 Inside the C++ Object Model 系列笔记 一 — Object Lessons Inside the C++ Object Model 系列笔记 二 — The Semantics of constructors Inside the C++ Object Model 系列笔记 三 — The Semantics of Data Inside the C++ Object Model 系列笔记 四 — The Semantics of Function]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《Inside the C++ Object Model》</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inside the C++ Object Model 系列笔记 一 -- Object Lessons]]></title>
    <url>%2Fblog%2F2017%2F10%2F19%2FInside-the-C%2B%2B-Object-Model-%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0--Object-Lessons%2F</url>
    <content type="text"><![CDATA[多态：统一的接口，不同的实现 C++多态（polymorphism） 表示“以一个public base class的指针（或者reference），寻址出一个derived class object” Layout Costs for Adding Encapsulation(封装) 意思是：为了添加封装所需要付出的内存布局花销 第一章 Object Lessons 介绍了 C++如何在背后实现一个对象，内存中的布局以及空间上的关系。 在计算机的原理中，要实现某个机制，我们总能找到很多种实现方式（对比着学习，多思考每种实现方法的利弊），C++的类的实现也不例外，让我们对比以下三种实现方式： 三种对象实现模式A Simple Object Model 可以看到，简单对象模型把所有的data member和member function（函数指针）都放在对象里了。 A Table-driven Object Model 表驱动模型把member分为data和function两类，用两个指针分别指向两个表，一个存放所有的data member，一个存放所有的function指针。 The C++ Object Model 12345678template&lt;class Type&gt;class Point3d&#123;public: Point3d(Type x, Type y, Type z) : x_(x), y_(y), z_(z) &#123;&#125; Type x() &#123; return x_; &#125;private: Type x_, y_, z_;&#125; 上面的 C++ 类并不会比 C 语言 的struct 耗费更多的内存空间，三个 data members 直接内含于 Object 中，member functions 则放在 Object 外。 C++的 data members 有两种：static 和 nonstatic C++的 member functions 有三种：static 、nonstatic 、virtual 放在 Object 中的只有 nonstatic data members，其他的统统是放在 Object 外。 一个对象的内存布局大小(通常由 3 部分组成): 其 nonstatic data member 的总和大小; 任何由于位对齐所需要的填补上去的空间;(关于内存对齐，自己查) 为了支持virtual机制而引起的额外负担。 data members 在内存中的布局C++只保证处于同一个 access section（也就是private,public,protected片段）的数据，一定会以声明的次序出现在内存布局当中(要求较晚出现的数据成员处在较大的内存地址中)。C++标准只提供了这一点点的保证。允许编译器将多个Acess Section的顺序自由排列，而不必在乎它们的声明次序。但似乎没有编译器这样做。对于继承类，C++标准并未指定是其基类成员在前还是自己的成员在前。 12345678class X &#123;public: int i; int j;private: int k; int n;&#125; 数据 i 一定在 j 之前，k 一定在 n 之前。其他顺序就看编译器了。 Virtual Table(vtbl, vtable) 和 vptrVirtual function 机制由以下2个步骤来支持： 每个 class 产生的 Virtual function 的指针放在 Virtual Table 中 编译器给每个 class object 添加一个指针 vptr，指向相应的 vtable 一个 vtable 对应一个 class，一个 vptr 才对应一个 class object，必须区分开这 2 个概念。vtable 独立于对象，就跟函数独立于对象一样。这样所有对象才能共享它们，就像 static data members 被共享一样。 nonstatic data member是对象独有的，每个对象都有自己的一份。而其他的member全都是公用的。其实这里可以顺便学一下序列化这个概念，思考一下序列化对象的时候哪些东西需要存储。 RTTI(run-time type identification):一般来说，每一个 class 相关联的 type_info 对象的指针通常也保存在 vtable 的第一个 slot 中。关于 type_info 是什么，可以自己查。 引入继承后的对象模型成本 如果是普通继承，父对象被直接包含在子对象里面，这样父对象的存取也是直接进行的，没有额外的指针成本。 如果是虚拟继承，父对象由一个指针指出来，这样父对象的存取就必须由指针访问，添加了一层间接性。 virtual base class，用以实现 “多次出现在继承体系中的base class，有一个单一而被共享的实例” 1234class A &#123; public: void Foo() &#123;&#125; &#125;;class B : public virtual A &#123;&#125;;class C : public virtual A &#123;&#125;;class D : public B, public C &#123;&#125;; 我觉得这里有个问题，class D继承class B和class C的时候并不是虚继承，所以何不将B和C直接放在D中呢？这样就省了两次指针。 这是我看到的一个讲的很不错的博客：虚拟继承 struct 和 class 关键字的区别总共就两个区别： struct defaults to public access and class defaults to private access. When inheriting, struct defaults to public inheritance and class defaults to private inheritance. (Ironically, as with so many things in C++, the default is backwards: public inheritance is by far the more common choice, but people rarely declare structs just to save on typing the “public” keyword). 哈哈，我觉得这么做的目的无非就是提醒你注意封装，不要给外部暴露没必要的东西，所以才把默认搞成private。 除此之外 struct 和 class 一样。 struct 用来表现那些只有数据的集合体 POD(Plain Old Data)、而 class则希望表达的是ADT(abstract data type)的思想。 POD stands for Plain Old Data - that is, a class (whether defined with the keyword struct or the keyword class) without constructors, destructors and virtual members functions. 由于这2个关键字在本质上无区别，所以class并没有必须要引入，但是引入它的确非常令人满意，因为这个语言所引入的不止是这个关键字，还有它所支持的封装和继承的哲学。可以这样想象：struct只剩下方便C程序员迁徙到C++的用途了。 programming paradigmsC++支持三种形式的编程风格(或称典范 paradigm): 面向过程的风格（procedural model）: 就像C一样，一条语句接一条语句的执行或者函数跳转; 抽象数据类型模型(abstract data type model，ADT): 仅仅使用了class的封装，很多人都是 在用基于对象的风格却误以为自己在使用面向对象的风格; 面向对象的风格(object-oriented): 使用了class的封装和多态的编程思维(多态才是 真正的面向对象的特征)。 纯粹以一种paradigm写程序，有助于整体行为的良好稳固。 一个 reference 通常是以一个指针来实现的，所以 point 和 reference 并没有本质的区别，reference 和 const 指针的区别就是，你取 reference 指针的地址的时候，取到的是数据的地址，const 指针取地址取到的是指针的地址。下面的程序说明了这一点： 123456789101112#include &lt;iostream&gt;using namespace std;int main()&#123; int a=1; int &amp;b=a; const int *p = &amp;a; cout &lt;&lt; &amp;b &lt;&lt; endl; cout &lt;&lt; p &lt;&lt; endl; cout &lt;&lt; &amp;p &lt;&lt; endl;&#125; 也就是说你取不到 b 的地址。所以说引用相当于一个 别名。引用常用在函数调用里，可以直接操作原有对象，这样就可以不用写指针的指针这种绕弯的东西了。 函数的实参传递给形参是值传递，也就是一个 copy，形参在函数里将是一个局部变量。这个特性是许多新手面临的大坑。一道经典的考察题目便是，实现一个 C 语言的 swap 函数，由于 C 语言没有引用，你就只能用指针来操作原有对象了。java更坑，java没有指针，所以需要用引用，但基础数据类型没有引用，所以你如果要交换基础数据类型的话，根本没办法写swap函数。 如果你对C语言的程序栈很了解的话，就会知道形参实际上是不存在的，实参直接拷贝到了寄存器中，所以底层上来说参数都是值拷贝，而且操作结果无法写回到实参，实参稳稳的放在上一个栈帧中从未发生任何变化。具体的细节可以看：《CSAPP》读书笔记 — 第3章：程序的机器级表示 指针的类型 对于内存来说，不同类型的指针并没有什么不同。它们都是占用一个word的大小（所以word的大小决定了内存可访问空间的大小，32位系统是4字节，64位系统是8字节），包含一个数字，这个数字代表内存中的一个地址; 指针的类型是编译器的概念，对于硬件来说，并没有什么指针类型的概念; 转型操作也只是一种编译器的指令，它改变的是编译器对被指内存的解释方式而已! void*指针只能够持有一个地址（一个字节），而不能通过它操作所指向的object Inside the C++ Object Model 系列笔记向导 Inside the C++ Object Model 系列笔记 一 — Object Lessons Inside the C++ Object Model 系列笔记 二 — The Semantics of constructors Inside the C++ Object Model 系列笔记 三 — The Semantics of Data Inside the C++ Object Model 系列笔记 四 — The Semantics of Function]]></content>
      <categories>
        <category>读书笔记</category>
        <category>《Inside the C++ Object Model》</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
